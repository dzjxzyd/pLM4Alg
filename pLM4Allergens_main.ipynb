{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95NTckuFZZzm"
      },
      "source": [
        "## package installation and load packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO71IBS6ZgZV",
        "outputId": "29f26b0b-6bda-461d-96e4-84b9315058c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m92.2/93.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post11.tar.gz (3.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "### packages required\n",
        "!pip install fair-esm\n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn\n",
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3sxRX-RfzoB",
        "outputId": "13d26bd0-6fd1-4637-f85d-05e7fed877a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU found\n"
          ]
        }
      ],
      "source": [
        "import esm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
        "from keras.layers import Dropout, AveragePooling1D, MaxPooling1D\n",
        "from keras.models import Sequential,Model, load_model\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "    tf.config.experimental.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU') # set the deep learning with GPU\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m91cA0H5w_eY"
      },
      "source": [
        "### peptide embeddings with differen pretrained model\n",
        "https://github.com/facebookresearch/esm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmb2VZKeZlWC"
      },
      "source": [
        "Explaination of the memeory usage of the following models\n",
        "\n",
        "sequence length > 900\n",
        "\n",
        "2560 output dimension model might need 24 G GPU memory\n",
        "\n",
        "5129 output dimension model, (in our attempts, 40 GB GPU memory is not enough)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings_320(esm2, esm2_alphabet, peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
        "  #         or you have too many sequences for transformation in a single converting,\n",
        "  #         you computer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  import pandas as pd\n",
        "  import gc\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  esm2 = esm2.eval().to(device)\n",
        "\n",
        "  batch_converter = esm2_alphabet.get_batch_converter()\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = esm2(batch_tokens, repr_layers=[6], return_contacts=False)\n",
        "  token_representations = results[\"representations\"][6].cpu()\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  del  batch_labels, batch_strs, batch_tokens, results, token_representations\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return embeddings_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXIH6LOsV-6v"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings_480(esm2, esm2_alphabet, peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
        "  #         or you have too many sequences for transformation in a single converting,\n",
        "  #         you computer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  import pandas as pd\n",
        "  import gc\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  esm2 = esm2.eval().to(device)\n",
        "\n",
        "  batch_converter = esm2_alphabet.get_batch_converter()\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t12_35M_UR50D' only has 12 layers, and therefore repr_layers parameters is equal to 12\n",
        "      results = esm2(batch_tokens, repr_layers=[12], return_contacts=False)\n",
        "  token_representations = results[\"representations\"][12].cpu()\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  del  batch_labels, batch_strs, batch_tokens, results, token_representations\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return embeddings_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN7A3bgzhFny"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings_640(esm2, esm2_alphabet, peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
        "  #         or you have too many sequences for transformation in a single converting,\n",
        "  #         you computer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  import pandas as pd\n",
        "  import gc\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  esm2 = esm2.eval().to(device)\n",
        "\n",
        "  batch_converter = esm2_alphabet.get_batch_converter()\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t30_150M_UR50D' only has 30 layers, and therefore repr_layers parameters is equal to 30\n",
        "      results = esm2(batch_tokens, repr_layers=[30], return_contacts=False)\n",
        "  token_representations = results[\"representations\"][30].cpu()\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  del  batch_labels, batch_strs, batch_tokens, results, token_representations\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return embeddings_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdQIPEe2V3lB"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings_1280(esm2, esm2_alphabet, peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
        "  #         or you have too many sequences for transformation in a single converting,\n",
        "  #         you computer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  import pandas as pd\n",
        "  import gc\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  esm2 = esm2.eval().to(device)\n",
        "\n",
        "  batch_converter = esm2_alphabet.get_batch_converter()\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t33_650M_UR50D' only has 33 layers, and therefore repr_layers parameters is equal to 33\n",
        "      results = esm2(batch_tokens, repr_layers=[33], return_contacts=False)\n",
        "  token_representations = results[\"representations\"][33].cpu()\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  del  batch_labels, batch_strs, batch_tokens, results, token_representations\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return embeddings_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmr0OfcTWN05"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings_2560(esm2, esm2_alphabet, peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
        "  #         or you have too many sequences for transformation in a single converting,\n",
        "  #         you computer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  import pandas as pd\n",
        "  import gc\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  esm2 = esm2.eval().to(device)\n",
        "\n",
        "  batch_converter = esm2_alphabet.get_batch_converter()\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t36_3B_UR50D' only has 36 layers, and therefore repr_layers parameters is equal to 36\n",
        "      results = esm2(batch_tokens, repr_layers=[36], return_contacts=False)\n",
        "  token_representations = results[\"representations\"][36].cpu()\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  del  batch_labels, batch_strs, batch_tokens, results, token_representations\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return embeddings_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kjrdZscWULt"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings_5120(esm2, esm2_alphabet, peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
        "  #         or you have too many sequences for transformation in a single converting,\n",
        "  #         you computer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  import pandas as pd\n",
        "  import gc\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  esm2 = esm2.eval().to(device)\n",
        "\n",
        "  batch_converter = esm2_alphabet.get_batch_converter()\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t48_15B_UR50D' only has 48 layers, and therefore repr_layers parameters is equal to 48\n",
        "      results = esm2(batch_tokens, repr_layers=[48], return_contacts=False)\n",
        "  token_representations = results[\"representations\"][48].cpu()\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  del  batch_labels, batch_strs, batch_tokens, results, token_representations\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return embeddings_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz-ZO_mrnSsn"
      },
      "source": [
        "### connect with googledrive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FroNV0ZpnW0e",
        "outputId": "40209112-686d-48ee-88cf-e7b3810287e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOCDoACdowFc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6JdFa_7ZGL7",
        "outputId": "425fc6cd-b5c2-45a8-a91a-9f7c199532c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/universal_allergenicity_new\n",
            " 1280_dim.joblib\n",
            "'1280_grid_performance output_repeat1.xlsx'\n",
            "'1280_grid_performance output_repeat_2048.xlsx'\n",
            "'1280_grid_performance output_repeat_256.xlsx'\n",
            "'1280_grid_performance output_repeat_node_4096_2.xlsx'\n",
            "'1280_grid_performance output_repeat_node_4096.xlsx'\n",
            "'1280_grid_performance output_repeat_node_512_second.xlsx'\n",
            "'1280_grid_performance output_repeat_node_8192_2.xlsx'\n",
            "'1280_grid_performance output.xlsx'\n",
            "'1280 performance output repeat 10.xlsx'\n",
            "'1280 ROC.xlsx'\n",
            " 1esm2_t6_8M_UR50D_unified_320_dimension.png\n",
            " 2560_dim.joblib\n",
            "'2560_grid_performance output_repeat_2.xlsx'\n",
            "'2560_grid_performance output_repeat_node_4096_2.xlsx'\n",
            "'2560_grid_performance output_repeat_node_512.xlsx'\n",
            "'2560_grid_performance output.xlsx'\n",
            "'2560 ROC.xlsx'\n",
            "'2560 ten times repeat performance output_large_contained.xlsx'\n",
            "'2560 ten times repeat performance output_small.xlsx'\n",
            " 320_dim.joblib\n",
            "'320_grid_performance output_repeat_2.xlsx'\n",
            "'320_grid_performance output_repeat_node_2048_second.xlsx'\n",
            "'320_grid_performance output_repeat_node_2048.xlsx'\n",
            "'320_grid_performance output_repeat_node_4096.xlsx'\n",
            "'320_grid_performance output_repeat_node_512_second.xlsx'\n",
            "'320_grid_performance output_repeat_node_512.xlsx'\n",
            "'320_grid_performance output_repeat_node_8192_second.xlsx'\n",
            "'320_grid_performance output_repeat_node_8192.xlsx'\n",
            "'320_grid_performance output.xlsx'\n",
            "'320 ROC.xlsx'\n",
            "'320 ten times repeat performance output_large_8192_contained.xlsx'\n",
            "'320 ten times repeat performance output_large.xlsx'\n",
            "'320 ten times repeat performance output_small_contained.xlsx'\n",
            " 480_dim.joblib\n",
            "'480_grid_performance output_repeat1.xlsx'\n",
            "'480_grid_performance output_repeat_256.xlsx'\n",
            "'480_grid_performance output_repeat_node_4096_2.xlsx'\n",
            "'480_grid_performance output_repeat_node_4096.xlsx'\n",
            "'480_grid_performance output_repeat_node512_second.xlsx'\n",
            "'480_grid_performance output_repeat_node512.xlsx'\n",
            "'480_grid_performance output_repeat_node5_2048_second.xlsx'\n",
            "'480_grid_performance output_repeat_node5_2048.xlsx'\n",
            "'480_grid_performance output_repeat_node_8192_second.xlsx'\n",
            "'480_grid_performance output_repeat_node_8192_third.xlsx'\n",
            "'480_grid_performance output_repeat_node_8192.xlsx'\n",
            "'480_grid_performance output_repeat_node_8192_.xlsx'\n",
            "'480_grid_performance output.xlsx'\n",
            "'480 ROC.xlsx'\n",
            "'480 ten times repeat performance output_small.xlsx'\n",
            "'480 ten times repeat performance output.xlsx'\n",
            " 640_dim.joblib\n",
            "'640_grid_performance output_repeat_2_256.xlsx'\n",
            "'640_grid_performance output_repeat_2.xlsx'\n",
            "'640_grid_performance output_repeat_node_2048_second.xlsx'\n",
            "'640_grid_performance output_repeat_node_2048.xlsx'\n",
            "'640_grid_performance output_repeat_node_40962.xlsx'\n",
            "'640_grid_performance output_repeat_node_4096.xlsx'\n",
            "'640_grid_performance output_repeat_node_512_second.xlsx'\n",
            "'640_grid_performance output_repeat_node_512.xlsx'\n",
            "'640_grid_performance output_repeat_node_8192.xlsx'\n",
            "'640_grid_performance output.xlsx'\n",
            "'640 ROC.xlsx'\n",
            "'640 ten times repeat performance output_large_8192_contained.xlsx'\n",
            " allergens_dataset_pos1_neg0.xlsx\n",
            " allergens_dataset.xlsx\n",
            " AllerTOPv2.xlsx\n",
            " average_pooling_test\n",
            " best_modelbest_1280_repeat_10small.h5\n",
            " best_modelbest_480_repeat.h5\n",
            " best_model_grid_1280.h5\n",
            " best_model_grid_1280_node4096.h5\n",
            " best_model_grid_1280_node.h5\n",
            " best_model_grid_1280_server.h5\n",
            " best_model_grid_2560_1.h5\n",
            " best_model_grid_2560.h5\n",
            " best_model_grid_2560_node_4096.h5\n",
            " best_model_grid_2560_node4096.h5\n",
            " best_model_grid_2560_node.h5\n",
            " best_model_grid_2560_server.h5\n",
            " best_model_grid_320.h5\n",
            " best_model_grid_320_node4096.h5\n",
            " best_model_grid_320_node8192.h5\n",
            " best_model_grid_320_server.h5\n",
            " best_model_grid_480.h5\n",
            " best_model_grid_480_node4096.h5\n",
            " best_model_grid_480_node8192.h5\n",
            " best_model_grid_480_node8192_.h5\n",
            " best_model_grid_640_4096.h5\n",
            " best_model_grid_640_8192.h5\n",
            " best_model_grid_640.h5\n",
            " esm2_t12_35M_UR50D_unified_480_dimension.png\n",
            " esm2_t12_35M_UR50D_unified_480_dimension.xlsx\n",
            " esm2_t30_150M_UR50D_unified_640_dimension.png\n",
            " esm2_t30_150M_UR50D_unified_640_dimension.xlsx\n",
            " esm2_t33_650M_UR50D_unified_1280_dimension.png\n",
            " esm2_t33_650M_UR50D_unified_1280_dimension.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension100.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension100.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension10.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension10.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension50.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension50.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA100__30.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA100__30.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA_10.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA_10.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA_15.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA_15.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA_30.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimensionPCA_30.xlsx\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension.png\n",
            " esm2_t36_3B_UR50D_unified_2560_dimension.xlsx\n",
            " esm2_t6_8M_UR50D_unified_320_dimension.xlsx\n",
            "'Test on other datasets-AllerStat'\n",
            "'Test on other datasets-AllerTopv2'\n",
            " umap_esm2_t12_35M_UR50D_unified_480_dimension.png\n",
            " umap_esm2_t12_35M_UR50D_unified_480_dimension.xlsx\n",
            " umap_esm2_t30_150M_UR50D_unified_640_dimension.png\n",
            " umap_esm2_t30_150M_UR50D_unified_640_dimension.xlsx\n",
            " umap_esm2_t33_650M_UR50D_unified_1280_dimension.png\n",
            " umap_esm2_t33_650M_UR50D_unified_1280_dimension.xlsx\n",
            " umap_esm2_t36_3B_UR50D_unified_2560_dimension.png\n",
            " umap_esm2_t36_3B_UR50D_unified_2560_dimension.xlsx\n",
            " umap_esm2_t6_8M_UR50D_unified_320_dimension.png\n",
            " umap_esm2_t6_8M_UR50D_unified_320_dimension.xlsx\n",
            "'web server'\n",
            " whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv\n",
            " whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv\n",
            " whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv\n",
            " whole_sample_dataset_esm2_t36_3B_UR50D_unified_2560_dimension.csv\n",
            " whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJ-0YPyiQhp"
      },
      "source": [
        "#### load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTetST5AiUAh",
        "outputId": "d404c45c-43fd-463a-ad2c-cdb2281f402f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU found\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
        "from keras.layers import Dropout, AveragePooling1D, MaxPooling1D\n",
        "from keras.models import Sequential,Model, load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "    tf.config.experimental.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU') # set the deep learning with GPU\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RLR10hUsxca"
      },
      "source": [
        "## Sequence embeddings with different pretrained protein language models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztgr6bl-YGDI"
      },
      "source": [
        "### 320 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eogcsymmYJ6A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "# select the ESM model for embeddings (you can select you desired model from https://github.com/facebookresearch/esm)\n",
        "# NOTICE: if you choose other model, the following model architecture might not be very compitable\n",
        "#         bseides,please revise the correspdoning parameters in esm_embeddings function (layers for feature extraction)\n",
        "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "\n",
        "\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple([seq,seq])\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings_320(model, alphabet, peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "embeddings_results.to_csv('whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5bIwhNNjM0T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9DKdoi6jPBb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "# select the ESM model for embeddings (you can select you desired model from https://github.com/facebookresearch/esm)\n",
        "# NOTICE: if you choose other model, the following model architecture might not be very compitable\n",
        "#         bseides,please revise the correspdoning parameters in esm_embeddings function (layers for feature extraction)\n",
        "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "\n",
        "\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset_pos1_neg0.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple([seq,seq])\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings_320(model, alphabet, peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "embeddings_results.to_csv('whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension_pos1_neg0.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3yzGDFEYfCY"
      },
      "source": [
        "### 480 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SMpqoc-3YlCo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "# select the ESM model for embeddings (you can select you desired model from https://github.com/facebookresearch/esm)\n",
        "# NOTICE: if you choose other model, the following model architecture might not be very compitable\n",
        "#         bseides,please revise the correspdoning parameters in esm_embeddings function (layers for feature extraction)\n",
        "model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
        "\n",
        "\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple([seq,seq])\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings_480(model, alphabet, peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "embeddings_results.to_csv('whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFyOy-19Yvil"
      },
      "source": [
        "### 640 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TXYWJ5EY4o-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "# select the ESM model for embeddings (you can select you desired model from https://github.com/facebookresearch/esm)\n",
        "# NOTICE: if you choose other model, the following model architecture might not be very compitable\n",
        "#         bseides,please revise the correspdoning parameters in esm_embeddings function (layers for feature extraction)\n",
        "model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
        "\n",
        "\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple([seq,seq])\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings_640(model, alphabet, peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "embeddings_results.to_csv('whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEdAluvxYzfJ"
      },
      "source": [
        "### 1280 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwang7k8Y_gt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "# select the ESM model for embeddings (you can select you desired model from https://github.com/facebookresearch/esm)\n",
        "# NOTICE: if you choose other model, the following model architecture might not be very compitable\n",
        "#         bseides,please revise the correspdoning parameters in esm_embeddings function (layers for feature extraction)\n",
        "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple([seq,seq])\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings_1280(model, alphabet, peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "embeddings_results.to_csv('whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex7esuYyY0vU"
      },
      "source": [
        "### 2560 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRUBeL3uaG0a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "# select the ESM model for embeddings (you can select you desired model from https://github.com/facebookresearch/esm)\n",
        "# NOTICE: if you choose other model, the following model architecture might not be very compitable\n",
        "#         bseides,please revise the correspdoning parameters in esm_embeddings function (layers for feature extraction)\n",
        "model, alphabet = esm.pretrained.esm2_t36_3B_UR50D()\n",
        "\n",
        "\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "a=0\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple([seq,seq])\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings_2560(model, alphabet, peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "    a=a+1\n",
        "    print(a)\n",
        "embeddings_results.to_csv('whole_sample_dataset_esm2_t36_3B_UR50D_unified_2560_dimension.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSCXCjv8gYIr"
      },
      "source": [
        "## grid search for hyperparameters of CNN model\n",
        "Due to the enormous memory consumption and limitted dataset, we do not test 256 fileter size in CNN with 8192 units in dense layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZBMpsS3_Ymu"
      },
      "source": [
        "### 320 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sguq72SHkfOL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "\n",
        "# loading the y dataset for model development\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "\n",
        "# split dataset as training and test dataset as ratio of 8:2\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ACC_collecton = []\n",
        "CNN_channel = [16,32,64,128,256]\n",
        "dense_node = [32,64,128,256,512,1024,2048,4096,8192]\n",
        "kernel_size = [3,6,9,12]\n",
        "stride_size = [1,2,4,8]\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        inputShape=(320,1) # input feature size\n",
        "        input = Input(inputShape)\n",
        "        x = Conv1D(CNN_channel[i],(kernel_size[k]),strides = (stride_size[l]),name='layer_conv2',padding='same')(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(dense_node[j],activation = 'relu',name='fc1')(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "        model = Model(inputs = input,outputs = x,name='Predict')\n",
        "        # define SGD optimizer\n",
        "        momentum = 0.5\n",
        "        sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "        # compile the model\n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "        # learning deccay setting\n",
        "        import math\n",
        "        def step_decay(epoch): # gradually decrease the learning rate\n",
        "            initial_lrate=0.1\n",
        "            drop=0.6\n",
        "            epochs_drop = 3.0\n",
        "            lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "                  math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "            return lrate\n",
        "        lr = LearningRateScheduler(step_decay)\n",
        "        # early stop setting\n",
        "        early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "        # set checkpoint and save the best model\n",
        "        mc = ModelCheckpoint('best_model_grid_320.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "        # summary the callbacks_list\n",
        "        callbacks_list = [ lr , early_stop, mc]\n",
        "        model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=0)\n",
        "        # load the save best model\n",
        "        saved_model = load_model('best_model_grid_320.h5')\n",
        "        # result collection list\n",
        "        # confusion matrix\n",
        "        predicted_class= []\n",
        "        predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "        for p in range(predicted_protability.shape[0]):\n",
        "          index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "          predicted_class.append(index)\n",
        "        predicted_class = np.array(predicted_class)\n",
        "        y_true = y_test\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        import math\n",
        "        # np.ravel() return a flatten 1D array\n",
        "        TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "        ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "        ACC_collecton.append(ACC)\n",
        "        print(ACC)\n",
        "        del model\n",
        "        import torch\n",
        "        import gc\n",
        "        torch.cuda.memory_reserved()\n",
        "        gc.collect()\n",
        "\n",
        "import collections\n",
        "model_parameters =collections.defaultdict(list)\n",
        "a=0\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        iter_num = str(a)\n",
        "        model_parameters[iter_num].append(CNN_channel[i])\n",
        "        model_parameters[iter_num].append(dense_node[j])\n",
        "        model_parameters[iter_num].append(kernel_size[k])\n",
        "        model_parameters[iter_num].append(stride_size[l])\n",
        "        model_parameters[iter_num].append(ACC_collecton[a])\n",
        "        a=a+1\n",
        "# export the DataFrame to an Excel file\n",
        "pd.DataFrame(model_parameters).to_excel('320_grid_performance output.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn_ddIHq_Ymv"
      },
      "source": [
        "### 480 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6YpKLSZkUo6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "\n",
        "# loading the y dataset for model development\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "\n",
        "# split dataset as training and test dataset as ratio of 8:2\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ACC_collecton = []\n",
        "CNN_channel = [16,32,64,128,256]\n",
        "dense_node = [32,64,128,256,512,1024,2048,4096,8192]\n",
        "kernel_size = [3,6,9,12]\n",
        "stride_size = [1,2,4,8]\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        inputShape=(480,1) # input feature size\n",
        "        input = Input(inputShape)\n",
        "        x = Conv1D(CNN_channel[i],(kernel_size[k]),strides = (stride_size[l]),name='layer_conv2',padding='same')(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(dense_node[j],activation = 'relu',name='fc1')(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "        model = Model(inputs = input,outputs = x,name='Predict')\n",
        "        # define SGD optimizer\n",
        "        momentum = 0.5\n",
        "        sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "        # compile the model\n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "        # learning deccay setting\n",
        "        import math\n",
        "        def step_decay(epoch): # gradually decrease the learning rate\n",
        "            initial_lrate=0.1\n",
        "            drop=0.6\n",
        "            epochs_drop = 3.0\n",
        "            lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "                  math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "            return lrate\n",
        "        lr = LearningRateScheduler(step_decay)\n",
        "        # early stop setting\n",
        "        early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "        # set checkpoint and save the best model\n",
        "        mc = ModelCheckpoint('best_model_grid_480.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "        # summary the callbacks_list\n",
        "        callbacks_list = [ lr , early_stop, mc]\n",
        "        model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=0)\n",
        "        # load the save best model\n",
        "        saved_model = load_model('best_model_grid_480.h5')\n",
        "        # result collection list\n",
        "        # confusion matrix\n",
        "        predicted_class= []\n",
        "        predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "        for p in range(predicted_protability.shape[0]):\n",
        "          index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "          predicted_class.append(index)\n",
        "        predicted_class = np.array(predicted_class)\n",
        "        y_true = y_test\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        import math\n",
        "        # np.ravel() return a flatten 1D array\n",
        "        TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "        ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "        ACC_collecton.append(ACC)\n",
        "        print(ACC)\n",
        "        del model\n",
        "        import torch\n",
        "        import gc\n",
        "        torch.cuda.memory_reserved()\n",
        "        gc.collect()\n",
        "\n",
        "import collections\n",
        "model_parameters =collections.defaultdict(list)\n",
        "a=0\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        iter_num = str(a)\n",
        "        model_parameters[iter_num].append(CNN_channel[i])\n",
        "        model_parameters[iter_num].append(dense_node[j])\n",
        "        model_parameters[iter_num].append(kernel_size[k])\n",
        "        model_parameters[iter_num].append(stride_size[l])\n",
        "        model_parameters[iter_num].append(ACC_collecton[a])\n",
        "        a=a+1\n",
        "# export the DataFrame to an Excel file\n",
        "pd.DataFrame(model_parameters).to_excel('480_grid_performance output.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXbl2M2w_Ymw"
      },
      "source": [
        "### 640 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J_Da_KbkPgS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "\n",
        "# loading the y dataset for model development\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "\n",
        "# split dataset as training and test dataset as ratio of 8:2\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ACC_collecton = []\n",
        "CNN_channel = [16,32,64,128,256]\n",
        "dense_node = [32,64,128,256,512,1024,2048,4096,8192]\n",
        "kernel_size = [3,6,9,12]\n",
        "stride_size = [1,2,4,8]\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        inputShape=(640,1) # input feature size\n",
        "        input = Input(inputShape)\n",
        "        x = Conv1D(CNN_channel[i],(kernel_size[k]),strides = (stride_size[l]),name='layer_conv2',padding='same')(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(dense_node[j],activation = 'relu',name='fc1')(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "        model = Model(inputs = input,outputs = x,name='Predict')\n",
        "        # define SGD optimizer\n",
        "        momentum = 0.5\n",
        "        sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "        # compile the model\n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "        # learning deccay setting\n",
        "        import math\n",
        "        def step_decay(epoch): # gradually decrease the learning rate\n",
        "            initial_lrate=0.1\n",
        "            drop=0.6\n",
        "            epochs_drop = 3.0\n",
        "            lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "                  math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "            return lrate\n",
        "        lr = LearningRateScheduler(step_decay)\n",
        "        # early stop setting\n",
        "        early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "        # set checkpoint and save the best model\n",
        "        mc = ModelCheckpoint('best_model_grid_640.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "        # summary the callbacks_list\n",
        "        callbacks_list = [ lr , early_stop, mc]\n",
        "        model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=0)\n",
        "        # load the save best model\n",
        "        saved_model = load_model('best_model_grid_640.h5')\n",
        "        # result collection list\n",
        "        # confusion matrix\n",
        "        predicted_class= []\n",
        "        predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "        for p in range(predicted_protability.shape[0]):\n",
        "          index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "          predicted_class.append(index)\n",
        "        predicted_class = np.array(predicted_class)\n",
        "        y_true = y_test\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        import math\n",
        "        # np.ravel() return a flatten 1D array\n",
        "        TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "        ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "        ACC_collecton.append(ACC)\n",
        "        print(ACC)\n",
        "        del model\n",
        "        import torch\n",
        "        import gc\n",
        "        torch.cuda.memory_reserved()\n",
        "        gc.collect()\n",
        "import collections\n",
        "model_parameters =collections.defaultdict(list)\n",
        "a=0\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        iter_num = str(a)\n",
        "        model_parameters[iter_num].append(CNN_channel[i])\n",
        "        model_parameters[iter_num].append(dense_node[j])\n",
        "        model_parameters[iter_num].append(kernel_size[k])\n",
        "        model_parameters[iter_num].append(stride_size[l])\n",
        "        model_parameters[iter_num].append(ACC_collecton[a])\n",
        "        a=a+1\n",
        "# export the DataFrame to an Excel file\n",
        "pd.DataFrame(model_parameters).to_excel('640_grid_performance output.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riQQE4SS_Ymy"
      },
      "source": [
        "### 1280 feature dimension embedding test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaLj2PIgckpH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "\n",
        "# loading the y dataset for model development\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "\n",
        "# split dataset as training and test dataset as ratio of 8:2\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ACC_collecton = []\n",
        "CNN_channel = [16,32,64,128,256]\n",
        "dense_node = [32,64,128,256,512,1024,2048,4096,8192]\n",
        "kernel_size = [3,6,9,12]\n",
        "stride_size = [1,2,4,8]\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        inputShape=(1280,1) # input feature size\n",
        "        input = Input(inputShape)\n",
        "        x = Conv1D(CNN_channel[i],(kernel_size[k]),strides = (stride_size[l]),name='layer_conv2',padding='same')(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(dense_node[j],activation = 'relu',name='fc1')(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "        model = Model(inputs = input,outputs = x,name='Predict')\n",
        "        # define SGD optimizer\n",
        "        momentum = 0.5\n",
        "        sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "        # compile the model\n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "        # learning deccay setting\n",
        "        import math\n",
        "        def step_decay(epoch): # gradually decrease the learning rate\n",
        "            initial_lrate=0.1\n",
        "            drop=0.6\n",
        "            epochs_drop = 3.0\n",
        "            lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "                  math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "            return lrate\n",
        "        lr = LearningRateScheduler(step_decay)\n",
        "        # early stop setting\n",
        "        early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "        # set checkpoint and save the best model\n",
        "        mc = ModelCheckpoint('best_model_grid_1280.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "        # summary the callbacks_list\n",
        "        callbacks_list = [ lr , early_stop, mc]\n",
        "        model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=0)\n",
        "        # load the save best model\n",
        "        saved_model = load_model('best_model_grid_1280.h5')\n",
        "        # result collection list\n",
        "        # confusion matrix\n",
        "        predicted_class= []\n",
        "        predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "        for p in range(predicted_protability.shape[0]):\n",
        "          index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "          predicted_class.append(index)\n",
        "        predicted_class = np.array(predicted_class)\n",
        "        y_true = y_test\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        import math\n",
        "        # np.ravel() return a flatten 1D array\n",
        "        TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "        ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "        ACC_collecton.append(ACC)\n",
        "        print(ACC)\n",
        "        del model\n",
        "        import torch\n",
        "        import gc\n",
        "        torch.cuda.memory_reserved()\n",
        "        gc.collect()\n",
        "import collections\n",
        "model_parameters =collections.defaultdict(list)\n",
        "a=0\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        iter_num = str(a)\n",
        "        model_parameters[iter_num].append(CNN_channel[i])\n",
        "        model_parameters[iter_num].append(dense_node[j])\n",
        "        model_parameters[iter_num].append(kernel_size[k])\n",
        "        model_parameters[iter_num].append(stride_size[l])\n",
        "        model_parameters[iter_num].append(ACC_collecton[a])\n",
        "        a=a+1\n",
        "# export the DataFrame to an Excel file\n",
        "pd.DataFrame(model_parameters).to_excel('1280_grid_performance output.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8q0KSsR_Ymz"
      },
      "source": [
        "### 2560 feature dimension embedding test\n",
        "Due to the enourmous computational needs and also the limitted performance improivement, we do not test the 128 and 256 fileter size with 8196 units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk1v0R7hCRFI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "\n",
        "# loading the y dataset for model development\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t36_3B_UR50D_unified_2560_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "\n",
        "# split dataset as training and test dataset as ratio of 8:2\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ACC_collecton = []\n",
        "CNN_channel = [16,32,64,128,256] #\n",
        "dense_node = [32,64,128,256,512,1024,2048,4096]\n",
        "kernel_size = [3,6,9,12]\n",
        "stride_size = [1,2,4,8]\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        inputShape=(2560,1) # input feature size\n",
        "        input = Input(inputShape)\n",
        "        x = Conv1D(CNN_channel[i],(kernel_size[k]),strides = (stride_size[l]),name='layer_conv2',padding='same')(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(dense_node[j],activation = 'relu',name='fc1')(x)\n",
        "        x = Dropout(0.15)(x)\n",
        "        x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "        model = Model(inputs = input,outputs = x,name='Predict')\n",
        "        # define SGD optimizer\n",
        "        momentum = 0.5\n",
        "        sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "        # compile the model\n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "        # learning deccay setting\n",
        "        import math\n",
        "        def step_decay(epoch): # gradually decrease the learning rate\n",
        "            initial_lrate=0.1\n",
        "            drop=0.6\n",
        "            epochs_drop = 3.0\n",
        "            lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "                  math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "            return lrate\n",
        "        lr = LearningRateScheduler(step_decay)\n",
        "        # early stop setting\n",
        "        early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "        # set checkpoint and save the best model\n",
        "        mc = ModelCheckpoint('best_model_grid_2560.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "        # summary the callbacks_list\n",
        "        callbacks_list = [ lr , early_stop, mc]\n",
        "        model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=0)\n",
        "        # load the save best model\n",
        "        saved_model = load_model('best_model_grid_2560.h5')\n",
        "        # result collection list\n",
        "        # confusion matrix\n",
        "        predicted_class= []\n",
        "        predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "        for p in range(predicted_protability.shape[0]):\n",
        "          index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "          predicted_class.append(index)\n",
        "        predicted_class = np.array(predicted_class)\n",
        "        y_true = y_test\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        import math\n",
        "        # np.ravel() return a flatten 1D array\n",
        "        TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "        ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "        ACC_collecton.append(ACC)\n",
        "        print(ACC)\n",
        "        del model\n",
        "        import torch\n",
        "        import gc\n",
        "        torch.cuda.memory_reserved()\n",
        "        gc.collect()\n",
        "import collections\n",
        "model_parameters =collections.defaultdict(list)\n",
        "a=0\n",
        "for i in range(len(CNN_channel)):\n",
        "  for j in range(len(dense_node)):\n",
        "    for k in range(len(kernel_size)):\n",
        "      for l in range(len(stride_size)):\n",
        "        iter_num = str(a)\n",
        "        model_parameters[iter_num].append(CNN_channel[i])\n",
        "        model_parameters[iter_num].append(dense_node[j])\n",
        "        model_parameters[iter_num].append(kernel_size[k])\n",
        "        model_parameters[iter_num].append(stride_size[l])\n",
        "        model_parameters[iter_num].append(ACC_collecton[a])\n",
        "        a=a+1\n",
        "# export the DataFrame to an Excel file\n",
        "pd.DataFrame(model_parameters).to_excel('2560_grid_performance output.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkgD_C1RDwWh"
      },
      "source": [
        "## 5-Fold cross validation and gather all the training dataset to generate the final model, evaluate the performance on test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAMCI-1F5DsR"
      },
      "source": [
        "### 320 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Phr-fdR3zm"
      },
      "source": [
        "#### defined function for model development and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8E_6SxF3vwb"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, X_valid, y_train, y_valid, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(320,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "  # set checkpoint and save the best model\n",
        "  mc = ModelCheckpoint('best_model_grid_320.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lr , early_stop, mc]\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  saved_model = load_model('best_model_grid_320.h5')\n",
        "  return saved_model\n",
        "\n",
        "  # import gc\n",
        "  # del model\n",
        "  # del saved_model\n",
        "  # import torch\n",
        "  # import gc\n",
        "  # torch.cuda.memory_reserved()\n",
        "  # gc.collect()\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0apTBCCEpEhR"
      },
      "source": [
        "#### 5 Fold CV for optimal hyperparrameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg-5R9IUWm8B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKtovTsbpEhR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "random_num = 1\n",
        "X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjSfBNFLpEhR",
        "outputId": "2d47d779-88b3-4ca2-c306-9d8b5c163950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26 26 26 26\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [32, 64, 16, 32, 32, 16, 16, 32, 32, 32, 128, 64, 32, 32, 64, 64, 128, 32, 64, 16, 128, 32, 16, 32, 32, 32]\n",
        "dense_node = [32, 32, 64, 64, 128, 128, 256, 256, 512, 512, 8192, 4096, 8192, 4096, 4096, 4096, 4096, 4096, 8192, 1024, 2048, 2048, 2048, 1024, 512, 512]\n",
        "kernel_size = [9, 6, 1, 6, 12, 12, 12, 3, 3, 9, 3, 12, 9, 6, 12, 12, 12, 12, 12, 9, 12, 12, 6, 6, 3, 12]\n",
        "stride_size = [1, 4, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 4, 4, 1, 2, 1, 8, 1, 1, 1, 1, 2]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mAnx181Wost"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drT4biERpEhS",
        "outputId": "72ded40b-e58a-4567-88fc-7e3b53675df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "241/241 [==============================] - 3s 5ms/step - loss: 0.8909 - accuracy: 0.6176 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.6765 - accuracy: 0.5960"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6630 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6631 - accuracy: 0.6229 - val_loss: 0.6631 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6633 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6627 - accuracy: 0.6229 - val_loss: 0.6639 - val_accuracy: 0.6232 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6630 - accuracy: 0.6229 - val_loss: 0.6627 - val_accuracy: 0.6232 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6440 - accuracy: 0.6456 - val_loss: 0.5433 - val_accuracy: 0.7637 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.7596 - val_loss: 0.4831 - val_accuracy: 0.7859 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.7997 - val_loss: 0.4231 - val_accuracy: 0.8194 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.4291 - accuracy: 0.8211 - val_loss: 0.3262 - val_accuracy: 0.8836 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.4048 - accuracy: 0.8360 - val_loss: 0.3322 - val_accuracy: 0.8673 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3938 - accuracy: 0.8425 - val_loss: 0.3339 - val_accuracy: 0.8673 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8455 - val_loss: 0.3014 - val_accuracy: 0.8930 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.8533 - val_loss: 0.3157 - val_accuracy: 0.8813 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8561 - val_loss: 0.2972 - val_accuracy: 0.8918 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8540 - val_loss: 0.3082 - val_accuracy: 0.8859 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3799 - accuracy: 0.8539 - val_loss: 0.2913 - val_accuracy: 0.8926 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8536 - val_loss: 0.2886 - val_accuracy: 0.8945 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8565 - val_loss: 0.3100 - val_accuracy: 0.8844 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3565 - accuracy: 0.8649 - val_loss: 0.3030 - val_accuracy: 0.8883 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8579 - val_loss: 0.2929 - val_accuracy: 0.8930 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3710 - accuracy: 0.8562 - val_loss: 0.2941 - val_accuracy: 0.8918 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3535 - accuracy: 0.8652 - val_loss: 0.2895 - val_accuracy: 0.8945 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3771 - accuracy: 0.8553 - val_loss: 0.2875 - val_accuracy: 0.8949 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3539 - accuracy: 0.8638 - val_loss: 0.2831 - val_accuracy: 0.9019 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8618 - val_loss: 0.2836 - val_accuracy: 0.8961 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8638 - val_loss: 0.2841 - val_accuracy: 0.8949 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3594 - accuracy: 0.8647 - val_loss: 0.2881 - val_accuracy: 0.8945 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.8612 - val_loss: 0.2837 - val_accuracy: 0.8949 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8665 - val_loss: 0.2863 - val_accuracy: 0.8945 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3622 - accuracy: 0.8630 - val_loss: 0.2954 - val_accuracy: 0.8937 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3530 - accuracy: 0.8678 - val_loss: 0.2844 - val_accuracy: 0.8961 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3676 - accuracy: 0.8592 - val_loss: 0.2854 - val_accuracy: 0.8945 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3601 - accuracy: 0.8629 - val_loss: 0.2851 - val_accuracy: 0.8949 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8632 - val_loss: 0.2848 - val_accuracy: 0.8953 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3679 - accuracy: 0.8596 - val_loss: 0.2854 - val_accuracy: 0.8953 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3593 - accuracy: 0.8635 - val_loss: 0.2844 - val_accuracy: 0.8949 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8661 - val_loss: 0.2842 - val_accuracy: 0.8953 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3528 - accuracy: 0.8680 - val_loss: 0.2855 - val_accuracy: 0.8953 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8648 - val_loss: 0.2851 - val_accuracy: 0.8953 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3614 - accuracy: 0.8631 - val_loss: 0.2847 - val_accuracy: 0.8961 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8648 - val_loss: 0.2849 - val_accuracy: 0.8953 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.8640 - val_loss: 0.2845 - val_accuracy: 0.8957 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3648 - accuracy: 0.8625 - val_loss: 0.2856 - val_accuracy: 0.8957 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8604 - val_loss: 0.2854 - val_accuracy: 0.8957 - lr: 4.7018e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9054474708171206 0.9096496619545175 0.8981972428419936 0.7994796053524201 0.9039234523982556 0.9607579805522007\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6352 - accuracy: 0.8012 - val_loss: 0.3078 - val_accuracy: 0.8665 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.3477 - accuracy: 0.8459"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3079 - accuracy: 0.8657 - val_loss: 0.2541 - val_accuracy: 0.8907 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2709 - accuracy: 0.8836 - val_loss: 0.2603 - val_accuracy: 0.8856 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2541 - accuracy: 0.8926 - val_loss: 0.2341 - val_accuracy: 0.8953 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2456 - accuracy: 0.8944 - val_loss: 0.2856 - val_accuracy: 0.8786 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.9067 - val_loss: 0.2321 - val_accuracy: 0.8961 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2163 - accuracy: 0.9066 - val_loss: 0.2169 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9083 - val_loss: 0.2341 - val_accuracy: 0.8949 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9133 - val_loss: 0.2141 - val_accuracy: 0.9070 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9141 - val_loss: 0.2110 - val_accuracy: 0.9058 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9198 - val_loss: 0.2156 - val_accuracy: 0.9051 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1895 - accuracy: 0.9198 - val_loss: 0.2115 - val_accuracy: 0.9078 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9190 - val_loss: 0.2059 - val_accuracy: 0.9089 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9229 - val_loss: 0.2043 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1757 - accuracy: 0.9281 - val_loss: 0.2069 - val_accuracy: 0.9105 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1810 - accuracy: 0.9238 - val_loss: 0.2070 - val_accuracy: 0.9109 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1775 - accuracy: 0.9279 - val_loss: 0.2064 - val_accuracy: 0.9136 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1755 - accuracy: 0.9279 - val_loss: 0.2045 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1733 - accuracy: 0.9307 - val_loss: 0.2042 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9290 - val_loss: 0.2055 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9284 - val_loss: 0.2036 - val_accuracy: 0.9101 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9316 - val_loss: 0.2050 - val_accuracy: 0.9105 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1682 - accuracy: 0.9289 - val_loss: 0.2058 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9280 - val_loss: 0.2044 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9279 - val_loss: 0.2039 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9327 - val_loss: 0.2038 - val_accuracy: 0.9093 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1672 - accuracy: 0.9311 - val_loss: 0.2042 - val_accuracy: 0.9101 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9273 - val_loss: 0.2043 - val_accuracy: 0.9101 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.9340 - val_loss: 0.2039 - val_accuracy: 0.9093 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1670 - accuracy: 0.9293 - val_loss: 0.2035 - val_accuracy: 0.9097 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9316 - val_loss: 0.2041 - val_accuracy: 0.9097 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1669 - accuracy: 0.9302 - val_loss: 0.2036 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9312 - val_loss: 0.2033 - val_accuracy: 0.9097 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1642 - accuracy: 0.9318 - val_loss: 0.2032 - val_accuracy: 0.9109 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9307 - val_loss: 0.2032 - val_accuracy: 0.9101 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9319 - val_loss: 0.2033 - val_accuracy: 0.9097 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9310 - val_loss: 0.2033 - val_accuracy: 0.9097 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9108602569093033 0.9585687382297552 0.8329918032786885 0.8098025571464812 0.8957802707542218 0.9676974313852613\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6712 - accuracy: 0.6972 - val_loss: 0.4892 - val_accuracy: 0.7568 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 45/241 [====>.........................] - ETA: 0s - loss: 0.4685 - accuracy: 0.7993"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.4490 - accuracy: 0.8094 - val_loss: 0.3379 - val_accuracy: 0.8778 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3596 - accuracy: 0.8588 - val_loss: 0.2740 - val_accuracy: 0.8953 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3169 - accuracy: 0.8684 - val_loss: 0.3238 - val_accuracy: 0.8471 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2860 - accuracy: 0.8847 - val_loss: 0.2382 - val_accuracy: 0.9054 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2592 - accuracy: 0.8945 - val_loss: 0.2434 - val_accuracy: 0.8864 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2534 - accuracy: 0.8913 - val_loss: 0.2250 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2507 - accuracy: 0.8959 - val_loss: 0.2245 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2343 - accuracy: 0.9045 - val_loss: 0.2227 - val_accuracy: 0.9039 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2343 - accuracy: 0.9061 - val_loss: 0.2219 - val_accuracy: 0.9031 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2284 - accuracy: 0.9063 - val_loss: 0.2257 - val_accuracy: 0.9043 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9064 - val_loss: 0.2172 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9155 - val_loss: 0.2322 - val_accuracy: 0.9062 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2155 - accuracy: 0.9149 - val_loss: 0.2193 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9153 - val_loss: 0.2231 - val_accuracy: 0.9086 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9162 - val_loss: 0.2172 - val_accuracy: 0.9086 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9158 - val_loss: 0.2211 - val_accuracy: 0.9078 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9161 - val_loss: 0.2173 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9185 - val_loss: 0.2254 - val_accuracy: 0.9089 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2055 - accuracy: 0.9181 - val_loss: 0.2181 - val_accuracy: 0.9086 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2041 - accuracy: 0.9193 - val_loss: 0.2204 - val_accuracy: 0.9062 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9181 - val_loss: 0.2223 - val_accuracy: 0.9031 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1975 - accuracy: 0.9196 - val_loss: 0.2221 - val_accuracy: 0.9043 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9209 - val_loss: 0.2181 - val_accuracy: 0.9140 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2184 - val_accuracy: 0.9093 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9207 - val_loss: 0.2183 - val_accuracy: 0.9093 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9233 - val_loss: 0.2174 - val_accuracy: 0.9105 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1997 - accuracy: 0.9221 - val_loss: 0.2188 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1990 - accuracy: 0.9172 - val_loss: 0.2182 - val_accuracy: 0.9121 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1993 - accuracy: 0.9206 - val_loss: 0.2169 - val_accuracy: 0.9105 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9238 - val_loss: 0.2179 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9207 - val_loss: 0.2174 - val_accuracy: 0.9128 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9219 - val_loss: 0.2172 - val_accuracy: 0.9113 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9193 - val_loss: 0.2174 - val_accuracy: 0.9117 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2011 - accuracy: 0.9172 - val_loss: 0.2177 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9211 - val_loss: 0.2177 - val_accuracy: 0.9121 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9206 - val_loss: 0.2176 - val_accuracy: 0.9125 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9223 - val_loss: 0.2175 - val_accuracy: 0.9121 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9228 - val_loss: 0.2177 - val_accuracy: 0.9125 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9216 - val_loss: 0.2178 - val_accuracy: 0.9117 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9196 - val_loss: 0.2176 - val_accuracy: 0.9117 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1919 - accuracy: 0.9237 - val_loss: 0.2178 - val_accuracy: 0.9128 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9220 - val_loss: 0.2177 - val_accuracy: 0.9128 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1997 - accuracy: 0.9192 - val_loss: 0.2178 - val_accuracy: 0.9121 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9050214091086025 0.951702786377709 0.8259958071278826 0.794887182761615 0.8888492967527958 0.9651232224104471\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5965 - accuracy: 0.8020 - val_loss: 0.3826 - val_accuracy: 0.8595 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 45/241 [====>.........................] - ETA: 0s - loss: 0.3226 - accuracy: 0.8528"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3067 - accuracy: 0.8571 - val_loss: 0.2524 - val_accuracy: 0.8879 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2687 - accuracy: 0.8780 - val_loss: 0.3077 - val_accuracy: 0.8568 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2537 - accuracy: 0.8817 - val_loss: 0.2314 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.8901 - val_loss: 0.2254 - val_accuracy: 0.8981 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2293 - accuracy: 0.8985 - val_loss: 0.2349 - val_accuracy: 0.8914 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2261 - accuracy: 0.9001 - val_loss: 0.2167 - val_accuracy: 0.8992 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9037 - val_loss: 0.2229 - val_accuracy: 0.9035 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9088 - val_loss: 0.2089 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9070 - val_loss: 0.2123 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9122 - val_loss: 0.2066 - val_accuracy: 0.9101 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1968 - accuracy: 0.9135 - val_loss: 0.2093 - val_accuracy: 0.9058 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1944 - accuracy: 0.9138 - val_loss: 0.2075 - val_accuracy: 0.9105 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1898 - accuracy: 0.9176 - val_loss: 0.2169 - val_accuracy: 0.9031 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1861 - accuracy: 0.9198 - val_loss: 0.2053 - val_accuracy: 0.9093 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1890 - accuracy: 0.9162 - val_loss: 0.2073 - val_accuracy: 0.9086 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1793 - accuracy: 0.9206 - val_loss: 0.2060 - val_accuracy: 0.9105 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9183 - val_loss: 0.2033 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1751 - accuracy: 0.9251 - val_loss: 0.2023 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9220 - val_loss: 0.2035 - val_accuracy: 0.9089 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1746 - accuracy: 0.9232 - val_loss: 0.2035 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1733 - accuracy: 0.9246 - val_loss: 0.2022 - val_accuracy: 0.9086 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1702 - accuracy: 0.9266 - val_loss: 0.2017 - val_accuracy: 0.9113 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9249 - val_loss: 0.2028 - val_accuracy: 0.9109 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1729 - accuracy: 0.9236 - val_loss: 0.2018 - val_accuracy: 0.9109 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9268 - val_loss: 0.2022 - val_accuracy: 0.9089 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1652 - accuracy: 0.9290 - val_loss: 0.2027 - val_accuracy: 0.9105 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1693 - accuracy: 0.9253 - val_loss: 0.2017 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9266 - val_loss: 0.2020 - val_accuracy: 0.9105 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9232 - val_loss: 0.2020 - val_accuracy: 0.9105 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9247 - val_loss: 0.2017 - val_accuracy: 0.9089 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9289 - val_loss: 0.2021 - val_accuracy: 0.9101 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9268 - val_loss: 0.2022 - val_accuracy: 0.9097 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9254 - val_loss: 0.2018 - val_accuracy: 0.9101 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1682 - accuracy: 0.9279 - val_loss: 0.2017 - val_accuracy: 0.9101 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1688 - accuracy: 0.9249 - val_loss: 0.2019 - val_accuracy: 0.9105 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9236 - val_loss: 0.2019 - val_accuracy: 0.9109 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9275 - val_loss: 0.2020 - val_accuracy: 0.9101 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9284 - val_loss: 0.2018 - val_accuracy: 0.9101 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9244842351109381 0.9280843149411035 0.9184100418410042 0.8401111055905539 0.9232471783910539 0.9776038437693738\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6793 - accuracy: 0.7719 - val_loss: 0.3278 - val_accuracy: 0.8767 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.3756 - accuracy: 0.8244"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3417 - accuracy: 0.8372 - val_loss: 0.2685 - val_accuracy: 0.8786 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3016 - accuracy: 0.8587 - val_loss: 0.2418 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2897 - accuracy: 0.8623 - val_loss: 0.2464 - val_accuracy: 0.8946 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.8719 - val_loss: 0.2397 - val_accuracy: 0.8957 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2605 - accuracy: 0.8765 - val_loss: 0.2391 - val_accuracy: 0.9008 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.8823 - val_loss: 0.2276 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2488 - accuracy: 0.8837 - val_loss: 0.2209 - val_accuracy: 0.9054 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2291 - accuracy: 0.8884 - val_loss: 0.2226 - val_accuracy: 0.9008 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2250 - accuracy: 0.8882 - val_loss: 0.2303 - val_accuracy: 0.8957 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2247 - accuracy: 0.8875 - val_loss: 0.2171 - val_accuracy: 0.9019 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.8933 - val_loss: 0.2222 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2097 - accuracy: 0.9011 - val_loss: 0.2158 - val_accuracy: 0.9043 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9005 - val_loss: 0.2123 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9085 - val_loss: 0.2093 - val_accuracy: 0.9109 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9045 - val_loss: 0.2089 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9085 - val_loss: 0.2090 - val_accuracy: 0.9171 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9061 - val_loss: 0.2086 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1986 - accuracy: 0.9083 - val_loss: 0.2083 - val_accuracy: 0.9140 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9132 - val_loss: 0.2087 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9077 - val_loss: 0.2094 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1946 - accuracy: 0.9120 - val_loss: 0.2108 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9111 - val_loss: 0.2074 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1950 - accuracy: 0.9079 - val_loss: 0.2071 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9093 - val_loss: 0.2059 - val_accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1899 - accuracy: 0.9120 - val_loss: 0.2064 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9136 - val_loss: 0.2079 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1892 - accuracy: 0.9135 - val_loss: 0.2066 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1875 - accuracy: 0.9129 - val_loss: 0.2063 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9124 - val_loss: 0.2063 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1903 - accuracy: 0.9124 - val_loss: 0.2064 - val_accuracy: 0.9175 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1879 - accuracy: 0.9154 - val_loss: 0.2063 - val_accuracy: 0.9175 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1890 - accuracy: 0.9132 - val_loss: 0.2060 - val_accuracy: 0.9156 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9166 - val_loss: 0.2062 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9132 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1885 - accuracy: 0.9107 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1885 - accuracy: 0.9132 - val_loss: 0.2061 - val_accuracy: 0.9160 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9141 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9146 - val_loss: 0.2063 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9096 - val_loss: 0.2062 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9122 - val_loss: 0.2062 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9158 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9116 - val_loss: 0.2061 - val_accuracy: 0.9163 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1897 - accuracy: 0.9145 - val_loss: 0.2062 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9132 - val_loss: 0.2062 - val_accuracy: 0.9171 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9110 - val_loss: 0.2061 - val_accuracy: 0.9167 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1820 - accuracy: 0.9183 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9107 - val_loss: 0.2061 - val_accuracy: 0.9163 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.905799922148696 0.9215686274509803 0.8805668016194332 0.8012326435695987 0.9010677145352068 0.9691189914649416\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4869 - accuracy: 0.7828 - val_loss: 0.4502 - val_accuracy: 0.8244 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 44/241 [====>.........................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8594"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8482 - val_loss: 0.3176 - val_accuracy: 0.8634 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2910 - accuracy: 0.8766 - val_loss: 0.2437 - val_accuracy: 0.8930 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.8802 - val_loss: 0.2395 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2676 - accuracy: 0.8858 - val_loss: 0.2318 - val_accuracy: 0.8984 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.8919 - val_loss: 0.2393 - val_accuracy: 0.8848 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.8971 - val_loss: 0.2321 - val_accuracy: 0.9019 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2457 - accuracy: 0.8993 - val_loss: 0.2224 - val_accuracy: 0.9004 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2357 - accuracy: 0.9010 - val_loss: 0.2211 - val_accuracy: 0.8996 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2280 - accuracy: 0.9028 - val_loss: 0.2191 - val_accuracy: 0.9031 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2290 - accuracy: 0.9066 - val_loss: 0.2194 - val_accuracy: 0.9031 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2163 - accuracy: 0.9128 - val_loss: 0.2262 - val_accuracy: 0.8926 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2185 - accuracy: 0.9090 - val_loss: 0.2223 - val_accuracy: 0.8988 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2194 - accuracy: 0.9080 - val_loss: 0.2236 - val_accuracy: 0.8961 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9100 - val_loss: 0.2164 - val_accuracy: 0.9007 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2117 - accuracy: 0.9125 - val_loss: 0.2184 - val_accuracy: 0.8968 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9145 - val_loss: 0.2150 - val_accuracy: 0.9054 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9122 - val_loss: 0.2142 - val_accuracy: 0.9058 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9157 - val_loss: 0.2131 - val_accuracy: 0.9062 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9167 - val_loss: 0.2119 - val_accuracy: 0.9066 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9151 - val_loss: 0.2147 - val_accuracy: 0.9019 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9176 - val_loss: 0.2131 - val_accuracy: 0.9054 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9189 - val_loss: 0.2139 - val_accuracy: 0.9035 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9168 - val_loss: 0.2123 - val_accuracy: 0.9058 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9199 - val_loss: 0.2138 - val_accuracy: 0.9027 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.9194 - val_loss: 0.2132 - val_accuracy: 0.9050 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9173 - val_loss: 0.2135 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9190 - val_loss: 0.2134 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9214 - val_loss: 0.2123 - val_accuracy: 0.9054 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1988 - accuracy: 0.9209 - val_loss: 0.2124 - val_accuracy: 0.9058 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1986 - accuracy: 0.9196 - val_loss: 0.2129 - val_accuracy: 0.9046 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9164 - val_loss: 0.2123 - val_accuracy: 0.9046 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9215 - val_loss: 0.2124 - val_accuracy: 0.9058 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.9209 - val_loss: 0.2127 - val_accuracy: 0.9050 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1998 - accuracy: 0.9186 - val_loss: 0.2124 - val_accuracy: 0.9050 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9175 - val_loss: 0.2125 - val_accuracy: 0.9062 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9167 - val_loss: 0.2128 - val_accuracy: 0.9031 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9210 - val_loss: 0.2125 - val_accuracy: 0.9046 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1940 - accuracy: 0.9207 - val_loss: 0.2125 - val_accuracy: 0.9062 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9188 - val_loss: 0.2125 - val_accuracy: 0.9054 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9132295719844358 0.9348494161032576 0.8759278897136797 0.8128048791499867 0.9053886529084687 0.9753591468465926\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5372 - accuracy: 0.7639 - val_loss: 0.6323 - val_accuracy: 0.5891 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 44/241 [====>.........................] - ETA: 0s - loss: 0.3097 - accuracy: 0.8501"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.8609 - val_loss: 0.2941 - val_accuracy: 0.8903 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2742 - accuracy: 0.8863 - val_loss: 0.2421 - val_accuracy: 0.8918 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.8888 - val_loss: 0.2301 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2512 - accuracy: 0.8924 - val_loss: 0.2405 - val_accuracy: 0.8973 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2384 - accuracy: 0.9000 - val_loss: 0.2237 - val_accuracy: 0.9058 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.9007 - val_loss: 0.2208 - val_accuracy: 0.9004 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2306 - accuracy: 0.8998 - val_loss: 0.2196 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2271 - accuracy: 0.9071 - val_loss: 0.2179 - val_accuracy: 0.9109 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9114 - val_loss: 0.2170 - val_accuracy: 0.9105 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9097 - val_loss: 0.2130 - val_accuracy: 0.9140 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9072 - val_loss: 0.2132 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9118 - val_loss: 0.2115 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9146 - val_loss: 0.2124 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9148 - val_loss: 0.2129 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9114 - val_loss: 0.2113 - val_accuracy: 0.9105 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9125 - val_loss: 0.2104 - val_accuracy: 0.9140 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9127 - val_loss: 0.2107 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9167 - val_loss: 0.2097 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9128 - val_loss: 0.2089 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.9166 - val_loss: 0.2095 - val_accuracy: 0.9156 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9133 - val_loss: 0.2101 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9164 - val_loss: 0.2102 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1979 - accuracy: 0.9153 - val_loss: 0.2098 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9179 - val_loss: 0.2097 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1977 - accuracy: 0.9136 - val_loss: 0.2101 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1931 - accuracy: 0.9164 - val_loss: 0.2100 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9164 - val_loss: 0.2095 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9161 - val_loss: 0.2097 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9150 - val_loss: 0.2091 - val_accuracy: 0.9163 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1948 - accuracy: 0.9161 - val_loss: 0.2091 - val_accuracy: 0.9152 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1942 - accuracy: 0.9185 - val_loss: 0.2090 - val_accuracy: 0.9160 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9185 - val_loss: 0.2089 - val_accuracy: 0.9163 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1960 - accuracy: 0.9170 - val_loss: 0.2089 - val_accuracy: 0.9163 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9186 - val_loss: 0.2091 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9181 - val_loss: 0.2093 - val_accuracy: 0.9163 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9211 - val_loss: 0.2094 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9167 - val_loss: 0.2093 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1979 - accuracy: 0.9163 - val_loss: 0.2093 - val_accuracy: 0.9163 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9148 - val_loss: 0.2092 - val_accuracy: 0.9163 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1921 - accuracy: 0.9181 - val_loss: 0.2092 - val_accuracy: 0.9160 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.9184 - val_loss: 0.2092 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1940 - accuracy: 0.9176 - val_loss: 0.2092 - val_accuracy: 0.9160 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1902 - accuracy: 0.9189 - val_loss: 0.2092 - val_accuracy: 0.9160 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1940 - accuracy: 0.9163 - val_loss: 0.2093 - val_accuracy: 0.9163 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9065784351887894 0.9196484620213434 0.8852459016393442 0.8024167766995679 0.9024471818303439 0.9664248942607515\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5689 - accuracy: 0.7494 - val_loss: 0.5047 - val_accuracy: 0.8284 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 41/241 [====>.........................] - ETA: 0s - loss: 0.3786 - accuracy: 0.8148"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8417 - val_loss: 0.2786 - val_accuracy: 0.8856 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2865 - accuracy: 0.8700 - val_loss: 0.3219 - val_accuracy: 0.8802 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2809 - accuracy: 0.8762 - val_loss: 0.2395 - val_accuracy: 0.9008 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2671 - accuracy: 0.8889 - val_loss: 0.2742 - val_accuracy: 0.8844 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2567 - accuracy: 0.8862 - val_loss: 0.2418 - val_accuracy: 0.8996 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2467 - accuracy: 0.8904 - val_loss: 0.2308 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2421 - accuracy: 0.8902 - val_loss: 0.2353 - val_accuracy: 0.8969 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2380 - accuracy: 0.8945 - val_loss: 0.2278 - val_accuracy: 0.8988 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.8963 - val_loss: 0.2347 - val_accuracy: 0.8949 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2348 - accuracy: 0.8965 - val_loss: 0.2204 - val_accuracy: 0.9101 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9041 - val_loss: 0.2177 - val_accuracy: 0.9101 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2200 - accuracy: 0.9037 - val_loss: 0.2194 - val_accuracy: 0.9086 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9067 - val_loss: 0.2171 - val_accuracy: 0.9035 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2099 - accuracy: 0.9072 - val_loss: 0.2155 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9068 - val_loss: 0.2156 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9085 - val_loss: 0.2175 - val_accuracy: 0.9121 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9097 - val_loss: 0.2194 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9110 - val_loss: 0.2171 - val_accuracy: 0.9148 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9097 - val_loss: 0.2183 - val_accuracy: 0.9089 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9100 - val_loss: 0.2127 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9116 - val_loss: 0.2134 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1985 - accuracy: 0.9138 - val_loss: 0.2127 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9133 - val_loss: 0.2148 - val_accuracy: 0.9156 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.9171 - val_loss: 0.2151 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2013 - accuracy: 0.9118 - val_loss: 0.2131 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1984 - accuracy: 0.9122 - val_loss: 0.2133 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1984 - accuracy: 0.9120 - val_loss: 0.2135 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1973 - accuracy: 0.9150 - val_loss: 0.2128 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9120 - val_loss: 0.2138 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9097 - val_loss: 0.2135 - val_accuracy: 0.9163 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1950 - accuracy: 0.9137 - val_loss: 0.2135 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1967 - accuracy: 0.9129 - val_loss: 0.2133 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1924 - accuracy: 0.9155 - val_loss: 0.2135 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1969 - accuracy: 0.9135 - val_loss: 0.2135 - val_accuracy: 0.9175 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9162 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9116 - val_loss: 0.2132 - val_accuracy: 0.9171 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1975 - accuracy: 0.9123 - val_loss: 0.2132 - val_accuracy: 0.9171 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1963 - accuracy: 0.9103 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9131 - val_loss: 0.2130 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1966 - accuracy: 0.9102 - val_loss: 0.2131 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1979 - accuracy: 0.9124 - val_loss: 0.2131 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1951 - accuracy: 0.9120 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9155 - val_loss: 0.2133 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1952 - accuracy: 0.9133 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1968 - accuracy: 0.9166 - val_loss: 0.2131 - val_accuracy: 0.9167 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9116 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9137 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1934 - accuracy: 0.9129 - val_loss: 0.2131 - val_accuracy: 0.9167 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9110 - val_loss: 0.2131 - val_accuracy: 0.9167 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1997 - accuracy: 0.9119 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1927 - accuracy: 0.9146 - val_loss: 0.2131 - val_accuracy: 0.9167 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1952 - accuracy: 0.9162 - val_loss: 0.2130 - val_accuracy: 0.9167 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9087 - val_loss: 0.2132 - val_accuracy: 0.9167 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9133 - val_loss: 0.2131 - val_accuracy: 0.9167 - lr: 1.0156e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9046321525885559 0.9139318885448916 0.8888888888888888 0.7974752960722103 0.9014103887168903 0.9643635077334475\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5636 - accuracy: 0.7831 - val_loss: 0.4940 - val_accuracy: 0.7210 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 38/241 [===>..........................] - ETA: 0s - loss: 0.3523 - accuracy: 0.8306"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3152 - accuracy: 0.8596 - val_loss: 0.2680 - val_accuracy: 0.8829 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.8857 - val_loss: 0.2411 - val_accuracy: 0.8973 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2587 - accuracy: 0.8906 - val_loss: 0.2415 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.8902 - val_loss: 0.2290 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2394 - accuracy: 0.9018 - val_loss: 0.2256 - val_accuracy: 0.9023 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2354 - accuracy: 0.9016 - val_loss: 0.2209 - val_accuracy: 0.9051 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2295 - accuracy: 0.9032 - val_loss: 0.2224 - val_accuracy: 0.9012 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9089 - val_loss: 0.2186 - val_accuracy: 0.9047 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9122 - val_loss: 0.2121 - val_accuracy: 0.9109 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9106 - val_loss: 0.2122 - val_accuracy: 0.9074 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9133 - val_loss: 0.2173 - val_accuracy: 0.9058 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9120 - val_loss: 0.2159 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2033 - accuracy: 0.9170 - val_loss: 0.2129 - val_accuracy: 0.9062 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1990 - accuracy: 0.9155 - val_loss: 0.2144 - val_accuracy: 0.9109 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9159 - val_loss: 0.2116 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9203 - val_loss: 0.2123 - val_accuracy: 0.9101 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9218 - val_loss: 0.2115 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1911 - accuracy: 0.9220 - val_loss: 0.2118 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1963 - accuracy: 0.9199 - val_loss: 0.2109 - val_accuracy: 0.9105 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1888 - accuracy: 0.9211 - val_loss: 0.2110 - val_accuracy: 0.9105 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1907 - accuracy: 0.9215 - val_loss: 0.2101 - val_accuracy: 0.9121 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1906 - accuracy: 0.9211 - val_loss: 0.2127 - val_accuracy: 0.9113 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1897 - accuracy: 0.9231 - val_loss: 0.2108 - val_accuracy: 0.9113 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9280 - val_loss: 0.2121 - val_accuracy: 0.9121 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9251 - val_loss: 0.2109 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9212 - val_loss: 0.2112 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1901 - accuracy: 0.9224 - val_loss: 0.2108 - val_accuracy: 0.9117 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1913 - accuracy: 0.9209 - val_loss: 0.2108 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9251 - val_loss: 0.2109 - val_accuracy: 0.9105 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.9244 - val_loss: 0.2109 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1897 - accuracy: 0.9216 - val_loss: 0.2115 - val_accuracy: 0.9109 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1860 - accuracy: 0.9262 - val_loss: 0.2112 - val_accuracy: 0.9105 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1830 - accuracy: 0.9288 - val_loss: 0.2111 - val_accuracy: 0.9109 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9244 - val_loss: 0.2111 - val_accuracy: 0.9105 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9238 - val_loss: 0.2109 - val_accuracy: 0.9109 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1840 - accuracy: 0.9236 - val_loss: 0.2112 - val_accuracy: 0.9101 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1838 - accuracy: 0.9241 - val_loss: 0.2115 - val_accuracy: 0.9101 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9260 - val_loss: 0.2113 - val_accuracy: 0.9105 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1855 - accuracy: 0.9240 - val_loss: 0.2113 - val_accuracy: 0.9109 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9244 - val_loss: 0.2113 - val_accuracy: 0.9105 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1841 - accuracy: 0.9255 - val_loss: 0.2113 - val_accuracy: 0.9101 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1866 - accuracy: 0.9221 - val_loss: 0.2113 - val_accuracy: 0.9105 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1886 - accuracy: 0.9219 - val_loss: 0.2112 - val_accuracy: 0.9105 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1837 - accuracy: 0.9262 - val_loss: 0.2113 - val_accuracy: 0.9109 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1862 - accuracy: 0.9266 - val_loss: 0.2113 - val_accuracy: 0.9105 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9174776177500973 0.9485430874147551 0.8650627615062761 0.8222735161240978 0.9068029244605156 0.9769355679663405\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5299 - accuracy: 0.7581 - val_loss: 0.4516 - val_accuracy: 0.8615 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 40/241 [===>..........................] - ETA: 0s - loss: 0.3595 - accuracy: 0.8172"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8405 - val_loss: 0.2665 - val_accuracy: 0.8844 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2736 - accuracy: 0.8718 - val_loss: 0.2431 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2676 - accuracy: 0.8778 - val_loss: 0.2264 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2608 - accuracy: 0.8763 - val_loss: 0.2770 - val_accuracy: 0.8821 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2445 - accuracy: 0.8853 - val_loss: 0.2216 - val_accuracy: 0.9043 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2356 - accuracy: 0.8895 - val_loss: 0.2191 - val_accuracy: 0.8996 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2376 - accuracy: 0.8882 - val_loss: 0.2166 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.8975 - val_loss: 0.2176 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2168 - accuracy: 0.8965 - val_loss: 0.2105 - val_accuracy: 0.9027 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2165 - accuracy: 0.9013 - val_loss: 0.2137 - val_accuracy: 0.9000 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9020 - val_loss: 0.2075 - val_accuracy: 0.9070 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.8996 - val_loss: 0.2102 - val_accuracy: 0.9093 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9026 - val_loss: 0.2061 - val_accuracy: 0.9125 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9066 - val_loss: 0.2081 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9055 - val_loss: 0.2062 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9055 - val_loss: 0.2089 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9070 - val_loss: 0.2067 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9045 - val_loss: 0.2072 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1984 - accuracy: 0.9092 - val_loss: 0.2064 - val_accuracy: 0.9113 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9096 - val_loss: 0.2078 - val_accuracy: 0.9128 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9036 - val_loss: 0.2057 - val_accuracy: 0.9132 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9057 - val_loss: 0.2055 - val_accuracy: 0.9128 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9101 - val_loss: 0.2059 - val_accuracy: 0.9128 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1956 - accuracy: 0.9080 - val_loss: 0.2053 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9120 - val_loss: 0.2057 - val_accuracy: 0.9128 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9109 - val_loss: 0.2048 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1932 - accuracy: 0.9122 - val_loss: 0.2051 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9084 - val_loss: 0.2055 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.9074 - val_loss: 0.2046 - val_accuracy: 0.9140 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1919 - accuracy: 0.9149 - val_loss: 0.2047 - val_accuracy: 0.9125 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1950 - accuracy: 0.9076 - val_loss: 0.2047 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1920 - accuracy: 0.9080 - val_loss: 0.2051 - val_accuracy: 0.9121 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9101 - val_loss: 0.2051 - val_accuracy: 0.9140 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1954 - accuracy: 0.9100 - val_loss: 0.2049 - val_accuracy: 0.9121 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9089 - val_loss: 0.2047 - val_accuracy: 0.9132 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9105 - val_loss: 0.2051 - val_accuracy: 0.9136 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9124 - val_loss: 0.2052 - val_accuracy: 0.9125 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1867 - accuracy: 0.9122 - val_loss: 0.2052 - val_accuracy: 0.9125 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.9110 - val_loss: 0.2051 - val_accuracy: 0.9125 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1897 - accuracy: 0.9118 - val_loss: 0.2049 - val_accuracy: 0.9121 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9128 - val_loss: 0.2050 - val_accuracy: 0.9121 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1911 - accuracy: 0.9105 - val_loss: 0.2049 - val_accuracy: 0.9117 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1890 - accuracy: 0.9102 - val_loss: 0.2048 - val_accuracy: 0.9113 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9110 - val_loss: 0.2048 - val_accuracy: 0.9117 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1927 - accuracy: 0.9096 - val_loss: 0.2048 - val_accuracy: 0.9121 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1910 - accuracy: 0.9116 - val_loss: 0.2049 - val_accuracy: 0.9125 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1913 - accuracy: 0.9122 - val_loss: 0.2049 - val_accuracy: 0.9125 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1901 - accuracy: 0.9066 - val_loss: 0.2049 - val_accuracy: 0.9125 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9034643830284157 0.9323213156230234 0.8572874493927125 0.7950527006324751 0.894804382507868 0.9695498416161555\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 3s 6ms/step - loss: 0.5425 - accuracy: 0.7574 - val_loss: 0.4025 - val_accuracy: 0.8206 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.3537 - accuracy: 0.8372"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3548 - accuracy: 0.8355 - val_loss: 0.3144 - val_accuracy: 0.8669 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3144 - accuracy: 0.8625 - val_loss: 0.2814 - val_accuracy: 0.8778 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2949 - accuracy: 0.8730 - val_loss: 0.2827 - val_accuracy: 0.8766 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2925 - accuracy: 0.8702 - val_loss: 0.2723 - val_accuracy: 0.8840 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2690 - accuracy: 0.8810 - val_loss: 0.2580 - val_accuracy: 0.8891 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2654 - accuracy: 0.8869 - val_loss: 0.2626 - val_accuracy: 0.8879 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2590 - accuracy: 0.8845 - val_loss: 0.2467 - val_accuracy: 0.8910 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.8957 - val_loss: 0.2482 - val_accuracy: 0.8891 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2471 - accuracy: 0.8941 - val_loss: 0.2401 - val_accuracy: 0.8972 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.8950 - val_loss: 0.2419 - val_accuracy: 0.8957 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.8972 - val_loss: 0.2403 - val_accuracy: 0.8937 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2360 - accuracy: 0.8961 - val_loss: 0.2377 - val_accuracy: 0.8965 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2370 - accuracy: 0.8980 - val_loss: 0.2371 - val_accuracy: 0.8957 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2310 - accuracy: 0.9029 - val_loss: 0.2380 - val_accuracy: 0.8972 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.8979 - val_loss: 0.2353 - val_accuracy: 0.8957 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2265 - accuracy: 0.9016 - val_loss: 0.2345 - val_accuracy: 0.9004 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.9031 - val_loss: 0.2354 - val_accuracy: 0.8957 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2267 - accuracy: 0.9004 - val_loss: 0.2342 - val_accuracy: 0.8976 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.8981 - val_loss: 0.2334 - val_accuracy: 0.8980 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2228 - accuracy: 0.9041 - val_loss: 0.2336 - val_accuracy: 0.8961 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9061 - val_loss: 0.2335 - val_accuracy: 0.8984 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2262 - accuracy: 0.9044 - val_loss: 0.2321 - val_accuracy: 0.8968 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9074 - val_loss: 0.2325 - val_accuracy: 0.8972 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2196 - accuracy: 0.9081 - val_loss: 0.2318 - val_accuracy: 0.8980 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2237 - accuracy: 0.9040 - val_loss: 0.2325 - val_accuracy: 0.8988 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2245 - accuracy: 0.9070 - val_loss: 0.2322 - val_accuracy: 0.8980 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9068 - val_loss: 0.2325 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9059 - val_loss: 0.2323 - val_accuracy: 0.8980 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9070 - val_loss: 0.2322 - val_accuracy: 0.8984 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.9054 - val_loss: 0.2318 - val_accuracy: 0.8988 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.9071 - val_loss: 0.2318 - val_accuracy: 0.9000 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9072 - val_loss: 0.2317 - val_accuracy: 0.8996 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2227 - accuracy: 0.9075 - val_loss: 0.2318 - val_accuracy: 0.9000 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9111 - val_loss: 0.2318 - val_accuracy: 0.9000 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2200 - accuracy: 0.9064 - val_loss: 0.2318 - val_accuracy: 0.9004 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9053 - val_loss: 0.2318 - val_accuracy: 0.9000 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9007782101167315 0.9237861094038107 0.8610816542948038 0.7861079065416744 0.8924338818493072 0.9674012439865186\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5700 - accuracy: 0.7712 - val_loss: 0.3976 - val_accuracy: 0.8265 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.3389 - accuracy: 0.8430"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8429 - val_loss: 0.2972 - val_accuracy: 0.8751 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2960 - accuracy: 0.8684 - val_loss: 0.2630 - val_accuracy: 0.8829 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2828 - accuracy: 0.8721 - val_loss: 0.2531 - val_accuracy: 0.8918 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.8870 - val_loss: 0.2512 - val_accuracy: 0.8911 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.8852 - val_loss: 0.2416 - val_accuracy: 0.9000 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2501 - accuracy: 0.8924 - val_loss: 0.2432 - val_accuracy: 0.8946 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2433 - accuracy: 0.8989 - val_loss: 0.2371 - val_accuracy: 0.8957 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2312 - accuracy: 0.9020 - val_loss: 0.2343 - val_accuracy: 0.9000 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.8998 - val_loss: 0.2349 - val_accuracy: 0.8930 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2314 - accuracy: 0.9002 - val_loss: 0.2345 - val_accuracy: 0.8984 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9028 - val_loss: 0.2298 - val_accuracy: 0.8988 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2197 - accuracy: 0.9049 - val_loss: 0.2281 - val_accuracy: 0.9027 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.9061 - val_loss: 0.2304 - val_accuracy: 0.9012 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2177 - accuracy: 0.9068 - val_loss: 0.2288 - val_accuracy: 0.9019 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9083 - val_loss: 0.2274 - val_accuracy: 0.9035 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9085 - val_loss: 0.2268 - val_accuracy: 0.9039 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9088 - val_loss: 0.2263 - val_accuracy: 0.9019 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9120 - val_loss: 0.2278 - val_accuracy: 0.9012 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2113 - accuracy: 0.9115 - val_loss: 0.2257 - val_accuracy: 0.9027 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9116 - val_loss: 0.2264 - val_accuracy: 0.9019 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9116 - val_loss: 0.2267 - val_accuracy: 0.9008 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2079 - accuracy: 0.9123 - val_loss: 0.2250 - val_accuracy: 0.9023 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9111 - val_loss: 0.2258 - val_accuracy: 0.9023 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2082 - accuracy: 0.9103 - val_loss: 0.2250 - val_accuracy: 0.9019 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9135 - val_loss: 0.2252 - val_accuracy: 0.9035 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2093 - accuracy: 0.9124 - val_loss: 0.2250 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9141 - val_loss: 0.2251 - val_accuracy: 0.9019 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9140 - val_loss: 0.2250 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.9077 - val_loss: 0.2251 - val_accuracy: 0.9023 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9135 - val_loss: 0.2249 - val_accuracy: 0.9035 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9116 - val_loss: 0.2248 - val_accuracy: 0.9023 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9128 - val_loss: 0.2247 - val_accuracy: 0.9035 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9150 - val_loss: 0.2247 - val_accuracy: 0.9035 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9149 - val_loss: 0.2246 - val_accuracy: 0.9031 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9141 - val_loss: 0.2246 - val_accuracy: 0.9035 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9128 - val_loss: 0.2247 - val_accuracy: 0.9039 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.897625535227715 0.9271814187068425 0.8493852459016393 0.7816325268920913 0.888283332304241 0.9606774129645066\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4991 - accuracy: 0.7648 - val_loss: 0.4110 - val_accuracy: 0.8187 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8490"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8535 - val_loss: 0.2972 - val_accuracy: 0.8529 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3014 - accuracy: 0.8719 - val_loss: 0.2756 - val_accuracy: 0.8837 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2834 - accuracy: 0.8767 - val_loss: 0.2602 - val_accuracy: 0.8903 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2679 - accuracy: 0.8830 - val_loss: 0.2617 - val_accuracy: 0.8918 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2587 - accuracy: 0.8872 - val_loss: 0.2505 - val_accuracy: 0.8899 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2441 - accuracy: 0.8943 - val_loss: 0.2446 - val_accuracy: 0.8957 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2450 - accuracy: 0.8966 - val_loss: 0.2514 - val_accuracy: 0.8911 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2329 - accuracy: 0.8992 - val_loss: 0.2368 - val_accuracy: 0.8996 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2320 - accuracy: 0.8985 - val_loss: 0.2367 - val_accuracy: 0.9004 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9011 - val_loss: 0.2350 - val_accuracy: 0.8992 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2209 - accuracy: 0.9011 - val_loss: 0.2323 - val_accuracy: 0.9008 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2201 - accuracy: 0.9009 - val_loss: 0.2354 - val_accuracy: 0.9047 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9007 - val_loss: 0.2344 - val_accuracy: 0.9031 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9055 - val_loss: 0.2339 - val_accuracy: 0.9008 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2133 - accuracy: 0.9094 - val_loss: 0.2332 - val_accuracy: 0.9031 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9085 - val_loss: 0.2326 - val_accuracy: 0.9039 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9105 - val_loss: 0.2324 - val_accuracy: 0.9043 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9090 - val_loss: 0.2317 - val_accuracy: 0.9023 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9101 - val_loss: 0.2310 - val_accuracy: 0.9043 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9107 - val_loss: 0.2311 - val_accuracy: 0.9031 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9094 - val_loss: 0.2313 - val_accuracy: 0.9035 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9097 - val_loss: 0.2319 - val_accuracy: 0.9016 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2099 - accuracy: 0.9098 - val_loss: 0.2313 - val_accuracy: 0.9019 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9123 - val_loss: 0.2308 - val_accuracy: 0.9035 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9116 - val_loss: 0.2312 - val_accuracy: 0.9019 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9133 - val_loss: 0.2309 - val_accuracy: 0.9035 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9094 - val_loss: 0.2307 - val_accuracy: 0.9047 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9146 - val_loss: 0.2304 - val_accuracy: 0.9039 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9132 - val_loss: 0.2302 - val_accuracy: 0.9047 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9146 - val_loss: 0.2303 - val_accuracy: 0.9047 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9120 - val_loss: 0.2303 - val_accuracy: 0.9035 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9105 - val_loss: 0.2303 - val_accuracy: 0.9043 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.897625535227715 0.9312693498452013 0.8406708595387841 0.7792531366246813 0.8859701046919927 0.958290982728742\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6108 - accuracy: 0.7563 - val_loss: 0.4078 - val_accuracy: 0.7891 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8387"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8417 - val_loss: 0.3096 - val_accuracy: 0.8677 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3123 - accuracy: 0.8591 - val_loss: 0.2902 - val_accuracy: 0.8747 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2960 - accuracy: 0.8702 - val_loss: 0.2846 - val_accuracy: 0.8770 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2834 - accuracy: 0.8743 - val_loss: 0.2780 - val_accuracy: 0.8802 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.8786 - val_loss: 0.2658 - val_accuracy: 0.8860 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2628 - accuracy: 0.8839 - val_loss: 0.2569 - val_accuracy: 0.8891 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2618 - accuracy: 0.8835 - val_loss: 0.2742 - val_accuracy: 0.8813 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2556 - accuracy: 0.8854 - val_loss: 0.2599 - val_accuracy: 0.8875 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2514 - accuracy: 0.8926 - val_loss: 0.2506 - val_accuracy: 0.8907 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2491 - accuracy: 0.8914 - val_loss: 0.2534 - val_accuracy: 0.8938 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2453 - accuracy: 0.8949 - val_loss: 0.2513 - val_accuracy: 0.8922 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2446 - accuracy: 0.8939 - val_loss: 0.2492 - val_accuracy: 0.8965 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2418 - accuracy: 0.8955 - val_loss: 0.2531 - val_accuracy: 0.8946 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2389 - accuracy: 0.8949 - val_loss: 0.2488 - val_accuracy: 0.8957 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.8957 - val_loss: 0.2479 - val_accuracy: 0.8961 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2360 - accuracy: 0.8970 - val_loss: 0.2492 - val_accuracy: 0.8946 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.8993 - val_loss: 0.2467 - val_accuracy: 0.8973 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2386 - accuracy: 0.8948 - val_loss: 0.2461 - val_accuracy: 0.8977 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2367 - accuracy: 0.8998 - val_loss: 0.2474 - val_accuracy: 0.8957 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.8950 - val_loss: 0.2457 - val_accuracy: 0.8973 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2339 - accuracy: 0.8949 - val_loss: 0.2456 - val_accuracy: 0.8957 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2306 - accuracy: 0.9009 - val_loss: 0.2459 - val_accuracy: 0.8965 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2284 - accuracy: 0.9035 - val_loss: 0.2459 - val_accuracy: 0.8969 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9042 - val_loss: 0.2476 - val_accuracy: 0.8957 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2261 - accuracy: 0.9024 - val_loss: 0.2465 - val_accuracy: 0.8988 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2264 - accuracy: 0.9022 - val_loss: 0.2463 - val_accuracy: 0.8973 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2299 - accuracy: 0.9006 - val_loss: 0.2459 - val_accuracy: 0.8984 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9004 - val_loss: 0.2455 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2300 - accuracy: 0.8993 - val_loss: 0.2456 - val_accuracy: 0.8973 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9031 - val_loss: 0.2454 - val_accuracy: 0.8977 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9055 - val_loss: 0.2455 - val_accuracy: 0.8981 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2300 - accuracy: 0.9026 - val_loss: 0.2453 - val_accuracy: 0.8977 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9014 - val_loss: 0.2453 - val_accuracy: 0.8977 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2246 - accuracy: 0.9005 - val_loss: 0.2454 - val_accuracy: 0.8973 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9013 - val_loss: 0.2454 - val_accuracy: 0.8973 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2261 - accuracy: 0.9033 - val_loss: 0.2454 - val_accuracy: 0.8977 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2254 - accuracy: 0.9014 - val_loss: 0.2454 - val_accuracy: 0.8981 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2279 - accuracy: 0.9001 - val_loss: 0.2454 - val_accuracy: 0.8977 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9002 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2272 - accuracy: 0.9041 - val_loss: 0.2453 - val_accuracy: 0.8984 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2295 - accuracy: 0.9019 - val_loss: 0.2453 - val_accuracy: 0.8988 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2265 - accuracy: 0.9026 - val_loss: 0.2453 - val_accuracy: 0.8984 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2300 - accuracy: 0.9037 - val_loss: 0.2453 - val_accuracy: 0.8984 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2286 - accuracy: 0.9015 - val_loss: 0.2453 - val_accuracy: 0.8988 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2267 - accuracy: 0.9035 - val_loss: 0.2453 - val_accuracy: 0.8992 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2248 - accuracy: 0.9032 - val_loss: 0.2454 - val_accuracy: 0.8992 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2248 - accuracy: 0.9062 - val_loss: 0.2453 - val_accuracy: 0.8988 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9018 - val_loss: 0.2453 - val_accuracy: 0.8988 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9016 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9013 - val_loss: 0.2453 - val_accuracy: 0.8977 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2294 - accuracy: 0.9004 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2275 - accuracy: 0.9016 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2285 - accuracy: 0.8998 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2282 - accuracy: 0.9002 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9066 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9018 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.9029 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2303 - accuracy: 0.9019 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.9005 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9015 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2251 - accuracy: 0.9024 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2280 - accuracy: 0.9020 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9010 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2254 - accuracy: 0.9011 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2255 - accuracy: 0.9066 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 1.3162e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9077462047489295 0.9336639801611903 0.8640167364016736 0.8017569839454514 0.8988403582814319 0.9687385702464547\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4721 - accuracy: 0.8003 - val_loss: 0.4207 - val_accuracy: 0.8331 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.3159 - accuracy: 0.8564"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3274 - accuracy: 0.8574 - val_loss: 0.3064 - val_accuracy: 0.8782 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2946 - accuracy: 0.8717 - val_loss: 0.2643 - val_accuracy: 0.8856 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2855 - accuracy: 0.8773 - val_loss: 0.2560 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.8798 - val_loss: 0.2523 - val_accuracy: 0.8981 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.8876 - val_loss: 0.2539 - val_accuracy: 0.8918 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2550 - accuracy: 0.8926 - val_loss: 0.2401 - val_accuracy: 0.8965 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2485 - accuracy: 0.8949 - val_loss: 0.2355 - val_accuracy: 0.8942 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2414 - accuracy: 0.8970 - val_loss: 0.2341 - val_accuracy: 0.8922 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2388 - accuracy: 0.8968 - val_loss: 0.2328 - val_accuracy: 0.8988 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2333 - accuracy: 0.9002 - val_loss: 0.2342 - val_accuracy: 0.8996 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2282 - accuracy: 0.9036 - val_loss: 0.2329 - val_accuracy: 0.8977 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2284 - accuracy: 0.9011 - val_loss: 0.2296 - val_accuracy: 0.8981 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2231 - accuracy: 0.9076 - val_loss: 0.2288 - val_accuracy: 0.8996 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2212 - accuracy: 0.9080 - val_loss: 0.2292 - val_accuracy: 0.9008 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2246 - accuracy: 0.9066 - val_loss: 0.2269 - val_accuracy: 0.9008 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9050 - val_loss: 0.2250 - val_accuracy: 0.9023 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2221 - accuracy: 0.9062 - val_loss: 0.2253 - val_accuracy: 0.8996 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9068 - val_loss: 0.2237 - val_accuracy: 0.9023 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9111 - val_loss: 0.2245 - val_accuracy: 0.9012 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2159 - accuracy: 0.9105 - val_loss: 0.2256 - val_accuracy: 0.9004 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9093 - val_loss: 0.2240 - val_accuracy: 0.9004 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9110 - val_loss: 0.2235 - val_accuracy: 0.9016 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9094 - val_loss: 0.2240 - val_accuracy: 0.9016 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2174 - accuracy: 0.9066 - val_loss: 0.2237 - val_accuracy: 0.9000 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9072 - val_loss: 0.2231 - val_accuracy: 0.9012 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9096 - val_loss: 0.2232 - val_accuracy: 0.8996 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9103 - val_loss: 0.2231 - val_accuracy: 0.9012 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.9114 - val_loss: 0.2234 - val_accuracy: 0.9008 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2169 - accuracy: 0.9081 - val_loss: 0.2235 - val_accuracy: 0.9019 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9120 - val_loss: 0.2236 - val_accuracy: 0.9023 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2153 - accuracy: 0.9115 - val_loss: 0.2235 - val_accuracy: 0.9019 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2183 - accuracy: 0.9080 - val_loss: 0.2233 - val_accuracy: 0.9019 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.9116 - val_loss: 0.2233 - val_accuracy: 0.9016 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9110 - val_loss: 0.2232 - val_accuracy: 0.9019 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9114 - val_loss: 0.2232 - val_accuracy: 0.9019 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9103 - val_loss: 0.2232 - val_accuracy: 0.9023 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9042428960685092 0.9190385831752056 0.8805668016194332 0.7981173542963206 0.8998026923973195 0.9652835928677336\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.9738 - accuracy: 0.6322 - val_loss: 0.6629 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 40/241 [===>..........................] - ETA: 0s - loss: 0.6636 - accuracy: 0.6227"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6452 - accuracy: 0.6455 - val_loss: 0.6659 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6620 - accuracy: 0.6248 - val_loss: 0.6560 - val_accuracy: 0.6322 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.6825 - val_loss: 0.5426 - val_accuracy: 0.7326 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5090 - accuracy: 0.7677 - val_loss: 0.3750 - val_accuracy: 0.8517 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.8134 - val_loss: 0.6388 - val_accuracy: 0.7482 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8355 - val_loss: 0.2927 - val_accuracy: 0.8871 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8418 - val_loss: 0.3058 - val_accuracy: 0.8680 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3222 - accuracy: 0.8565 - val_loss: 0.2603 - val_accuracy: 0.8965 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.8568 - val_loss: 0.2568 - val_accuracy: 0.8910 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3069 - accuracy: 0.8654 - val_loss: 0.2539 - val_accuracy: 0.8871 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3008 - accuracy: 0.8639 - val_loss: 0.2666 - val_accuracy: 0.8797 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3009 - accuracy: 0.8664 - val_loss: 0.2486 - val_accuracy: 0.8914 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.8629 - val_loss: 0.2749 - val_accuracy: 0.8727 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2949 - accuracy: 0.8639 - val_loss: 0.2457 - val_accuracy: 0.8949 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.8674 - val_loss: 0.2427 - val_accuracy: 0.8941 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2883 - accuracy: 0.8717 - val_loss: 0.2439 - val_accuracy: 0.8961 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.8669 - val_loss: 0.2387 - val_accuracy: 0.8980 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.8763 - val_loss: 0.2433 - val_accuracy: 0.8930 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.8718 - val_loss: 0.2413 - val_accuracy: 0.8965 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.8731 - val_loss: 0.2389 - val_accuracy: 0.8984 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.8770 - val_loss: 0.2391 - val_accuracy: 0.8957 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2739 - accuracy: 0.8770 - val_loss: 0.2381 - val_accuracy: 0.8980 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2756 - accuracy: 0.8734 - val_loss: 0.2412 - val_accuracy: 0.8949 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.8776 - val_loss: 0.2402 - val_accuracy: 0.8930 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2765 - accuracy: 0.8747 - val_loss: 0.2377 - val_accuracy: 0.8961 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2686 - accuracy: 0.8784 - val_loss: 0.2380 - val_accuracy: 0.8976 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2711 - accuracy: 0.8783 - val_loss: 0.2373 - val_accuracy: 0.8957 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.8738 - val_loss: 0.2391 - val_accuracy: 0.8945 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.8792 - val_loss: 0.2373 - val_accuracy: 0.8965 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2727 - accuracy: 0.8796 - val_loss: 0.2369 - val_accuracy: 0.8976 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2698 - accuracy: 0.8774 - val_loss: 0.2362 - val_accuracy: 0.8980 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2726 - accuracy: 0.8763 - val_loss: 0.2381 - val_accuracy: 0.8945 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2708 - accuracy: 0.8793 - val_loss: 0.2369 - val_accuracy: 0.8972 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.8766 - val_loss: 0.2371 - val_accuracy: 0.8961 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2708 - accuracy: 0.8786 - val_loss: 0.2370 - val_accuracy: 0.8965 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2709 - accuracy: 0.8758 - val_loss: 0.2369 - val_accuracy: 0.8965 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2750 - accuracy: 0.8722 - val_loss: 0.2371 - val_accuracy: 0.8965 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2702 - accuracy: 0.8779 - val_loss: 0.2371 - val_accuracy: 0.8961 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.8806 - val_loss: 0.2369 - val_accuracy: 0.8965 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.8797 - val_loss: 0.2366 - val_accuracy: 0.8965 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9070038910505837 0.931161647203442 0.865323435843054 0.7992206653733088 0.898242541523248 0.9667703213468896\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 1.1543 - accuracy: 0.6228 - val_loss: 0.6611 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.6631 - accuracy: 0.6235"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6616 - accuracy: 0.6259 - val_loss: 0.6607 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6435 - accuracy: 0.6479 - val_loss: 0.5815 - val_accuracy: 0.7097 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6046 - accuracy: 0.6855 - val_loss: 0.5712 - val_accuracy: 0.7148 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5797 - accuracy: 0.7084 - val_loss: 0.4834 - val_accuracy: 0.7778 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.7808 - val_loss: 0.3519 - val_accuracy: 0.8416 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8272 - val_loss: 0.3382 - val_accuracy: 0.8346 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.8484 - val_loss: 0.2791 - val_accuracy: 0.8774 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8660 - val_loss: 0.2986 - val_accuracy: 0.8611 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3054 - accuracy: 0.8679 - val_loss: 0.2576 - val_accuracy: 0.8907 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2971 - accuracy: 0.8704 - val_loss: 0.2554 - val_accuracy: 0.8926 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.8796 - val_loss: 0.2533 - val_accuracy: 0.8899 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2845 - accuracy: 0.8806 - val_loss: 0.2473 - val_accuracy: 0.8946 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2803 - accuracy: 0.8791 - val_loss: 0.2469 - val_accuracy: 0.8907 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.8843 - val_loss: 0.2453 - val_accuracy: 0.8981 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2651 - accuracy: 0.8865 - val_loss: 0.2437 - val_accuracy: 0.8911 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2581 - accuracy: 0.8901 - val_loss: 0.2441 - val_accuracy: 0.8973 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2569 - accuracy: 0.8880 - val_loss: 0.2404 - val_accuracy: 0.8988 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2576 - accuracy: 0.8862 - val_loss: 0.2356 - val_accuracy: 0.9012 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2555 - accuracy: 0.8887 - val_loss: 0.2357 - val_accuracy: 0.8981 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.8930 - val_loss: 0.2336 - val_accuracy: 0.9008 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2502 - accuracy: 0.8919 - val_loss: 0.2333 - val_accuracy: 0.9023 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2553 - accuracy: 0.8882 - val_loss: 0.2314 - val_accuracy: 0.9016 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2452 - accuracy: 0.8950 - val_loss: 0.2319 - val_accuracy: 0.9039 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.8961 - val_loss: 0.2311 - val_accuracy: 0.9035 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2440 - accuracy: 0.8961 - val_loss: 0.2317 - val_accuracy: 0.9004 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.8941 - val_loss: 0.2315 - val_accuracy: 0.8996 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2493 - accuracy: 0.8913 - val_loss: 0.2304 - val_accuracy: 0.9051 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2455 - accuracy: 0.8927 - val_loss: 0.2301 - val_accuracy: 0.9051 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2409 - accuracy: 0.8979 - val_loss: 0.2294 - val_accuracy: 0.9054 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.8992 - val_loss: 0.2288 - val_accuracy: 0.9062 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2404 - accuracy: 0.8957 - val_loss: 0.2286 - val_accuracy: 0.9047 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.8946 - val_loss: 0.2286 - val_accuracy: 0.9058 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2447 - accuracy: 0.8941 - val_loss: 0.2286 - val_accuracy: 0.9043 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2410 - accuracy: 0.8953 - val_loss: 0.2286 - val_accuracy: 0.9047 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2451 - accuracy: 0.8919 - val_loss: 0.2283 - val_accuracy: 0.9054 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.8927 - val_loss: 0.2285 - val_accuracy: 0.9051 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2429 - accuracy: 0.8949 - val_loss: 0.2284 - val_accuracy: 0.9051 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2437 - accuracy: 0.8988 - val_loss: 0.2282 - val_accuracy: 0.9051 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2424 - accuracy: 0.8945 - val_loss: 0.2283 - val_accuracy: 0.9054 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2405 - accuracy: 0.8945 - val_loss: 0.2282 - val_accuracy: 0.9051 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2426 - accuracy: 0.8922 - val_loss: 0.2284 - val_accuracy: 0.9047 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2383 - accuracy: 0.8966 - val_loss: 0.2283 - val_accuracy: 0.9047 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.8976 - val_loss: 0.2283 - val_accuracy: 0.9051 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2431 - accuracy: 0.8933 - val_loss: 0.2283 - val_accuracy: 0.9047 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.8937 - val_loss: 0.2283 - val_accuracy: 0.9051 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2425 - accuracy: 0.8949 - val_loss: 0.2283 - val_accuracy: 0.9051 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.8939 - val_loss: 0.2283 - val_accuracy: 0.9054 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2437 - accuracy: 0.8939 - val_loss: 0.2283 - val_accuracy: 0.9054 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2453 - accuracy: 0.8957 - val_loss: 0.2282 - val_accuracy: 0.9051 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.8927 - val_loss: 0.2283 - val_accuracy: 0.9051 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9015181004281821 0.9416195856873822 0.8360655737704918 0.7894063626546353 0.888842579728937 0.9605931560207053\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6792 - accuracy: 0.8011 - val_loss: 0.3247 - val_accuracy: 0.8794 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8576"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2982 - accuracy: 0.8636 - val_loss: 0.2884 - val_accuracy: 0.8875 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2588 - accuracy: 0.8887 - val_loss: 0.2291 - val_accuracy: 0.9004 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2431 - accuracy: 0.8940 - val_loss: 0.2643 - val_accuracy: 0.8829 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2315 - accuracy: 0.8937 - val_loss: 0.2267 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2176 - accuracy: 0.9036 - val_loss: 0.2210 - val_accuracy: 0.9043 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9075 - val_loss: 0.2219 - val_accuracy: 0.9054 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2049 - accuracy: 0.9118 - val_loss: 0.2209 - val_accuracy: 0.9082 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1946 - accuracy: 0.9120 - val_loss: 0.2159 - val_accuracy: 0.9062 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1951 - accuracy: 0.9170 - val_loss: 0.2115 - val_accuracy: 0.9093 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1830 - accuracy: 0.9219 - val_loss: 0.2191 - val_accuracy: 0.9113 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1821 - accuracy: 0.9228 - val_loss: 0.2091 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1771 - accuracy: 0.9276 - val_loss: 0.2086 - val_accuracy: 0.9078 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1732 - accuracy: 0.9257 - val_loss: 0.2049 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1699 - accuracy: 0.9302 - val_loss: 0.2099 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1655 - accuracy: 0.9289 - val_loss: 0.2031 - val_accuracy: 0.9136 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9307 - val_loss: 0.2041 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9333 - val_loss: 0.2026 - val_accuracy: 0.9156 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9268 - val_loss: 0.2058 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9324 - val_loss: 0.2039 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9363 - val_loss: 0.2042 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1594 - accuracy: 0.9307 - val_loss: 0.2028 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1592 - accuracy: 0.9345 - val_loss: 0.2046 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.9353 - val_loss: 0.2041 - val_accuracy: 0.9140 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1578 - accuracy: 0.9338 - val_loss: 0.2039 - val_accuracy: 0.9156 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9320 - val_loss: 0.2046 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1586 - accuracy: 0.9358 - val_loss: 0.2053 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.9342 - val_loss: 0.2049 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9359 - val_loss: 0.2048 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9342 - val_loss: 0.2040 - val_accuracy: 0.9140 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1554 - accuracy: 0.9341 - val_loss: 0.2042 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1545 - accuracy: 0.9366 - val_loss: 0.2043 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1541 - accuracy: 0.9347 - val_loss: 0.2041 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9360 - val_loss: 0.2034 - val_accuracy: 0.9156 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.9371 - val_loss: 0.2034 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1540 - accuracy: 0.9355 - val_loss: 0.2038 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.9323 - val_loss: 0.2034 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9358 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1562 - accuracy: 0.9337 - val_loss: 0.2033 - val_accuracy: 0.9144 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1578 - accuracy: 0.9318 - val_loss: 0.2030 - val_accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9376 - val_loss: 0.2031 - val_accuracy: 0.9156 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9320 - val_loss: 0.2030 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9376 - val_loss: 0.2031 - val_accuracy: 0.9144 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1571 - accuracy: 0.9341 - val_loss: 0.2031 - val_accuracy: 0.9144 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1544 - accuracy: 0.9360 - val_loss: 0.2031 - val_accuracy: 0.9148 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1548 - accuracy: 0.9384 - val_loss: 0.2032 - val_accuracy: 0.9144 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9327 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9112495134293499 0.9486068111455108 0.8480083857442348 0.8084628705625054 0.8983075984448727 0.9685651420449014\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5218 - accuracy: 0.8203 - val_loss: 0.3445 - val_accuracy: 0.8665 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.2560 - accuracy: 0.8874"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2844 - accuracy: 0.8730 - val_loss: 0.2625 - val_accuracy: 0.8930 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2508 - accuracy: 0.8939 - val_loss: 0.2242 - val_accuracy: 0.9051 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2359 - accuracy: 0.8954 - val_loss: 0.2187 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9019 - val_loss: 0.2140 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9075 - val_loss: 0.2128 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9076 - val_loss: 0.2089 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1998 - accuracy: 0.9146 - val_loss: 0.2102 - val_accuracy: 0.9031 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1868 - accuracy: 0.9188 - val_loss: 0.2120 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1839 - accuracy: 0.9221 - val_loss: 0.2021 - val_accuracy: 0.9105 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.9197 - val_loss: 0.2058 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9267 - val_loss: 0.2048 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1699 - accuracy: 0.9273 - val_loss: 0.2061 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9279 - val_loss: 0.2059 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1609 - accuracy: 0.9341 - val_loss: 0.2039 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9307 - val_loss: 0.2045 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9318 - val_loss: 0.2008 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1581 - accuracy: 0.9312 - val_loss: 0.2047 - val_accuracy: 0.9121 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9351 - val_loss: 0.2047 - val_accuracy: 0.9113 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1548 - accuracy: 0.9366 - val_loss: 0.2047 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9386 - val_loss: 0.2052 - val_accuracy: 0.9121 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1554 - accuracy: 0.9355 - val_loss: 0.2020 - val_accuracy: 0.9121 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1501 - accuracy: 0.9377 - val_loss: 0.2025 - val_accuracy: 0.9121 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1511 - accuracy: 0.9364 - val_loss: 0.2029 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9401 - val_loss: 0.2034 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1509 - accuracy: 0.9411 - val_loss: 0.2034 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9394 - val_loss: 0.2028 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1487 - accuracy: 0.9404 - val_loss: 0.2027 - val_accuracy: 0.9121 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1495 - accuracy: 0.9384 - val_loss: 0.2037 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1467 - accuracy: 0.9415 - val_loss: 0.2030 - val_accuracy: 0.9140 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9395 - val_loss: 0.2036 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9384 - val_loss: 0.2033 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1453 - accuracy: 0.9411 - val_loss: 0.2035 - val_accuracy: 0.9144 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9377 - val_loss: 0.2031 - val_accuracy: 0.9140 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9403 - val_loss: 0.2035 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9426 - val_loss: 0.2035 - val_accuracy: 0.9152 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.9420 - val_loss: 0.2035 - val_accuracy: 0.9148 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.9411 - val_loss: 0.2035 - val_accuracy: 0.9148 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1487 - accuracy: 0.9377 - val_loss: 0.2033 - val_accuracy: 0.9152 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1433 - accuracy: 0.9416 - val_loss: 0.2033 - val_accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9399 - val_loss: 0.2035 - val_accuracy: 0.9152 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9415 - val_loss: 0.2035 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1451 - accuracy: 0.9408 - val_loss: 0.2035 - val_accuracy: 0.9148 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1492 - accuracy: 0.9391 - val_loss: 0.2033 - val_accuracy: 0.9148 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9424 - val_loss: 0.2033 - val_accuracy: 0.9152 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1485 - accuracy: 0.9420 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9366 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9389 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9397 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1453 - accuracy: 0.9415 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1451 - accuracy: 0.9429 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9386 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9397 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9382 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1452 - accuracy: 0.9410 - val_loss: 0.2031 - val_accuracy: 0.9148 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1474 - accuracy: 0.9421 - val_loss: 0.2033 - val_accuracy: 0.9148 - lr: 1.0156e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.927209030751265 0.9380037197768134 0.9089958158995816 0.8447095850760837 0.9234997678381975 0.9776385383404192\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.8281 - accuracy: 0.7858 - val_loss: 0.3649 - val_accuracy: 0.8160 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.3224 - accuracy: 0.8519"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3086 - accuracy: 0.8645 - val_loss: 0.2571 - val_accuracy: 0.8942 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2708 - accuracy: 0.8871 - val_loss: 0.2467 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.8959 - val_loss: 0.2619 - val_accuracy: 0.8755 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2411 - accuracy: 0.8981 - val_loss: 0.2312 - val_accuracy: 0.9031 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2246 - accuracy: 0.9036 - val_loss: 0.2298 - val_accuracy: 0.9043 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9059 - val_loss: 0.2178 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2100 - accuracy: 0.9111 - val_loss: 0.2121 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9136 - val_loss: 0.2133 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9214 - val_loss: 0.2105 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1933 - accuracy: 0.9211 - val_loss: 0.2173 - val_accuracy: 0.9101 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9207 - val_loss: 0.2090 - val_accuracy: 0.9074 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1808 - accuracy: 0.9237 - val_loss: 0.2112 - val_accuracy: 0.9109 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.9241 - val_loss: 0.2082 - val_accuracy: 0.9101 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1780 - accuracy: 0.9241 - val_loss: 0.2037 - val_accuracy: 0.9144 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1776 - accuracy: 0.9231 - val_loss: 0.2044 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9258 - val_loss: 0.2046 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9281 - val_loss: 0.2055 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1714 - accuracy: 0.9286 - val_loss: 0.2009 - val_accuracy: 0.9140 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1680 - accuracy: 0.9295 - val_loss: 0.2038 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9281 - val_loss: 0.2015 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9277 - val_loss: 0.2017 - val_accuracy: 0.9128 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9279 - val_loss: 0.2022 - val_accuracy: 0.9109 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1648 - accuracy: 0.9312 - val_loss: 0.2018 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1622 - accuracy: 0.9328 - val_loss: 0.2015 - val_accuracy: 0.9140 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1651 - accuracy: 0.9297 - val_loss: 0.2004 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9333 - val_loss: 0.2027 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9302 - val_loss: 0.2008 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1670 - accuracy: 0.9299 - val_loss: 0.2006 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9311 - val_loss: 0.2012 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9330 - val_loss: 0.2011 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9281 - val_loss: 0.2007 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9295 - val_loss: 0.2008 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1658 - accuracy: 0.9305 - val_loss: 0.2009 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1637 - accuracy: 0.9312 - val_loss: 0.2008 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9314 - val_loss: 0.2006 - val_accuracy: 0.9136 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9337 - val_loss: 0.2006 - val_accuracy: 0.9136 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9307 - val_loss: 0.2007 - val_accuracy: 0.9140 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9303 - val_loss: 0.2006 - val_accuracy: 0.9140 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1602 - accuracy: 0.9336 - val_loss: 0.2005 - val_accuracy: 0.9144 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9128065395095368 0.9285262492093611 0.8876518218623481 0.8158694417402585 0.9080890355358546 0.9721086945944631\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6011 - accuracy: 0.7917 - val_loss: 0.3401 - val_accuracy: 0.8735 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8670"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2922 - accuracy: 0.8710 - val_loss: 0.2723 - val_accuracy: 0.8821 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2500 - accuracy: 0.8919 - val_loss: 0.2571 - val_accuracy: 0.8879 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2330 - accuracy: 0.9027 - val_loss: 0.2312 - val_accuracy: 0.9011 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2189 - accuracy: 0.9037 - val_loss: 0.2231 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9103 - val_loss: 0.2178 - val_accuracy: 0.9085 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9161 - val_loss: 0.2184 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1906 - accuracy: 0.9180 - val_loss: 0.2262 - val_accuracy: 0.9019 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1806 - accuracy: 0.9242 - val_loss: 0.2104 - val_accuracy: 0.9116 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1739 - accuracy: 0.9258 - val_loss: 0.2097 - val_accuracy: 0.9120 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.9301 - val_loss: 0.2086 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1643 - accuracy: 0.9286 - val_loss: 0.2096 - val_accuracy: 0.9151 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1586 - accuracy: 0.9340 - val_loss: 0.2098 - val_accuracy: 0.9163 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.9349 - val_loss: 0.2137 - val_accuracy: 0.9105 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9378 - val_loss: 0.2070 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1498 - accuracy: 0.9376 - val_loss: 0.2057 - val_accuracy: 0.9186 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1497 - accuracy: 0.9386 - val_loss: 0.2048 - val_accuracy: 0.9124 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9389 - val_loss: 0.2047 - val_accuracy: 0.9155 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1445 - accuracy: 0.9398 - val_loss: 0.2039 - val_accuracy: 0.9159 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9416 - val_loss: 0.2042 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1429 - accuracy: 0.9421 - val_loss: 0.2034 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9420 - val_loss: 0.2043 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9419 - val_loss: 0.2051 - val_accuracy: 0.9155 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9425 - val_loss: 0.2043 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9425 - val_loss: 0.2051 - val_accuracy: 0.9155 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9436 - val_loss: 0.2047 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9447 - val_loss: 0.2049 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1409 - accuracy: 0.9424 - val_loss: 0.2047 - val_accuracy: 0.9155 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1398 - accuracy: 0.9429 - val_loss: 0.2050 - val_accuracy: 0.9159 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9441 - val_loss: 0.2048 - val_accuracy: 0.9151 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1390 - accuracy: 0.9434 - val_loss: 0.2046 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.9445 - val_loss: 0.2047 - val_accuracy: 0.9155 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9416 - val_loss: 0.2046 - val_accuracy: 0.9159 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9467 - val_loss: 0.2047 - val_accuracy: 0.9159 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1363 - accuracy: 0.9451 - val_loss: 0.2045 - val_accuracy: 0.9163 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1362 - accuracy: 0.9423 - val_loss: 0.2047 - val_accuracy: 0.9155 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9186770428015564 0.9213275968039336 0.9141039236479321 0.8273977566277713 0.9177157602259329 0.9765137743838891\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6819 - accuracy: 0.7980 - val_loss: 0.3869 - val_accuracy: 0.8315 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.2943 - accuracy: 0.8705"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2809 - accuracy: 0.8809 - val_loss: 0.2465 - val_accuracy: 0.8946 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2439 - accuracy: 0.8989 - val_loss: 0.2426 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2289 - accuracy: 0.9033 - val_loss: 0.2455 - val_accuracy: 0.8977 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2206 - accuracy: 0.9081 - val_loss: 0.2216 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9149 - val_loss: 0.2114 - val_accuracy: 0.9051 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1977 - accuracy: 0.9150 - val_loss: 0.2098 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1876 - accuracy: 0.9233 - val_loss: 0.2089 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1837 - accuracy: 0.9259 - val_loss: 0.2082 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9240 - val_loss: 0.2099 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1715 - accuracy: 0.9290 - val_loss: 0.2147 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9325 - val_loss: 0.2053 - val_accuracy: 0.9117 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9312 - val_loss: 0.2044 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1599 - accuracy: 0.9360 - val_loss: 0.2034 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1580 - accuracy: 0.9336 - val_loss: 0.2020 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1587 - accuracy: 0.9325 - val_loss: 0.2014 - val_accuracy: 0.9160 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1541 - accuracy: 0.9338 - val_loss: 0.2028 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9388 - val_loss: 0.2031 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1521 - accuracy: 0.9376 - val_loss: 0.2005 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9359 - val_loss: 0.2022 - val_accuracy: 0.9187 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9412 - val_loss: 0.2025 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9414 - val_loss: 0.2014 - val_accuracy: 0.9171 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9424 - val_loss: 0.2020 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1443 - accuracy: 0.9421 - val_loss: 0.2003 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1445 - accuracy: 0.9408 - val_loss: 0.2018 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1482 - accuracy: 0.9408 - val_loss: 0.2012 - val_accuracy: 0.9160 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1445 - accuracy: 0.9419 - val_loss: 0.2012 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1435 - accuracy: 0.9411 - val_loss: 0.2012 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1438 - accuracy: 0.9419 - val_loss: 0.2007 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1429 - accuracy: 0.9424 - val_loss: 0.2003 - val_accuracy: 0.9179 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9419 - val_loss: 0.2002 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1453 - accuracy: 0.9414 - val_loss: 0.2002 - val_accuracy: 0.9175 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9426 - val_loss: 0.2002 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9421 - val_loss: 0.2000 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9406 - val_loss: 0.2002 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9411 - val_loss: 0.2001 - val_accuracy: 0.9179 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1448 - accuracy: 0.9430 - val_loss: 0.2001 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1418 - accuracy: 0.9419 - val_loss: 0.2002 - val_accuracy: 0.9179 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9411 - val_loss: 0.2002 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9423 - val_loss: 0.2002 - val_accuracy: 0.9179 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1403 - accuracy: 0.9447 - val_loss: 0.2002 - val_accuracy: 0.9187 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1444 - accuracy: 0.9402 - val_loss: 0.2002 - val_accuracy: 0.9183 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9430 - val_loss: 0.2002 - val_accuracy: 0.9183 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9416 - val_loss: 0.2002 - val_accuracy: 0.9183 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9450 - val_loss: 0.2001 - val_accuracy: 0.9187 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9163098481899572 0.9453860640301318 0.8688524590163934 0.8213960517198438 0.9071192615232626 0.9717305089891226\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 3s 6ms/step - loss: 0.5326 - accuracy: 0.8154 - val_loss: 0.3153 - val_accuracy: 0.8774 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 41/241 [====>.........................] - ETA: 0s - loss: 0.3178 - accuracy: 0.8567"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2823 - accuracy: 0.8774 - val_loss: 0.2520 - val_accuracy: 0.8899 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.8950 - val_loss: 0.2595 - val_accuracy: 0.8883 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2251 - accuracy: 0.9009 - val_loss: 0.2335 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2155 - accuracy: 0.9050 - val_loss: 0.2334 - val_accuracy: 0.8946 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1971 - accuracy: 0.9149 - val_loss: 0.2278 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1893 - accuracy: 0.9176 - val_loss: 0.2249 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1862 - accuracy: 0.9218 - val_loss: 0.2229 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1773 - accuracy: 0.9263 - val_loss: 0.2156 - val_accuracy: 0.9117 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9292 - val_loss: 0.2173 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9292 - val_loss: 0.2439 - val_accuracy: 0.9117 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1605 - accuracy: 0.9319 - val_loss: 0.2138 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1507 - accuracy: 0.9391 - val_loss: 0.2197 - val_accuracy: 0.9054 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.9371 - val_loss: 0.2168 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1452 - accuracy: 0.9377 - val_loss: 0.2162 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9398 - val_loss: 0.2143 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9389 - val_loss: 0.2156 - val_accuracy: 0.9136 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1394 - accuracy: 0.9424 - val_loss: 0.2120 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1391 - accuracy: 0.9401 - val_loss: 0.2165 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1417 - accuracy: 0.9403 - val_loss: 0.2163 - val_accuracy: 0.9156 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9438 - val_loss: 0.2143 - val_accuracy: 0.9117 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1362 - accuracy: 0.9428 - val_loss: 0.2147 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1333 - accuracy: 0.9428 - val_loss: 0.2154 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1330 - accuracy: 0.9451 - val_loss: 0.2171 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9450 - val_loss: 0.2156 - val_accuracy: 0.9121 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9416 - val_loss: 0.2167 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9462 - val_loss: 0.2163 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 0.9463 - val_loss: 0.2166 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9481 - val_loss: 0.2176 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1312 - accuracy: 0.9459 - val_loss: 0.2166 - val_accuracy: 0.9136 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9486 - val_loss: 0.2162 - val_accuracy: 0.9128 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9459 - val_loss: 0.2155 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9469 - val_loss: 0.2153 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9467 - val_loss: 0.2157 - val_accuracy: 0.9140 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1288 - accuracy: 0.9454 - val_loss: 0.2161 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9468 - val_loss: 0.2162 - val_accuracy: 0.9140 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9477 - val_loss: 0.2164 - val_accuracy: 0.9140 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9438 - val_loss: 0.2163 - val_accuracy: 0.9140 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9469 - val_loss: 0.2164 - val_accuracy: 0.9136 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9447 - val_loss: 0.2162 - val_accuracy: 0.9136 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9104710003892565 0.939938080495356 0.860587002096436 0.8071244761257346 0.900262541295896 0.9702072421156479\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6029 - accuracy: 0.8194 - val_loss: 0.3433 - val_accuracy: 0.8292 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.3029 - accuracy: 0.8677"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2777 - accuracy: 0.8801 - val_loss: 0.2497 - val_accuracy: 0.8984 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2430 - accuracy: 0.8984 - val_loss: 0.2283 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2261 - accuracy: 0.9052 - val_loss: 0.2315 - val_accuracy: 0.8984 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.9063 - val_loss: 0.2349 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1990 - accuracy: 0.9127 - val_loss: 0.2176 - val_accuracy: 0.9039 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1900 - accuracy: 0.9188 - val_loss: 0.2111 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9185 - val_loss: 0.2085 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1782 - accuracy: 0.9254 - val_loss: 0.2089 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9286 - val_loss: 0.2033 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1665 - accuracy: 0.9288 - val_loss: 0.2049 - val_accuracy: 0.9163 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9324 - val_loss: 0.2049 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1591 - accuracy: 0.9351 - val_loss: 0.2014 - val_accuracy: 0.9152 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9367 - val_loss: 0.2005 - val_accuracy: 0.9105 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1458 - accuracy: 0.9408 - val_loss: 0.2034 - val_accuracy: 0.9093 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9382 - val_loss: 0.1993 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1464 - accuracy: 0.9395 - val_loss: 0.2061 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9414 - val_loss: 0.2028 - val_accuracy: 0.9101 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1427 - accuracy: 0.9406 - val_loss: 0.2002 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1438 - accuracy: 0.9410 - val_loss: 0.2022 - val_accuracy: 0.9101 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9437 - val_loss: 0.2021 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9449 - val_loss: 0.2018 - val_accuracy: 0.9132 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1369 - accuracy: 0.9441 - val_loss: 0.2024 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9456 - val_loss: 0.2008 - val_accuracy: 0.9113 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1345 - accuracy: 0.9452 - val_loss: 0.2025 - val_accuracy: 0.9113 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.9459 - val_loss: 0.2018 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1349 - accuracy: 0.9439 - val_loss: 0.2016 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1348 - accuracy: 0.9442 - val_loss: 0.2006 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1333 - accuracy: 0.9446 - val_loss: 0.2009 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1368 - accuracy: 0.9439 - val_loss: 0.2006 - val_accuracy: 0.9128 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9467 - val_loss: 0.2013 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9244842351109381 0.9411035337879727 0.8964435146443515 0.8382660127495455 0.9187735242161621 0.9789063493010504\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4896 - accuracy: 0.8235 - val_loss: 0.3767 - val_accuracy: 0.8405 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.2884 - accuracy: 0.8823"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2737 - accuracy: 0.8857 - val_loss: 0.2597 - val_accuracy: 0.8981 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2363 - accuracy: 0.9013 - val_loss: 0.2263 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2233 - accuracy: 0.9057 - val_loss: 0.2158 - val_accuracy: 0.9097 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2114 - accuracy: 0.9100 - val_loss: 0.2132 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1959 - accuracy: 0.9196 - val_loss: 0.2145 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1884 - accuracy: 0.9205 - val_loss: 0.2035 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1836 - accuracy: 0.9225 - val_loss: 0.2036 - val_accuracy: 0.9152 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9295 - val_loss: 0.2018 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1667 - accuracy: 0.9293 - val_loss: 0.2045 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1620 - accuracy: 0.9302 - val_loss: 0.2020 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1564 - accuracy: 0.9341 - val_loss: 0.1939 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9378 - val_loss: 0.1973 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1498 - accuracy: 0.9363 - val_loss: 0.1944 - val_accuracy: 0.9230 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.9403 - val_loss: 0.1962 - val_accuracy: 0.9257 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1410 - accuracy: 0.9420 - val_loss: 0.1934 - val_accuracy: 0.9265 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1418 - accuracy: 0.9408 - val_loss: 0.1937 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1394 - accuracy: 0.9429 - val_loss: 0.1938 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1375 - accuracy: 0.9438 - val_loss: 0.1966 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1338 - accuracy: 0.9482 - val_loss: 0.1941 - val_accuracy: 0.9261 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1328 - accuracy: 0.9477 - val_loss: 0.1949 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1355 - accuracy: 0.9437 - val_loss: 0.1950 - val_accuracy: 0.9265 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1321 - accuracy: 0.9476 - val_loss: 0.1951 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9472 - val_loss: 0.1933 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9477 - val_loss: 0.1944 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1304 - accuracy: 0.9497 - val_loss: 0.1936 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1295 - accuracy: 0.9446 - val_loss: 0.1935 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1262 - accuracy: 0.9497 - val_loss: 0.1943 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9485 - val_loss: 0.1941 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9463 - val_loss: 0.1933 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1301 - accuracy: 0.9495 - val_loss: 0.1933 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9489 - val_loss: 0.1933 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9486 - val_loss: 0.1936 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1317 - accuracy: 0.9439 - val_loss: 0.1930 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1288 - accuracy: 0.9507 - val_loss: 0.1929 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9500 - val_loss: 0.1930 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9225379525107046 0.9367488931056294 0.8997975708502024 0.8363879857523485 0.9182732319779159 0.976141272755674\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4630 - accuracy: 0.8111 - val_loss: 0.3289 - val_accuracy: 0.8801 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.2848 - accuracy: 0.8859"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2855 - accuracy: 0.8763 - val_loss: 0.2585 - val_accuracy: 0.8930 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2468 - accuracy: 0.8940 - val_loss: 0.2354 - val_accuracy: 0.8980 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2298 - accuracy: 0.9018 - val_loss: 0.2229 - val_accuracy: 0.9023 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.9077 - val_loss: 0.2303 - val_accuracy: 0.9042 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9145 - val_loss: 0.2186 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9159 - val_loss: 0.2133 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1909 - accuracy: 0.9190 - val_loss: 0.2104 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.9266 - val_loss: 0.2056 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1763 - accuracy: 0.9272 - val_loss: 0.2086 - val_accuracy: 0.9124 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1705 - accuracy: 0.9298 - val_loss: 0.2056 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1668 - accuracy: 0.9310 - val_loss: 0.2060 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9324 - val_loss: 0.2045 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9347 - val_loss: 0.2095 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1565 - accuracy: 0.9375 - val_loss: 0.2047 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1536 - accuracy: 0.9368 - val_loss: 0.2028 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1532 - accuracy: 0.9363 - val_loss: 0.2020 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9364 - val_loss: 0.2021 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1512 - accuracy: 0.9371 - val_loss: 0.2015 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1448 - accuracy: 0.9406 - val_loss: 0.2009 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1473 - accuracy: 0.9385 - val_loss: 0.2002 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9393 - val_loss: 0.1994 - val_accuracy: 0.9225 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9381 - val_loss: 0.1998 - val_accuracy: 0.9202 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1435 - accuracy: 0.9403 - val_loss: 0.1990 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1444 - accuracy: 0.9410 - val_loss: 0.1997 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9415 - val_loss: 0.2007 - val_accuracy: 0.9206 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1428 - accuracy: 0.9399 - val_loss: 0.2001 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1398 - accuracy: 0.9429 - val_loss: 0.1994 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1399 - accuracy: 0.9424 - val_loss: 0.1993 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9397 - val_loss: 0.1993 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1392 - accuracy: 0.9430 - val_loss: 0.1994 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.9437 - val_loss: 0.1997 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9411 - val_loss: 0.1999 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9394 - val_loss: 0.1998 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9445 - val_loss: 0.1997 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1414 - accuracy: 0.9408 - val_loss: 0.1996 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1418 - accuracy: 0.9395 - val_loss: 0.1996 - val_accuracy: 0.9253 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9430 - val_loss: 0.1995 - val_accuracy: 0.9249 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9414 - val_loss: 0.1994 - val_accuracy: 0.9241 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1407 - accuracy: 0.9419 - val_loss: 0.1994 - val_accuracy: 0.9241 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9417 - val_loss: 0.1994 - val_accuracy: 0.9249 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1400 - accuracy: 0.9419 - val_loss: 0.1994 - val_accuracy: 0.9245 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9417 - val_loss: 0.1994 - val_accuracy: 0.9245 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9467 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1396 - accuracy: 0.9415 - val_loss: 0.1995 - val_accuracy: 0.9249 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9437 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1408 - accuracy: 0.9433 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9424 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.9426 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9441 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9416 - val_loss: 0.1996 - val_accuracy: 0.9245 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9420 - val_loss: 0.1996 - val_accuracy: 0.9245 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9412 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1422 - accuracy: 0.9401 - val_loss: 0.1996 - val_accuracy: 0.9245 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1401 - accuracy: 0.9421 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1392 - accuracy: 0.9439 - val_loss: 0.1996 - val_accuracy: 0.9245 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1379 - accuracy: 0.9434 - val_loss: 0.1995 - val_accuracy: 0.9245 - lr: 6.0936e-06\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9190661478599221 0.9237861094038107 0.9109225874867445 0.8277884053005458 0.9173543484452775 0.9766702014846237\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5277 - accuracy: 0.8238 - val_loss: 0.3095 - val_accuracy: 0.8805 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.2444 - accuracy: 0.8932"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2662 - accuracy: 0.8857 - val_loss: 0.2484 - val_accuracy: 0.8938 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2342 - accuracy: 0.9026 - val_loss: 0.2349 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9061 - val_loss: 0.2262 - val_accuracy: 0.9051 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9088 - val_loss: 0.2193 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2001 - accuracy: 0.9176 - val_loss: 0.2133 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1895 - accuracy: 0.9212 - val_loss: 0.2157 - val_accuracy: 0.9144 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9223 - val_loss: 0.2147 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1814 - accuracy: 0.9246 - val_loss: 0.2076 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1721 - accuracy: 0.9279 - val_loss: 0.2037 - val_accuracy: 0.9101 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1728 - accuracy: 0.9310 - val_loss: 0.2039 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9323 - val_loss: 0.2060 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1640 - accuracy: 0.9332 - val_loss: 0.2034 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9320 - val_loss: 0.1991 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9336 - val_loss: 0.2009 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9377 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1545 - accuracy: 0.9360 - val_loss: 0.2046 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1548 - accuracy: 0.9362 - val_loss: 0.2014 - val_accuracy: 0.9167 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1517 - accuracy: 0.9384 - val_loss: 0.2001 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9368 - val_loss: 0.1990 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9402 - val_loss: 0.2024 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1452 - accuracy: 0.9406 - val_loss: 0.1993 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1492 - accuracy: 0.9410 - val_loss: 0.2000 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1446 - accuracy: 0.9399 - val_loss: 0.1993 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.9408 - val_loss: 0.1988 - val_accuracy: 0.9175 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1510 - accuracy: 0.9389 - val_loss: 0.1983 - val_accuracy: 0.9183 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9404 - val_loss: 0.1983 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1445 - accuracy: 0.9404 - val_loss: 0.1981 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.9399 - val_loss: 0.1988 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9401 - val_loss: 0.1984 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.9434 - val_loss: 0.1985 - val_accuracy: 0.9195 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9442 - val_loss: 0.1987 - val_accuracy: 0.9179 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1472 - accuracy: 0.9381 - val_loss: 0.1984 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1433 - accuracy: 0.9402 - val_loss: 0.1985 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1452 - accuracy: 0.9416 - val_loss: 0.1983 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1427 - accuracy: 0.9421 - val_loss: 0.1983 - val_accuracy: 0.9187 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.9423 - val_loss: 0.1982 - val_accuracy: 0.9187 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9425 - val_loss: 0.1982 - val_accuracy: 0.9191 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9420 - val_loss: 0.1983 - val_accuracy: 0.9187 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9429 - val_loss: 0.1983 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9408 - val_loss: 0.1982 - val_accuracy: 0.9191 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.9399 - val_loss: 0.1982 - val_accuracy: 0.9191 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1422 - accuracy: 0.9404 - val_loss: 0.1983 - val_accuracy: 0.9191 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.9416 - val_loss: 0.1983 - val_accuracy: 0.9191 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9155313351498637 0.9397363465160076 0.8760245901639344 0.8200044034991286 0.907880468339971 0.971071889825363\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4469 - accuracy: 0.8270 - val_loss: 0.3706 - val_accuracy: 0.8825 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 40/241 [===>..........................] - ETA: 0s - loss: 0.2789 - accuracy: 0.8773"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2618 - accuracy: 0.8875 - val_loss: 0.2338 - val_accuracy: 0.9039 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.9036 - val_loss: 0.2279 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2141 - accuracy: 0.9096 - val_loss: 0.2319 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2084 - accuracy: 0.9124 - val_loss: 0.2142 - val_accuracy: 0.9175 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9192 - val_loss: 0.2120 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1803 - accuracy: 0.9224 - val_loss: 0.2124 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1800 - accuracy: 0.9238 - val_loss: 0.2085 - val_accuracy: 0.9156 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9308 - val_loss: 0.2093 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9318 - val_loss: 0.2119 - val_accuracy: 0.9183 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1588 - accuracy: 0.9338 - val_loss: 0.2125 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9368 - val_loss: 0.2055 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.9336 - val_loss: 0.2043 - val_accuracy: 0.9171 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9388 - val_loss: 0.2096 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9421 - val_loss: 0.2015 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9410 - val_loss: 0.2056 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1375 - accuracy: 0.9441 - val_loss: 0.2035 - val_accuracy: 0.9214 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1367 - accuracy: 0.9449 - val_loss: 0.2044 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9449 - val_loss: 0.2029 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9449 - val_loss: 0.2052 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9452 - val_loss: 0.2035 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9484 - val_loss: 0.2043 - val_accuracy: 0.9226 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1342 - accuracy: 0.9472 - val_loss: 0.2021 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9486 - val_loss: 0.2039 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9503 - val_loss: 0.2035 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1302 - accuracy: 0.9471 - val_loss: 0.2032 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1321 - accuracy: 0.9476 - val_loss: 0.2036 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1263 - accuracy: 0.9491 - val_loss: 0.2036 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9481 - val_loss: 0.2032 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1278 - accuracy: 0.9473 - val_loss: 0.2031 - val_accuracy: 0.9230 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1277 - accuracy: 0.9485 - val_loss: 0.2031 - val_accuracy: 0.9230 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9495 - val_loss: 0.2026 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1286 - accuracy: 0.9473 - val_loss: 0.2026 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9493 - val_loss: 0.2024 - val_accuracy: 0.9230 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9487 - val_loss: 0.2027 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9506 - val_loss: 0.2029 - val_accuracy: 0.9241 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1288 - accuracy: 0.9481 - val_loss: 0.2028 - val_accuracy: 0.9241 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1271 - accuracy: 0.9486 - val_loss: 0.2028 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1277 - accuracy: 0.9506 - val_loss: 0.2027 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1305 - accuracy: 0.9475 - val_loss: 0.2027 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9512 - val_loss: 0.2028 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1263 - accuracy: 0.9508 - val_loss: 0.2028 - val_accuracy: 0.9233 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9463 - val_loss: 0.2028 - val_accuracy: 0.9233 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9135850525496302 0.9337461300309597 0.8794549266247379 0.8146171647707292 0.9066005283278489 0.9701588877855015\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5869 - accuracy: 0.7963 - val_loss: 0.3137 - val_accuracy: 0.8576 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 41/241 [====>.........................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8605"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2931 - accuracy: 0.8691 - val_loss: 0.2578 - val_accuracy: 0.8895 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.8845 - val_loss: 0.2355 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2470 - accuracy: 0.8952 - val_loss: 0.2373 - val_accuracy: 0.8973 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2358 - accuracy: 0.8978 - val_loss: 0.2251 - val_accuracy: 0.9031 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9070 - val_loss: 0.2222 - val_accuracy: 0.9019 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.9066 - val_loss: 0.2212 - val_accuracy: 0.9043 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9075 - val_loss: 0.2129 - val_accuracy: 0.9086 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2011 - accuracy: 0.9158 - val_loss: 0.2109 - val_accuracy: 0.9054 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9141 - val_loss: 0.2135 - val_accuracy: 0.9047 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9159 - val_loss: 0.2103 - val_accuracy: 0.9012 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9206 - val_loss: 0.2065 - val_accuracy: 0.9082 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1873 - accuracy: 0.9238 - val_loss: 0.2085 - val_accuracy: 0.9078 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1841 - accuracy: 0.9259 - val_loss: 0.2067 - val_accuracy: 0.9082 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1794 - accuracy: 0.9259 - val_loss: 0.2047 - val_accuracy: 0.9109 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1775 - accuracy: 0.9258 - val_loss: 0.2051 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1767 - accuracy: 0.9266 - val_loss: 0.2085 - val_accuracy: 0.9101 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1754 - accuracy: 0.9273 - val_loss: 0.2058 - val_accuracy: 0.9097 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1717 - accuracy: 0.9286 - val_loss: 0.2050 - val_accuracy: 0.9097 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.9288 - val_loss: 0.2063 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9332 - val_loss: 0.2053 - val_accuracy: 0.9113 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1717 - accuracy: 0.9280 - val_loss: 0.2046 - val_accuracy: 0.9109 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1704 - accuracy: 0.9314 - val_loss: 0.2040 - val_accuracy: 0.9121 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1687 - accuracy: 0.9308 - val_loss: 0.2041 - val_accuracy: 0.9105 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.9321 - val_loss: 0.2046 - val_accuracy: 0.9117 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1670 - accuracy: 0.9306 - val_loss: 0.2043 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1653 - accuracy: 0.9324 - val_loss: 0.2035 - val_accuracy: 0.9117 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1661 - accuracy: 0.9298 - val_loss: 0.2032 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1665 - accuracy: 0.9341 - val_loss: 0.2032 - val_accuracy: 0.9117 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1642 - accuracy: 0.9330 - val_loss: 0.2035 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1644 - accuracy: 0.9318 - val_loss: 0.2031 - val_accuracy: 0.9117 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1617 - accuracy: 0.9336 - val_loss: 0.2035 - val_accuracy: 0.9117 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1673 - accuracy: 0.9321 - val_loss: 0.2034 - val_accuracy: 0.9121 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9353 - val_loss: 0.2034 - val_accuracy: 0.9128 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1672 - accuracy: 0.9318 - val_loss: 0.2034 - val_accuracy: 0.9125 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9318 - val_loss: 0.2033 - val_accuracy: 0.9128 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.9330 - val_loss: 0.2033 - val_accuracy: 0.9132 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1651 - accuracy: 0.9301 - val_loss: 0.2031 - val_accuracy: 0.9132 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1662 - accuracy: 0.9333 - val_loss: 0.2032 - val_accuracy: 0.9132 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1664 - accuracy: 0.9325 - val_loss: 0.2032 - val_accuracy: 0.9132 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9328 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.9306 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9318 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9318 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1615 - accuracy: 0.9350 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1640 - accuracy: 0.9333 - val_loss: 0.2032 - val_accuracy: 0.9128 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1615 - accuracy: 0.9338 - val_loss: 0.2032 - val_accuracy: 0.9128 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9314 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1639 - accuracy: 0.9311 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1668 - accuracy: 0.9294 - val_loss: 0.2032 - val_accuracy: 0.9128 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1642 - accuracy: 0.9328 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9349 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9314 - val_loss: 0.2032 - val_accuracy: 0.9128 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9329 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1685 - accuracy: 0.9321 - val_loss: 0.2032 - val_accuracy: 0.9128 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1644 - accuracy: 0.9324 - val_loss: 0.2031 - val_accuracy: 0.9128 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1612 - accuracy: 0.9345 - val_loss: 0.2032 - val_accuracy: 0.9128 - lr: 6.0936e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9252627481510315 0.9349039057656541 0.9089958158995816 0.8407698922806509 0.9219498608326178 0.9774602017602793\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.7471 - val_loss: 0.3463 - val_accuracy: 0.8401 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 41/241 [====>.........................] - ETA: 0s - loss: 0.3593 - accuracy: 0.8216"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8449 - val_loss: 0.2885 - val_accuracy: 0.8630 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2713 - accuracy: 0.8865 - val_loss: 0.2549 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2665 - accuracy: 0.8878 - val_loss: 0.2416 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2537 - accuracy: 0.8913 - val_loss: 0.2385 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9011 - val_loss: 0.2251 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2244 - accuracy: 0.9055 - val_loss: 0.2269 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2232 - accuracy: 0.9084 - val_loss: 0.2220 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2095 - accuracy: 0.9135 - val_loss: 0.2209 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9138 - val_loss: 0.2179 - val_accuracy: 0.9105 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9154 - val_loss: 0.2136 - val_accuracy: 0.9121 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9170 - val_loss: 0.2178 - val_accuracy: 0.9078 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9203 - val_loss: 0.2115 - val_accuracy: 0.9117 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9202 - val_loss: 0.2116 - val_accuracy: 0.9163 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1861 - accuracy: 0.9203 - val_loss: 0.2130 - val_accuracy: 0.9101 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1876 - accuracy: 0.9180 - val_loss: 0.2119 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1857 - accuracy: 0.9231 - val_loss: 0.2084 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1814 - accuracy: 0.9267 - val_loss: 0.2081 - val_accuracy: 0.9105 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9273 - val_loss: 0.2078 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1800 - accuracy: 0.9263 - val_loss: 0.2060 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1797 - accuracy: 0.9244 - val_loss: 0.2061 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1800 - accuracy: 0.9244 - val_loss: 0.2072 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9250 - val_loss: 0.2068 - val_accuracy: 0.9156 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1783 - accuracy: 0.9249 - val_loss: 0.2077 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.9246 - val_loss: 0.2058 - val_accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1783 - accuracy: 0.9238 - val_loss: 0.2065 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9293 - val_loss: 0.2060 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1787 - accuracy: 0.9272 - val_loss: 0.2060 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9272 - val_loss: 0.2065 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1709 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1695 - accuracy: 0.9301 - val_loss: 0.2066 - val_accuracy: 0.9163 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1737 - accuracy: 0.9260 - val_loss: 0.2067 - val_accuracy: 0.9152 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1752 - accuracy: 0.9279 - val_loss: 0.2070 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1724 - accuracy: 0.9267 - val_loss: 0.2066 - val_accuracy: 0.9156 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1779 - accuracy: 0.9247 - val_loss: 0.2061 - val_accuracy: 0.9160 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1724 - accuracy: 0.9303 - val_loss: 0.2063 - val_accuracy: 0.9160 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9268 - val_loss: 0.2061 - val_accuracy: 0.9167 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9264 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.9267 - val_loss: 0.2062 - val_accuracy: 0.9163 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9281 - val_loss: 0.2061 - val_accuracy: 0.9163 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1779 - accuracy: 0.9237 - val_loss: 0.2060 - val_accuracy: 0.9163 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9288 - val_loss: 0.2060 - val_accuracy: 0.9163 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9293 - val_loss: 0.2060 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9286 - val_loss: 0.2060 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9285 - val_loss: 0.2060 - val_accuracy: 0.9167 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9292 - val_loss: 0.2060 - val_accuracy: 0.9167 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1761 - accuracy: 0.9254 - val_loss: 0.2060 - val_accuracy: 0.9163 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9147528221097704 0.9316888045540797 0.8876518218623481 0.8198099649705947 0.9096703132082139 0.972522259524157\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5020 - accuracy: 0.8195 - val_loss: 0.3108 - val_accuracy: 0.8571 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 44/241 [====>.........................] - ETA: 0s - loss: 0.3008 - accuracy: 0.8679"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2834 - accuracy: 0.8779 - val_loss: 0.2467 - val_accuracy: 0.8906 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.8948 - val_loss: 0.2271 - val_accuracy: 0.8988 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9023 - val_loss: 0.2410 - val_accuracy: 0.8976 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2249 - accuracy: 0.9046 - val_loss: 0.2188 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9116 - val_loss: 0.2152 - val_accuracy: 0.9042 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1995 - accuracy: 0.9164 - val_loss: 0.2198 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9158 - val_loss: 0.2192 - val_accuracy: 0.9046 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9219 - val_loss: 0.2063 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.9250 - val_loss: 0.2059 - val_accuracy: 0.9112 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1767 - accuracy: 0.9249 - val_loss: 0.2065 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1721 - accuracy: 0.9254 - val_loss: 0.2045 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9318 - val_loss: 0.2031 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9295 - val_loss: 0.2040 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9314 - val_loss: 0.2016 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1618 - accuracy: 0.9319 - val_loss: 0.2011 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9346 - val_loss: 0.2018 - val_accuracy: 0.9179 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9362 - val_loss: 0.2033 - val_accuracy: 0.9159 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1537 - accuracy: 0.9390 - val_loss: 0.2005 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1540 - accuracy: 0.9358 - val_loss: 0.2008 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9373 - val_loss: 0.1997 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9381 - val_loss: 0.2003 - val_accuracy: 0.9190 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9393 - val_loss: 0.2011 - val_accuracy: 0.9186 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1492 - accuracy: 0.9385 - val_loss: 0.2010 - val_accuracy: 0.9175 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9410 - val_loss: 0.2006 - val_accuracy: 0.9186 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9389 - val_loss: 0.2007 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9402 - val_loss: 0.2008 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1482 - accuracy: 0.9381 - val_loss: 0.2007 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.9376 - val_loss: 0.2000 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1494 - accuracy: 0.9367 - val_loss: 0.1999 - val_accuracy: 0.9194 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1522 - accuracy: 0.9366 - val_loss: 0.2000 - val_accuracy: 0.9183 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9399 - val_loss: 0.1999 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9406 - val_loss: 0.2000 - val_accuracy: 0.9194 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1487 - accuracy: 0.9385 - val_loss: 0.1999 - val_accuracy: 0.9194 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1485 - accuracy: 0.9391 - val_loss: 0.2000 - val_accuracy: 0.9186 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9385 - val_loss: 0.1999 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9397 - val_loss: 0.1999 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9416 - val_loss: 0.1999 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1480 - accuracy: 0.9386 - val_loss: 0.1999 - val_accuracy: 0.9179 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9249027237354086 0.9342347879532883 0.9088016967126193 0.8392371605207588 0.9215182423329538 0.9770182517837579\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4180 - accuracy: 0.8285 - val_loss: 0.3071 - val_accuracy: 0.8879 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 45/241 [====>.........................] - ETA: 0s - loss: 0.2994 - accuracy: 0.8625"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2699 - accuracy: 0.8819 - val_loss: 0.2381 - val_accuracy: 0.8946 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9027 - val_loss: 0.2168 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2174 - accuracy: 0.9097 - val_loss: 0.2114 - val_accuracy: 0.9086 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.9133 - val_loss: 0.2138 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1898 - accuracy: 0.9210 - val_loss: 0.2053 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.9237 - val_loss: 0.2081 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1768 - accuracy: 0.9260 - val_loss: 0.1979 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9325 - val_loss: 0.1978 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1620 - accuracy: 0.9351 - val_loss: 0.1943 - val_accuracy: 0.9160 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1587 - accuracy: 0.9334 - val_loss: 0.1940 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9368 - val_loss: 0.1921 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1519 - accuracy: 0.9385 - val_loss: 0.1955 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9364 - val_loss: 0.2026 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9406 - val_loss: 0.1903 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1428 - accuracy: 0.9411 - val_loss: 0.1905 - val_accuracy: 0.9160 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1403 - accuracy: 0.9417 - val_loss: 0.1907 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1375 - accuracy: 0.9429 - val_loss: 0.1900 - val_accuracy: 0.9156 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9445 - val_loss: 0.1898 - val_accuracy: 0.9183 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9455 - val_loss: 0.1901 - val_accuracy: 0.9187 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9463 - val_loss: 0.1895 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.9468 - val_loss: 0.1899 - val_accuracy: 0.9206 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9473 - val_loss: 0.1895 - val_accuracy: 0.9202 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9480 - val_loss: 0.1898 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9472 - val_loss: 0.1889 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1289 - accuracy: 0.9482 - val_loss: 0.1892 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9487 - val_loss: 0.1890 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9480 - val_loss: 0.1891 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9491 - val_loss: 0.1899 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9487 - val_loss: 0.1891 - val_accuracy: 0.9191 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.9482 - val_loss: 0.1888 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9499 - val_loss: 0.1889 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9471 - val_loss: 0.1889 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9472 - val_loss: 0.1889 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9491 - val_loss: 0.1889 - val_accuracy: 0.9198 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9468 - val_loss: 0.1889 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9484 - val_loss: 0.1890 - val_accuracy: 0.9187 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.9502 - val_loss: 0.1891 - val_accuracy: 0.9187 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1263 - accuracy: 0.9498 - val_loss: 0.1891 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1270 - accuracy: 0.9489 - val_loss: 0.1890 - val_accuracy: 0.9191 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9489 - val_loss: 0.1890 - val_accuracy: 0.9195 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9487 - val_loss: 0.1889 - val_accuracy: 0.9198 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9182561307901907 0.9416195856873822 0.8801229508196722 0.8258384151201411 0.9108712682535272 0.9732487419344878\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4977 - accuracy: 0.8193 - val_loss: 0.3328 - val_accuracy: 0.8813 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 41/241 [====>.........................] - ETA: 0s - loss: 0.3106 - accuracy: 0.8666"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2738 - accuracy: 0.8811 - val_loss: 0.2550 - val_accuracy: 0.8984 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9000 - val_loss: 0.2400 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2264 - accuracy: 0.9027 - val_loss: 0.2362 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2126 - accuracy: 0.9105 - val_loss: 0.2283 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1989 - accuracy: 0.9158 - val_loss: 0.2214 - val_accuracy: 0.9082 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1974 - accuracy: 0.9158 - val_loss: 0.2183 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1852 - accuracy: 0.9207 - val_loss: 0.2165 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9263 - val_loss: 0.2114 - val_accuracy: 0.9070 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9251 - val_loss: 0.2108 - val_accuracy: 0.9078 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9263 - val_loss: 0.2175 - val_accuracy: 0.9074 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9310 - val_loss: 0.2064 - val_accuracy: 0.9109 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1611 - accuracy: 0.9320 - val_loss: 0.2108 - val_accuracy: 0.9070 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1584 - accuracy: 0.9345 - val_loss: 0.2087 - val_accuracy: 0.9082 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1573 - accuracy: 0.9341 - val_loss: 0.2048 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1564 - accuracy: 0.9324 - val_loss: 0.2056 - val_accuracy: 0.9089 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9360 - val_loss: 0.2060 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9363 - val_loss: 0.2052 - val_accuracy: 0.9140 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1483 - accuracy: 0.9372 - val_loss: 0.2061 - val_accuracy: 0.9121 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9403 - val_loss: 0.2065 - val_accuracy: 0.9101 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9408 - val_loss: 0.2054 - val_accuracy: 0.9117 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9394 - val_loss: 0.2046 - val_accuracy: 0.9113 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1504 - accuracy: 0.9373 - val_loss: 0.2037 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9390 - val_loss: 0.2051 - val_accuracy: 0.9109 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9398 - val_loss: 0.2047 - val_accuracy: 0.9105 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9391 - val_loss: 0.2052 - val_accuracy: 0.9109 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9416 - val_loss: 0.2053 - val_accuracy: 0.9105 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1441 - accuracy: 0.9386 - val_loss: 0.2048 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9388 - val_loss: 0.2050 - val_accuracy: 0.9105 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9393 - val_loss: 0.2058 - val_accuracy: 0.9101 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1452 - accuracy: 0.9393 - val_loss: 0.2056 - val_accuracy: 0.9105 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9430 - val_loss: 0.2053 - val_accuracy: 0.9097 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9391 - val_loss: 0.2049 - val_accuracy: 0.9101 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9415 - val_loss: 0.2051 - val_accuracy: 0.9101 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9432 - val_loss: 0.2050 - val_accuracy: 0.9109 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9450 - val_loss: 0.2050 - val_accuracy: 0.9101 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9388 - val_loss: 0.2048 - val_accuracy: 0.9101 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9390 - val_loss: 0.2051 - val_accuracy: 0.9105 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9054106656286492 0.9325077399380804 0.859538784067086 0.7964918971720832 0.8960232620025832 0.9676230439213089\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4456 - accuracy: 0.8237 - val_loss: 0.3349 - val_accuracy: 0.8700 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.2990 - accuracy: 0.8601"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.8744 - val_loss: 0.2545 - val_accuracy: 0.8961 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2448 - accuracy: 0.8963 - val_loss: 0.2359 - val_accuracy: 0.9008 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9019 - val_loss: 0.2305 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2203 - accuracy: 0.9053 - val_loss: 0.2177 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9149 - val_loss: 0.2115 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9162 - val_loss: 0.2077 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.9186 - val_loss: 0.2137 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1798 - accuracy: 0.9214 - val_loss: 0.2086 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1716 - accuracy: 0.9262 - val_loss: 0.2029 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.9307 - val_loss: 0.2061 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9297 - val_loss: 0.2060 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1606 - accuracy: 0.9328 - val_loss: 0.2038 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1615 - accuracy: 0.9330 - val_loss: 0.2030 - val_accuracy: 0.9152 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.9371 - val_loss: 0.2005 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9367 - val_loss: 0.2023 - val_accuracy: 0.9140 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9369 - val_loss: 0.2002 - val_accuracy: 0.9171 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1491 - accuracy: 0.9394 - val_loss: 0.2008 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9376 - val_loss: 0.2004 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1467 - accuracy: 0.9401 - val_loss: 0.2010 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1448 - accuracy: 0.9404 - val_loss: 0.2001 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1451 - accuracy: 0.9390 - val_loss: 0.2002 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1411 - accuracy: 0.9417 - val_loss: 0.2007 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1432 - accuracy: 0.9391 - val_loss: 0.1999 - val_accuracy: 0.9156 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9415 - val_loss: 0.1999 - val_accuracy: 0.9175 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9426 - val_loss: 0.1995 - val_accuracy: 0.9140 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9410 - val_loss: 0.1995 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9439 - val_loss: 0.1998 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1419 - accuracy: 0.9433 - val_loss: 0.1998 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1398 - accuracy: 0.9426 - val_loss: 0.1998 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.9395 - val_loss: 0.1999 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1448 - accuracy: 0.9410 - val_loss: 0.1997 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9424 - val_loss: 0.1996 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1410 - accuracy: 0.9420 - val_loss: 0.1996 - val_accuracy: 0.9156 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1404 - accuracy: 0.9410 - val_loss: 0.1996 - val_accuracy: 0.9160 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1379 - accuracy: 0.9458 - val_loss: 0.1995 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1410 - accuracy: 0.9415 - val_loss: 0.1995 - val_accuracy: 0.9144 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1397 - accuracy: 0.9441 - val_loss: 0.1995 - val_accuracy: 0.9148 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9446 - val_loss: 0.1995 - val_accuracy: 0.9144 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1403 - accuracy: 0.9429 - val_loss: 0.1996 - val_accuracy: 0.9144 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1407 - accuracy: 0.9455 - val_loss: 0.1996 - val_accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1388 - accuracy: 0.9445 - val_loss: 0.1996 - val_accuracy: 0.9148 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9449 - val_loss: 0.1996 - val_accuracy: 0.9148 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9233164655507979 0.9417234965902046 0.8922594142259415 0.8356085344407277 0.916991455408073 0.9796877877703907\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4491 - accuracy: 0.8331 - val_loss: 0.2984 - val_accuracy: 0.8942 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.2825 - accuracy: 0.8683"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2749 - accuracy: 0.8805 - val_loss: 0.2482 - val_accuracy: 0.8953 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2333 - accuracy: 0.8978 - val_loss: 0.2315 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9032 - val_loss: 0.2195 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2142 - accuracy: 0.9076 - val_loss: 0.2275 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.9150 - val_loss: 0.2125 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1882 - accuracy: 0.9194 - val_loss: 0.2116 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1841 - accuracy: 0.9203 - val_loss: 0.2124 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1737 - accuracy: 0.9280 - val_loss: 0.2038 - val_accuracy: 0.9163 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9281 - val_loss: 0.2072 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9285 - val_loss: 0.2060 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.9288 - val_loss: 0.2049 - val_accuracy: 0.9109 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1560 - accuracy: 0.9342 - val_loss: 0.2019 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9312 - val_loss: 0.2025 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9368 - val_loss: 0.2030 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9372 - val_loss: 0.1997 - val_accuracy: 0.9187 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9368 - val_loss: 0.1983 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1453 - accuracy: 0.9393 - val_loss: 0.1998 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9403 - val_loss: 0.1984 - val_accuracy: 0.9179 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9414 - val_loss: 0.1974 - val_accuracy: 0.9191 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9395 - val_loss: 0.1980 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9407 - val_loss: 0.1991 - val_accuracy: 0.9198 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9407 - val_loss: 0.1990 - val_accuracy: 0.9191 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1401 - accuracy: 0.9417 - val_loss: 0.1987 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9420 - val_loss: 0.1986 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1405 - accuracy: 0.9421 - val_loss: 0.1985 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.9415 - val_loss: 0.1983 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1378 - accuracy: 0.9443 - val_loss: 0.1992 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1374 - accuracy: 0.9442 - val_loss: 0.1986 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9430 - val_loss: 0.1986 - val_accuracy: 0.9191 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9407 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1405 - accuracy: 0.9429 - val_loss: 0.1983 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1407 - accuracy: 0.9410 - val_loss: 0.1985 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9415 - val_loss: 0.1987 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1382 - accuracy: 0.9410 - val_loss: 0.1985 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1403 - accuracy: 0.9434 - val_loss: 0.1985 - val_accuracy: 0.9179 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9417 - val_loss: 0.1986 - val_accuracy: 0.9179 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1401 - accuracy: 0.9419 - val_loss: 0.1986 - val_accuracy: 0.9187 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1382 - accuracy: 0.9439 - val_loss: 0.1985 - val_accuracy: 0.9187 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9446 - val_loss: 0.1986 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9434 - val_loss: 0.1985 - val_accuracy: 0.9179 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1368 - accuracy: 0.9447 - val_loss: 0.1985 - val_accuracy: 0.9179 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1392 - accuracy: 0.9441 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1351 - accuracy: 0.9443 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1380 - accuracy: 0.9446 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1394 - accuracy: 0.9443 - val_loss: 0.1986 - val_accuracy: 0.9179 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9434 - val_loss: 0.1986 - val_accuracy: 0.9179 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9429 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1380 - accuracy: 0.9441 - val_loss: 0.1985 - val_accuracy: 0.9179 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 5s 2ms/step\n",
            "0.9155313351498637 0.9278937381404174 0.895748987854251 0.821960039320886 0.9118213629973342 0.9733820392464155\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6431 - accuracy: 0.8289 - val_loss: 0.3311 - val_accuracy: 0.8599 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.2810 - accuracy: 0.8832"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2684 - accuracy: 0.8849 - val_loss: 0.2440 - val_accuracy: 0.8984 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2293 - accuracy: 0.9007 - val_loss: 0.2362 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2188 - accuracy: 0.9057 - val_loss: 0.2325 - val_accuracy: 0.9011 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9094 - val_loss: 0.2180 - val_accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1933 - accuracy: 0.9189 - val_loss: 0.2150 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1848 - accuracy: 0.9209 - val_loss: 0.2147 - val_accuracy: 0.9116 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9245 - val_loss: 0.2227 - val_accuracy: 0.9039 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1681 - accuracy: 0.9311 - val_loss: 0.2162 - val_accuracy: 0.9116 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1644 - accuracy: 0.9303 - val_loss: 0.2122 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1599 - accuracy: 0.9316 - val_loss: 0.2161 - val_accuracy: 0.9155 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9369 - val_loss: 0.2114 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9381 - val_loss: 0.2142 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9398 - val_loss: 0.2114 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1423 - accuracy: 0.9424 - val_loss: 0.2129 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9436 - val_loss: 0.2101 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1382 - accuracy: 0.9432 - val_loss: 0.2132 - val_accuracy: 0.9144 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1351 - accuracy: 0.9468 - val_loss: 0.2108 - val_accuracy: 0.9179 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.9451 - val_loss: 0.2119 - val_accuracy: 0.9159 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9449 - val_loss: 0.2083 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1306 - accuracy: 0.9480 - val_loss: 0.2081 - val_accuracy: 0.9186 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1316 - accuracy: 0.9472 - val_loss: 0.2086 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9490 - val_loss: 0.2096 - val_accuracy: 0.9151 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1275 - accuracy: 0.9504 - val_loss: 0.2090 - val_accuracy: 0.9190 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1252 - accuracy: 0.9511 - val_loss: 0.2094 - val_accuracy: 0.9186 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9480 - val_loss: 0.2095 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1259 - accuracy: 0.9487 - val_loss: 0.2092 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1298 - accuracy: 0.9476 - val_loss: 0.2095 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9485 - val_loss: 0.2092 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1267 - accuracy: 0.9495 - val_loss: 0.2090 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9475 - val_loss: 0.2090 - val_accuracy: 0.9186 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9484 - val_loss: 0.2090 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1287 - accuracy: 0.9460 - val_loss: 0.2092 - val_accuracy: 0.9194 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9469 - val_loss: 0.2091 - val_accuracy: 0.9190 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9506 - val_loss: 0.2089 - val_accuracy: 0.9190 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1278 - accuracy: 0.9485 - val_loss: 0.2088 - val_accuracy: 0.9179 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9487 - val_loss: 0.2087 - val_accuracy: 0.9186 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9508 - val_loss: 0.2088 - val_accuracy: 0.9190 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1252 - accuracy: 0.9490 - val_loss: 0.2088 - val_accuracy: 0.9190 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9480 - val_loss: 0.2088 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1259 - accuracy: 0.9516 - val_loss: 0.2087 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.9473 - val_loss: 0.2088 - val_accuracy: 0.9186 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9486 - val_loss: 0.2088 - val_accuracy: 0.9186 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9495 - val_loss: 0.2088 - val_accuracy: 0.9186 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1267 - accuracy: 0.9502 - val_loss: 0.2088 - val_accuracy: 0.9190 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9502 - val_loss: 0.2089 - val_accuracy: 0.9190 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9499 - val_loss: 0.2089 - val_accuracy: 0.9190 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9494 - val_loss: 0.2089 - val_accuracy: 0.9186 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9512 - val_loss: 0.2089 - val_accuracy: 0.9186 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1278 - accuracy: 0.9489 - val_loss: 0.2088 - val_accuracy: 0.9190 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9493 - val_loss: 0.2089 - val_accuracy: 0.9186 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1259 - accuracy: 0.9510 - val_loss: 0.2089 - val_accuracy: 0.9186 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1271 - accuracy: 0.9489 - val_loss: 0.2088 - val_accuracy: 0.9190 - lr: 1.6927e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9221789883268483 0.9299323909035033 0.9088016967126193 0.8337581071693698 0.9193670438080613 0.9747282242069635\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5488 - accuracy: 0.8425 - val_loss: 0.3802 - val_accuracy: 0.8763 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 40/241 [===>..........................] - ETA: 0s - loss: 0.2609 - accuracy: 0.8859"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2652 - accuracy: 0.8888 - val_loss: 0.2484 - val_accuracy: 0.9008 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2307 - accuracy: 0.9005 - val_loss: 0.2219 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2177 - accuracy: 0.9087 - val_loss: 0.2359 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9093 - val_loss: 0.2220 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1897 - accuracy: 0.9219 - val_loss: 0.2135 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1824 - accuracy: 0.9223 - val_loss: 0.2086 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9238 - val_loss: 0.2189 - val_accuracy: 0.9039 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1670 - accuracy: 0.9298 - val_loss: 0.2036 - val_accuracy: 0.9140 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1593 - accuracy: 0.9334 - val_loss: 0.2055 - val_accuracy: 0.9078 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9349 - val_loss: 0.2016 - val_accuracy: 0.9101 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1484 - accuracy: 0.9399 - val_loss: 0.2018 - val_accuracy: 0.9160 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9406 - val_loss: 0.2036 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1408 - accuracy: 0.9438 - val_loss: 0.1988 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1406 - accuracy: 0.9421 - val_loss: 0.1996 - val_accuracy: 0.9183 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1397 - accuracy: 0.9445 - val_loss: 0.1987 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1360 - accuracy: 0.9463 - val_loss: 0.2002 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9471 - val_loss: 0.1987 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1332 - accuracy: 0.9454 - val_loss: 0.1997 - val_accuracy: 0.9218 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1292 - accuracy: 0.9497 - val_loss: 0.1979 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1284 - accuracy: 0.9510 - val_loss: 0.1993 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9506 - val_loss: 0.1969 - val_accuracy: 0.9222 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1280 - accuracy: 0.9490 - val_loss: 0.1971 - val_accuracy: 0.9218 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9490 - val_loss: 0.1962 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1243 - accuracy: 0.9486 - val_loss: 0.1970 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9499 - val_loss: 0.1965 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1222 - accuracy: 0.9493 - val_loss: 0.1962 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1244 - accuracy: 0.9524 - val_loss: 0.1967 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9503 - val_loss: 0.1965 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.9523 - val_loss: 0.1962 - val_accuracy: 0.9230 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9506 - val_loss: 0.1956 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1240 - accuracy: 0.9504 - val_loss: 0.1962 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9493 - val_loss: 0.1959 - val_accuracy: 0.9249 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9516 - val_loss: 0.1957 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1254 - accuracy: 0.9497 - val_loss: 0.1957 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9495 - val_loss: 0.1956 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9538 - val_loss: 0.1956 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9525 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9506 - val_loss: 0.1958 - val_accuracy: 0.9241 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1206 - accuracy: 0.9545 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9521 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1234 - accuracy: 0.9515 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9521 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9534 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9526 - val_loss: 0.1958 - val_accuracy: 0.9245 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9528 - val_loss: 0.1958 - val_accuracy: 0.9245 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9190346438302841 0.9409918392969241 0.8831967213114754 0.8275862173655512 0.9120942803041998 0.971320158377327\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 1.0769 - accuracy: 0.6166 - val_loss: 0.6618 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.6655 - accuracy: 0.6194"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6629 - accuracy: 0.6250 - val_loss: 0.6594 - val_accuracy: 0.6304 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6328 - accuracy: 0.6575 - val_loss: 0.5893 - val_accuracy: 0.7066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.6990 - val_loss: 0.6310 - val_accuracy: 0.6677 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6421 - accuracy: 0.6472 - val_loss: 0.5786 - val_accuracy: 0.7082 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.7193 - val_loss: 0.5038 - val_accuracy: 0.7599 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5311 - accuracy: 0.7511 - val_loss: 0.4227 - val_accuracy: 0.8195 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7898 - val_loss: 0.3818 - val_accuracy: 0.8381 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8211 - val_loss: 0.3753 - val_accuracy: 0.8315 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8256 - val_loss: 0.3544 - val_accuracy: 0.8444 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3951 - accuracy: 0.8278 - val_loss: 0.3154 - val_accuracy: 0.8529 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3608 - accuracy: 0.8475 - val_loss: 0.2967 - val_accuracy: 0.8809 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.8543 - val_loss: 0.2947 - val_accuracy: 0.8611 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8545 - val_loss: 0.3491 - val_accuracy: 0.8370 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3183 - accuracy: 0.8643 - val_loss: 0.2762 - val_accuracy: 0.8763 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3161 - accuracy: 0.8664 - val_loss: 0.2650 - val_accuracy: 0.8879 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8680 - val_loss: 0.2825 - val_accuracy: 0.8840 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3015 - accuracy: 0.8712 - val_loss: 0.2658 - val_accuracy: 0.8817 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2914 - accuracy: 0.8756 - val_loss: 0.2841 - val_accuracy: 0.8665 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2937 - accuracy: 0.8740 - val_loss: 0.2538 - val_accuracy: 0.8840 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2821 - accuracy: 0.8796 - val_loss: 0.2591 - val_accuracy: 0.8825 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2856 - accuracy: 0.8797 - val_loss: 0.2535 - val_accuracy: 0.8946 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2853 - accuracy: 0.8788 - val_loss: 0.2580 - val_accuracy: 0.8883 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.8754 - val_loss: 0.2508 - val_accuracy: 0.8965 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8806 - val_loss: 0.2508 - val_accuracy: 0.8868 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2797 - accuracy: 0.8823 - val_loss: 0.2475 - val_accuracy: 0.8946 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2715 - accuracy: 0.8845 - val_loss: 0.2486 - val_accuracy: 0.8957 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2821 - accuracy: 0.8830 - val_loss: 0.2489 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2722 - accuracy: 0.8827 - val_loss: 0.2501 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2768 - accuracy: 0.8801 - val_loss: 0.2466 - val_accuracy: 0.8942 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2799 - accuracy: 0.8783 - val_loss: 0.2471 - val_accuracy: 0.8957 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2786 - accuracy: 0.8806 - val_loss: 0.2466 - val_accuracy: 0.8938 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2732 - accuracy: 0.8836 - val_loss: 0.2473 - val_accuracy: 0.8934 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2743 - accuracy: 0.8828 - val_loss: 0.2464 - val_accuracy: 0.8938 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.8797 - val_loss: 0.2509 - val_accuracy: 0.8840 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2755 - accuracy: 0.8843 - val_loss: 0.2474 - val_accuracy: 0.8961 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2691 - accuracy: 0.8858 - val_loss: 0.2459 - val_accuracy: 0.8953 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2712 - accuracy: 0.8823 - val_loss: 0.2465 - val_accuracy: 0.8984 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2752 - accuracy: 0.8805 - val_loss: 0.2473 - val_accuracy: 0.8922 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2707 - accuracy: 0.8844 - val_loss: 0.2469 - val_accuracy: 0.8969 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2770 - accuracy: 0.8792 - val_loss: 0.2487 - val_accuracy: 0.8965 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2683 - accuracy: 0.8909 - val_loss: 0.2476 - val_accuracy: 0.8953 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2654 - accuracy: 0.8871 - val_loss: 0.2469 - val_accuracy: 0.8946 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2673 - accuracy: 0.8865 - val_loss: 0.2458 - val_accuracy: 0.8981 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.8876 - val_loss: 0.2459 - val_accuracy: 0.8965 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.8834 - val_loss: 0.2466 - val_accuracy: 0.8969 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2688 - accuracy: 0.8858 - val_loss: 0.2472 - val_accuracy: 0.8961 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.8814 - val_loss: 0.2468 - val_accuracy: 0.8953 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.8856 - val_loss: 0.2467 - val_accuracy: 0.8953 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2652 - accuracy: 0.8897 - val_loss: 0.2463 - val_accuracy: 0.8961 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2730 - accuracy: 0.8810 - val_loss: 0.2462 - val_accuracy: 0.8957 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2745 - accuracy: 0.8827 - val_loss: 0.2461 - val_accuracy: 0.8957 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2711 - accuracy: 0.8866 - val_loss: 0.2462 - val_accuracy: 0.8957 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2692 - accuracy: 0.8854 - val_loss: 0.2462 - val_accuracy: 0.8953 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.8859 - val_loss: 0.2461 - val_accuracy: 0.8969 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2719 - accuracy: 0.8857 - val_loss: 0.2462 - val_accuracy: 0.8961 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2703 - accuracy: 0.8876 - val_loss: 0.2462 - val_accuracy: 0.8965 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2680 - accuracy: 0.8872 - val_loss: 0.2462 - val_accuracy: 0.8961 - lr: 6.0936e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.888283378746594 0.9386996904024768 0.8029350104821803 0.7582416630081218 0.8708173504423286 0.9565989056993204\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5399 - accuracy: 0.8128 - val_loss: 0.3321 - val_accuracy: 0.8728 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.2958 - accuracy: 0.8683"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2851 - accuracy: 0.8786 - val_loss: 0.2513 - val_accuracy: 0.8844 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2424 - accuracy: 0.8959 - val_loss: 0.2406 - val_accuracy: 0.8942 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2295 - accuracy: 0.8988 - val_loss: 0.2236 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9058 - val_loss: 0.2168 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2024 - accuracy: 0.9150 - val_loss: 0.2130 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1989 - accuracy: 0.9173 - val_loss: 0.2156 - val_accuracy: 0.9043 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1904 - accuracy: 0.9202 - val_loss: 0.2093 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1764 - accuracy: 0.9255 - val_loss: 0.2096 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1737 - accuracy: 0.9293 - val_loss: 0.2072 - val_accuracy: 0.9117 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1686 - accuracy: 0.9275 - val_loss: 0.2096 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1581 - accuracy: 0.9341 - val_loss: 0.2087 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9351 - val_loss: 0.2080 - val_accuracy: 0.9105 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1522 - accuracy: 0.9355 - val_loss: 0.2047 - val_accuracy: 0.9125 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1467 - accuracy: 0.9394 - val_loss: 0.2085 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9386 - val_loss: 0.2028 - val_accuracy: 0.9101 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1428 - accuracy: 0.9426 - val_loss: 0.2113 - val_accuracy: 0.9086 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9429 - val_loss: 0.2040 - val_accuracy: 0.9086 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9432 - val_loss: 0.2060 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.9434 - val_loss: 0.2064 - val_accuracy: 0.9113 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9436 - val_loss: 0.2054 - val_accuracy: 0.9109 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1345 - accuracy: 0.9438 - val_loss: 0.2058 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1362 - accuracy: 0.9424 - val_loss: 0.2049 - val_accuracy: 0.9125 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.9452 - val_loss: 0.2045 - val_accuracy: 0.9128 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1335 - accuracy: 0.9443 - val_loss: 0.2047 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.9443 - val_loss: 0.2059 - val_accuracy: 0.9117 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1309 - accuracy: 0.9463 - val_loss: 0.2050 - val_accuracy: 0.9121 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1309 - accuracy: 0.9476 - val_loss: 0.2050 - val_accuracy: 0.9117 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1317 - accuracy: 0.9476 - val_loss: 0.2053 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1335 - accuracy: 0.9454 - val_loss: 0.2049 - val_accuracy: 0.9125 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1309 - accuracy: 0.9452 - val_loss: 0.2054 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9467 - val_loss: 0.2053 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9237057220708447 0.9423434593924365 0.8922594142259415 0.8364137764667594 0.917301436809189 0.9765895950008691\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5048 - accuracy: 0.8285 - val_loss: 0.3113 - val_accuracy: 0.8883 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.2859 - accuracy: 0.8743"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2663 - accuracy: 0.8885 - val_loss: 0.2486 - val_accuracy: 0.9016 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2310 - accuracy: 0.9037 - val_loss: 0.2263 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9096 - val_loss: 0.2226 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2074 - accuracy: 0.9102 - val_loss: 0.2182 - val_accuracy: 0.9031 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1886 - accuracy: 0.9231 - val_loss: 0.2131 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1826 - accuracy: 0.9231 - val_loss: 0.2116 - val_accuracy: 0.9144 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1725 - accuracy: 0.9298 - val_loss: 0.2090 - val_accuracy: 0.9175 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9363 - val_loss: 0.2111 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1573 - accuracy: 0.9356 - val_loss: 0.2081 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1514 - accuracy: 0.9375 - val_loss: 0.2031 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9415 - val_loss: 0.2027 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1421 - accuracy: 0.9408 - val_loss: 0.2026 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1370 - accuracy: 0.9451 - val_loss: 0.2013 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1336 - accuracy: 0.9443 - val_loss: 0.2004 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9455 - val_loss: 0.2006 - val_accuracy: 0.9222 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1309 - accuracy: 0.9484 - val_loss: 0.2050 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9511 - val_loss: 0.2012 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9504 - val_loss: 0.2011 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9495 - val_loss: 0.2011 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1255 - accuracy: 0.9511 - val_loss: 0.1997 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9498 - val_loss: 0.1998 - val_accuracy: 0.9272 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9520 - val_loss: 0.2003 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1204 - accuracy: 0.9533 - val_loss: 0.2008 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9520 - val_loss: 0.2009 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9499 - val_loss: 0.2003 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9535 - val_loss: 0.2006 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9539 - val_loss: 0.2015 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1204 - accuracy: 0.9516 - val_loss: 0.2015 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1187 - accuracy: 0.9534 - val_loss: 0.2010 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9516 - val_loss: 0.2007 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9530 - val_loss: 0.2007 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9560 - val_loss: 0.2006 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9550 - val_loss: 0.2008 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9503 - val_loss: 0.2007 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9523 - val_loss: 0.2006 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1171 - accuracy: 0.9551 - val_loss: 0.2006 - val_accuracy: 0.9261 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9541 - val_loss: 0.2005 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9541 - val_loss: 0.2004 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9493 - val_loss: 0.2004 - val_accuracy: 0.9265 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1154 - accuracy: 0.9551 - val_loss: 0.2005 - val_accuracy: 0.9257 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.2004 - val_accuracy: 0.9257 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9159205916699105 0.9405439595192916 0.8765182186234818 0.821648139397275 0.9085310890713867 0.9739742181318134\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4767 - accuracy: 0.8421 - val_loss: 0.4009 - val_accuracy: 0.8867 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 29/241 [==>...........................] - ETA: 0s - loss: 0.2315 - accuracy: 0.8901"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2539 - accuracy: 0.8904 - val_loss: 0.2558 - val_accuracy: 0.8957 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2207 - accuracy: 0.9072 - val_loss: 0.2470 - val_accuracy: 0.8918 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2102 - accuracy: 0.9096 - val_loss: 0.2409 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1973 - accuracy: 0.9155 - val_loss: 0.2171 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9231 - val_loss: 0.2259 - val_accuracy: 0.9054 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1701 - accuracy: 0.9284 - val_loss: 0.2156 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1620 - accuracy: 0.9318 - val_loss: 0.2163 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1500 - accuracy: 0.9351 - val_loss: 0.2076 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9428 - val_loss: 0.2121 - val_accuracy: 0.9155 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1406 - accuracy: 0.9410 - val_loss: 0.2143 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1311 - accuracy: 0.9445 - val_loss: 0.2074 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1292 - accuracy: 0.9476 - val_loss: 0.2082 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1271 - accuracy: 0.9482 - val_loss: 0.2047 - val_accuracy: 0.9179 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9516 - val_loss: 0.2081 - val_accuracy: 0.9179 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1213 - accuracy: 0.9520 - val_loss: 0.2074 - val_accuracy: 0.9229 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9538 - val_loss: 0.2085 - val_accuracy: 0.9221 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9543 - val_loss: 0.2075 - val_accuracy: 0.9186 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9567 - val_loss: 0.2069 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1123 - accuracy: 0.9581 - val_loss: 0.2068 - val_accuracy: 0.9194 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9558 - val_loss: 0.2057 - val_accuracy: 0.9221 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9568 - val_loss: 0.2074 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9585 - val_loss: 0.2068 - val_accuracy: 0.9206 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.2073 - val_accuracy: 0.9206 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9565 - val_loss: 0.2067 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9574 - val_loss: 0.2080 - val_accuracy: 0.9221 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9603 - val_loss: 0.2076 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9607 - val_loss: 0.2077 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9619 - val_loss: 0.2072 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9599 - val_loss: 0.2075 - val_accuracy: 0.9214 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9218 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9599 - val_loss: 0.2077 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9620 - val_loss: 0.2077 - val_accuracy: 0.9210 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9600 - val_loss: 0.2076 - val_accuracy: 0.9214 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9608 - val_loss: 0.2074 - val_accuracy: 0.9218 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9617 - val_loss: 0.2075 - val_accuracy: 0.9210 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9595 - val_loss: 0.2074 - val_accuracy: 0.9214 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9608 - val_loss: 0.2074 - val_accuracy: 0.9210 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9621 - val_loss: 0.2075 - val_accuracy: 0.9214 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9598 - val_loss: 0.2074 - val_accuracy: 0.9210 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9593 - val_loss: 0.2075 - val_accuracy: 0.9210 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9582 - val_loss: 0.2075 - val_accuracy: 0.9218 - lr: 7.8364e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9252918287937744 0.9305470190534727 0.9162248144220573 0.840738347055839 0.9233859167377649 0.9766783487294535\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5414 - accuracy: 0.8411 - val_loss: 0.3734 - val_accuracy: 0.8790 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 29/241 [==>...........................] - ETA: 0s - loss: 0.2432 - accuracy: 0.8998"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2588 - accuracy: 0.8896 - val_loss: 0.2404 - val_accuracy: 0.9019 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2229 - accuracy: 0.9059 - val_loss: 0.2377 - val_accuracy: 0.8895 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9114 - val_loss: 0.2425 - val_accuracy: 0.8977 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9171 - val_loss: 0.2202 - val_accuracy: 0.9086 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1744 - accuracy: 0.9282 - val_loss: 0.2081 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1736 - accuracy: 0.9253 - val_loss: 0.2097 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9323 - val_loss: 0.2071 - val_accuracy: 0.9144 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9358 - val_loss: 0.1991 - val_accuracy: 0.9160 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9402 - val_loss: 0.1964 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9407 - val_loss: 0.1951 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9433 - val_loss: 0.1967 - val_accuracy: 0.9187 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1311 - accuracy: 0.9473 - val_loss: 0.1921 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9469 - val_loss: 0.1958 - val_accuracy: 0.9187 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1274 - accuracy: 0.9481 - val_loss: 0.1922 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9499 - val_loss: 0.1936 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.9551 - val_loss: 0.1947 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9552 - val_loss: 0.1920 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9560 - val_loss: 0.1930 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9561 - val_loss: 0.1937 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9555 - val_loss: 0.1938 - val_accuracy: 0.9214 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9564 - val_loss: 0.1929 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.9587 - val_loss: 0.1923 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9574 - val_loss: 0.1928 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.9569 - val_loss: 0.1927 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9598 - val_loss: 0.1917 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9590 - val_loss: 0.1914 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9596 - val_loss: 0.1917 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9593 - val_loss: 0.1917 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9600 - val_loss: 0.1922 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9572 - val_loss: 0.1925 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9569 - val_loss: 0.1924 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9608 - val_loss: 0.1925 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.1924 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9604 - val_loss: 0.1926 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9587 - val_loss: 0.1926 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9613 - val_loss: 0.1924 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9635 - val_loss: 0.1924 - val_accuracy: 0.9237 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9598 - val_loss: 0.1925 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9630 - val_loss: 0.1924 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9617 - val_loss: 0.1924 - val_accuracy: 0.9237 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9616 - val_loss: 0.1924 - val_accuracy: 0.9237 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9616 - val_loss: 0.1924 - val_accuracy: 0.9237 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9581 - val_loss: 0.1924 - val_accuracy: 0.9237 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9621 - val_loss: 0.1925 - val_accuracy: 0.9233 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9586 - val_loss: 0.1924 - val_accuracy: 0.9237 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9619 - val_loss: 0.1924 - val_accuracy: 0.9233 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9225379525107046 0.9409918392969241 0.8924180327868853 0.8352675291690073 0.9167049360419046 0.9722913643707615\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.4920 - accuracy: 0.8353 - val_loss: 0.3377 - val_accuracy: 0.8899 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 29/241 [==>...........................] - ETA: 0s - loss: 0.2953 - accuracy: 0.8761"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2568 - accuracy: 0.8911 - val_loss: 0.2495 - val_accuracy: 0.9058 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9089 - val_loss: 0.2333 - val_accuracy: 0.9047 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9127 - val_loss: 0.2187 - val_accuracy: 0.9128 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1932 - accuracy: 0.9202 - val_loss: 0.2104 - val_accuracy: 0.9132 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1714 - accuracy: 0.9259 - val_loss: 0.2113 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9319 - val_loss: 0.2056 - val_accuracy: 0.9152 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9345 - val_loss: 0.2067 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1467 - accuracy: 0.9384 - val_loss: 0.2025 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1414 - accuracy: 0.9411 - val_loss: 0.1970 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9460 - val_loss: 0.2062 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9476 - val_loss: 0.1950 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1224 - accuracy: 0.9517 - val_loss: 0.2002 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1231 - accuracy: 0.9494 - val_loss: 0.2017 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1175 - accuracy: 0.9532 - val_loss: 0.1963 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9528 - val_loss: 0.1953 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9568 - val_loss: 0.1950 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9561 - val_loss: 0.1965 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1076 - accuracy: 0.9568 - val_loss: 0.1976 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1072 - accuracy: 0.9598 - val_loss: 0.1986 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9574 - val_loss: 0.1959 - val_accuracy: 0.9218 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9602 - val_loss: 0.1969 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9608 - val_loss: 0.1976 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9638 - val_loss: 0.1969 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1006 - accuracy: 0.9626 - val_loss: 0.1975 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9624 - val_loss: 0.1977 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9621 - val_loss: 0.1975 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9639 - val_loss: 0.1975 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9644 - val_loss: 0.1977 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9622 - val_loss: 0.1977 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9635 - val_loss: 0.1981 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9612 - val_loss: 0.1980 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9642 - val_loss: 0.1979 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9622 - val_loss: 0.1979 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9630 - val_loss: 0.1980 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0951 - accuracy: 0.9652 - val_loss: 0.1981 - val_accuracy: 0.9237 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9638 - val_loss: 0.1980 - val_accuracy: 0.9237 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9639 - val_loss: 0.1981 - val_accuracy: 0.9230 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9628 - val_loss: 0.1980 - val_accuracy: 0.9237 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9643 - val_loss: 0.1981 - val_accuracy: 0.9237 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9635 - val_loss: 0.1980 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: 0.1979 - val_accuracy: 0.9237 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9634 - val_loss: 0.1981 - val_accuracy: 0.9237 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0960 - accuracy: 0.9624 - val_loss: 0.1981 - val_accuracy: 0.9233 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9621 - val_loss: 0.1980 - val_accuracy: 0.9237 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9642 - val_loss: 0.1980 - val_accuracy: 0.9230 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9147528221097704 0.9393188854489164 0.8731656184486373 0.8166646329509426 0.9062422519487768 0.9692463215011261\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5394 - accuracy: 0.8305 - val_loss: 0.3713 - val_accuracy: 0.8704 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 29/241 [==>...........................] - ETA: 0s - loss: 0.2921 - accuracy: 0.8879"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2680 - accuracy: 0.8884 - val_loss: 0.2679 - val_accuracy: 0.8856 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2339 - accuracy: 0.9014 - val_loss: 0.2254 - val_accuracy: 0.9008 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2207 - accuracy: 0.9061 - val_loss: 0.2500 - val_accuracy: 0.8934 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2110 - accuracy: 0.9131 - val_loss: 0.2177 - val_accuracy: 0.9054 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1900 - accuracy: 0.9173 - val_loss: 0.2168 - val_accuracy: 0.9047 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1827 - accuracy: 0.9241 - val_loss: 0.2064 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1753 - accuracy: 0.9264 - val_loss: 0.2128 - val_accuracy: 0.9089 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9350 - val_loss: 0.2096 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1572 - accuracy: 0.9368 - val_loss: 0.2063 - val_accuracy: 0.9140 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1496 - accuracy: 0.9395 - val_loss: 0.2155 - val_accuracy: 0.9066 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1425 - accuracy: 0.9419 - val_loss: 0.2100 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1390 - accuracy: 0.9458 - val_loss: 0.2120 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9458 - val_loss: 0.2105 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9504 - val_loss: 0.2111 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9494 - val_loss: 0.2103 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9500 - val_loss: 0.2101 - val_accuracy: 0.9171 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1218 - accuracy: 0.9516 - val_loss: 0.2100 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1222 - accuracy: 0.9529 - val_loss: 0.2097 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9520 - val_loss: 0.2124 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9545 - val_loss: 0.2128 - val_accuracy: 0.9128 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1143 - accuracy: 0.9565 - val_loss: 0.2104 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9554 - val_loss: 0.2137 - val_accuracy: 0.9117 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1136 - accuracy: 0.9580 - val_loss: 0.2121 - val_accuracy: 0.9128 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9556 - val_loss: 0.2111 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9559 - val_loss: 0.2111 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9556 - val_loss: 0.2113 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9586 - val_loss: 0.2112 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9583 - val_loss: 0.2114 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9565 - val_loss: 0.2110 - val_accuracy: 0.9136 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9564 - val_loss: 0.2119 - val_accuracy: 0.9109 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9573 - val_loss: 0.2117 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9581 - val_loss: 0.2118 - val_accuracy: 0.9109 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1114 - accuracy: 0.9569 - val_loss: 0.2120 - val_accuracy: 0.9101 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9589 - val_loss: 0.2124 - val_accuracy: 0.9105 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.9582 - val_loss: 0.2123 - val_accuracy: 0.9109 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9589 - val_loss: 0.2123 - val_accuracy: 0.9109 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9283768003114052 0.9417234965902046 0.9058577405857741 0.8468643002498032 0.9237906185879894 0.9782286702965187\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5409 - accuracy: 0.8106 - val_loss: 0.3304 - val_accuracy: 0.8790 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2699 - accuracy: 0.8796"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2717 - accuracy: 0.8835 - val_loss: 0.2502 - val_accuracy: 0.9000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2309 - accuracy: 0.9039 - val_loss: 0.2248 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9093 - val_loss: 0.2222 - val_accuracy: 0.9140 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9138 - val_loss: 0.2179 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.9234 - val_loss: 0.2097 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1797 - accuracy: 0.9240 - val_loss: 0.2064 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9262 - val_loss: 0.2094 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1628 - accuracy: 0.9345 - val_loss: 0.2041 - val_accuracy: 0.9148 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1569 - accuracy: 0.9369 - val_loss: 0.2004 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1536 - accuracy: 0.9324 - val_loss: 0.2054 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.9436 - val_loss: 0.1977 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1423 - accuracy: 0.9443 - val_loss: 0.2027 - val_accuracy: 0.9230 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1406 - accuracy: 0.9420 - val_loss: 0.2034 - val_accuracy: 0.9198 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1344 - accuracy: 0.9471 - val_loss: 0.2011 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1320 - accuracy: 0.9482 - val_loss: 0.2015 - val_accuracy: 0.9183 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1302 - accuracy: 0.9462 - val_loss: 0.1972 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1258 - accuracy: 0.9526 - val_loss: 0.1987 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.9500 - val_loss: 0.1968 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1190 - accuracy: 0.9533 - val_loss: 0.1975 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9539 - val_loss: 0.1965 - val_accuracy: 0.9268 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9529 - val_loss: 0.1976 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1219 - accuracy: 0.9547 - val_loss: 0.1976 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9551 - val_loss: 0.1966 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9534 - val_loss: 0.1972 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9532 - val_loss: 0.1965 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9554 - val_loss: 0.1964 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9550 - val_loss: 0.1960 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1196 - accuracy: 0.9542 - val_loss: 0.1958 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9560 - val_loss: 0.1959 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9545 - val_loss: 0.1958 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9532 - val_loss: 0.1959 - val_accuracy: 0.9288 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9567 - val_loss: 0.1957 - val_accuracy: 0.9280 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9542 - val_loss: 0.1956 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1142 - accuracy: 0.9552 - val_loss: 0.1958 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9574 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9532 - val_loss: 0.1958 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9532 - val_loss: 0.1956 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1170 - accuracy: 0.9551 - val_loss: 0.1956 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1137 - accuracy: 0.9574 - val_loss: 0.1957 - val_accuracy: 0.9265 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1147 - accuracy: 0.9552 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9564 - val_loss: 0.1958 - val_accuracy: 0.9265 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1142 - accuracy: 0.9565 - val_loss: 0.1958 - val_accuracy: 0.9261 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1134 - accuracy: 0.9555 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1166 - accuracy: 0.9560 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9583 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9582 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9546 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9554 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9556 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9567 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9563 - val_loss: 0.1958 - val_accuracy: 0.9268 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9217594394706111 0.9361163820366857 0.8987854251012146 0.8347436405037907 0.9174509035689502 0.976783386725462\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5152 - accuracy: 0.8320 - val_loss: 0.3387 - val_accuracy: 0.8828 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2480 - accuracy: 0.8935"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2620 - accuracy: 0.8888 - val_loss: 0.2533 - val_accuracy: 0.8902 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2177 - accuracy: 0.9072 - val_loss: 0.2300 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9119 - val_loss: 0.2289 - val_accuracy: 0.9050 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1917 - accuracy: 0.9192 - val_loss: 0.2149 - val_accuracy: 0.9120 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1764 - accuracy: 0.9264 - val_loss: 0.2151 - val_accuracy: 0.9112 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9299 - val_loss: 0.2159 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9315 - val_loss: 0.2251 - val_accuracy: 0.9066 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1488 - accuracy: 0.9388 - val_loss: 0.2093 - val_accuracy: 0.9183 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1417 - accuracy: 0.9404 - val_loss: 0.2275 - val_accuracy: 0.9112 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1409 - accuracy: 0.9419 - val_loss: 0.2054 - val_accuracy: 0.9233 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1327 - accuracy: 0.9460 - val_loss: 0.2069 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9489 - val_loss: 0.2073 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.9499 - val_loss: 0.2061 - val_accuracy: 0.9253 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9528 - val_loss: 0.2058 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9547 - val_loss: 0.2076 - val_accuracy: 0.9229 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1150 - accuracy: 0.9516 - val_loss: 0.2072 - val_accuracy: 0.9229 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.9538 - val_loss: 0.2077 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9561 - val_loss: 0.2064 - val_accuracy: 0.9218 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9565 - val_loss: 0.2054 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9574 - val_loss: 0.2055 - val_accuracy: 0.9225 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9594 - val_loss: 0.2052 - val_accuracy: 0.9225 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9580 - val_loss: 0.2042 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1058 - accuracy: 0.9598 - val_loss: 0.2046 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1054 - accuracy: 0.9599 - val_loss: 0.2043 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9600 - val_loss: 0.2058 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1046 - accuracy: 0.9602 - val_loss: 0.2057 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9594 - val_loss: 0.2056 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1007 - accuracy: 0.9613 - val_loss: 0.2054 - val_accuracy: 0.9221 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 0.2058 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9613 - val_loss: 0.2057 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1026 - accuracy: 0.9593 - val_loss: 0.2057 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9594 - val_loss: 0.2057 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9606 - val_loss: 0.2058 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9210116731517509 0.9256299938537185 0.9130434782608695 0.8318816337466185 0.9193367360572939 0.9763364903363899\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.7089 - accuracy: 0.8324 - val_loss: 0.3043 - val_accuracy: 0.8883 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 29/241 [==>...........................] - ETA: 0s - loss: 0.2546 - accuracy: 0.8804"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2568 - accuracy: 0.8891 - val_loss: 0.2359 - val_accuracy: 0.9000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2203 - accuracy: 0.9093 - val_loss: 0.2237 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9159 - val_loss: 0.2226 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9183 - val_loss: 0.2138 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1746 - accuracy: 0.9301 - val_loss: 0.2179 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1713 - accuracy: 0.9258 - val_loss: 0.2059 - val_accuracy: 0.9144 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1608 - accuracy: 0.9343 - val_loss: 0.2036 - val_accuracy: 0.9222 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9376 - val_loss: 0.2008 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9384 - val_loss: 0.2014 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9406 - val_loss: 0.2102 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1374 - accuracy: 0.9441 - val_loss: 0.2003 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1298 - accuracy: 0.9485 - val_loss: 0.2002 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1321 - accuracy: 0.9477 - val_loss: 0.1970 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9511 - val_loss: 0.2002 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1206 - accuracy: 0.9520 - val_loss: 0.1978 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.9534 - val_loss: 0.1970 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1161 - accuracy: 0.9580 - val_loss: 0.1982 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1157 - accuracy: 0.9538 - val_loss: 0.1981 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1969 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9543 - val_loss: 0.1968 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9568 - val_loss: 0.1969 - val_accuracy: 0.9230 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1159 - accuracy: 0.9550 - val_loss: 0.1952 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9565 - val_loss: 0.1955 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9567 - val_loss: 0.1966 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9554 - val_loss: 0.1965 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9574 - val_loss: 0.1969 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9574 - val_loss: 0.1965 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1121 - accuracy: 0.9560 - val_loss: 0.1960 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9582 - val_loss: 0.1962 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.9624 - val_loss: 0.1965 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9581 - val_loss: 0.1966 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1081 - accuracy: 0.9590 - val_loss: 0.1966 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9569 - val_loss: 0.1964 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9599 - val_loss: 0.1965 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9599 - val_loss: 0.1966 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9587 - val_loss: 0.1968 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1094 - accuracy: 0.9564 - val_loss: 0.1968 - val_accuracy: 0.9249 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9609 - val_loss: 0.1967 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.920591669910471 0.943502824858757 0.8831967213114754 0.830820132412488 0.9133497730851162 0.9716185951859057\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.8976 - accuracy: 0.8204 - val_loss: 0.3116 - val_accuracy: 0.8541 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 30/241 [==>...........................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8677"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2709 - accuracy: 0.8831 - val_loss: 0.2521 - val_accuracy: 0.8809 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2294 - accuracy: 0.9007 - val_loss: 0.2373 - val_accuracy: 0.8953 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9054 - val_loss: 0.2269 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9111 - val_loss: 0.2245 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1933 - accuracy: 0.9173 - val_loss: 0.2108 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1824 - accuracy: 0.9220 - val_loss: 0.2290 - val_accuracy: 0.8984 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9254 - val_loss: 0.2148 - val_accuracy: 0.9023 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1692 - accuracy: 0.9281 - val_loss: 0.2050 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1580 - accuracy: 0.9350 - val_loss: 0.2041 - val_accuracy: 0.9156 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1571 - accuracy: 0.9360 - val_loss: 0.2015 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.9372 - val_loss: 0.1977 - val_accuracy: 0.9171 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9414 - val_loss: 0.2016 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9411 - val_loss: 0.1975 - val_accuracy: 0.9198 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1390 - accuracy: 0.9429 - val_loss: 0.1980 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9459 - val_loss: 0.1961 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9467 - val_loss: 0.1975 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9495 - val_loss: 0.1960 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9494 - val_loss: 0.1966 - val_accuracy: 0.9183 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1271 - accuracy: 0.9481 - val_loss: 0.1968 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9513 - val_loss: 0.1979 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9512 - val_loss: 0.1958 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1242 - accuracy: 0.9515 - val_loss: 0.1956 - val_accuracy: 0.9195 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1242 - accuracy: 0.9525 - val_loss: 0.1954 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1214 - accuracy: 0.9545 - val_loss: 0.1952 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1236 - accuracy: 0.9526 - val_loss: 0.1953 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1212 - accuracy: 0.9530 - val_loss: 0.1952 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1190 - accuracy: 0.9529 - val_loss: 0.1953 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1193 - accuracy: 0.9539 - val_loss: 0.1953 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9548 - val_loss: 0.1955 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1217 - accuracy: 0.9524 - val_loss: 0.1952 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9537 - val_loss: 0.1953 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9521 - val_loss: 0.1952 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9525 - val_loss: 0.1951 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9112495134293499 0.9529411764705882 0.8406708595387841 0.8084434275691016 0.8968060180046862 0.9706304236358563\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.6623 - accuracy: 0.8119 - val_loss: 0.3058 - val_accuracy: 0.8696 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 26/241 [==>...........................] - ETA: 0s - loss: 0.2762 - accuracy: 0.8870"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2766 - accuracy: 0.8800 - val_loss: 0.2681 - val_accuracy: 0.8747 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2394 - accuracy: 0.8984 - val_loss: 0.2480 - val_accuracy: 0.8895 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2226 - accuracy: 0.9037 - val_loss: 0.2256 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9090 - val_loss: 0.2174 - val_accuracy: 0.9054 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9224 - val_loss: 0.2235 - val_accuracy: 0.8965 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1908 - accuracy: 0.9192 - val_loss: 0.2136 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1760 - accuracy: 0.9268 - val_loss: 0.2171 - val_accuracy: 0.9054 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1709 - accuracy: 0.9281 - val_loss: 0.2095 - val_accuracy: 0.9058 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1605 - accuracy: 0.9341 - val_loss: 0.2092 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9336 - val_loss: 0.2061 - val_accuracy: 0.9093 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1472 - accuracy: 0.9402 - val_loss: 0.2031 - val_accuracy: 0.9086 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1469 - accuracy: 0.9419 - val_loss: 0.2038 - val_accuracy: 0.9082 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9401 - val_loss: 0.2052 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1422 - accuracy: 0.9426 - val_loss: 0.2041 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1390 - accuracy: 0.9437 - val_loss: 0.2027 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1360 - accuracy: 0.9462 - val_loss: 0.2065 - val_accuracy: 0.9105 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9475 - val_loss: 0.2073 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9486 - val_loss: 0.2048 - val_accuracy: 0.9101 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9495 - val_loss: 0.2047 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1297 - accuracy: 0.9489 - val_loss: 0.2066 - val_accuracy: 0.9086 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1298 - accuracy: 0.9481 - val_loss: 0.2048 - val_accuracy: 0.9117 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1275 - accuracy: 0.9481 - val_loss: 0.2048 - val_accuracy: 0.9089 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9524 - val_loss: 0.2048 - val_accuracy: 0.9117 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1249 - accuracy: 0.9489 - val_loss: 0.2050 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1223 - accuracy: 0.9515 - val_loss: 0.2062 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1220 - accuracy: 0.9530 - val_loss: 0.2058 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9524 - val_loss: 0.2060 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1244 - accuracy: 0.9506 - val_loss: 0.2053 - val_accuracy: 0.9121 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9541 - val_loss: 0.2057 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1212 - accuracy: 0.9530 - val_loss: 0.2056 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9530 - val_loss: 0.2054 - val_accuracy: 0.9121 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9543 - val_loss: 0.2053 - val_accuracy: 0.9113 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.9545 - val_loss: 0.2054 - val_accuracy: 0.9117 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 5s 2ms/step\n",
            "0.9256520046710782 0.9404835709857409 0.9006276150627615 0.8409323329560674 0.9205555930242512 0.9780211513669013\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.8865 - accuracy: 0.8122 - val_loss: 0.3002 - val_accuracy: 0.8864 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.2945 - accuracy: 0.8795"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2726 - accuracy: 0.8837 - val_loss: 0.2498 - val_accuracy: 0.8891 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2337 - accuracy: 0.9031 - val_loss: 0.2242 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2203 - accuracy: 0.9049 - val_loss: 0.2276 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9118 - val_loss: 0.2264 - val_accuracy: 0.9051 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1927 - accuracy: 0.9189 - val_loss: 0.2136 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1828 - accuracy: 0.9240 - val_loss: 0.2095 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.9249 - val_loss: 0.2065 - val_accuracy: 0.9171 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1660 - accuracy: 0.9294 - val_loss: 0.2069 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1643 - accuracy: 0.9330 - val_loss: 0.2028 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1602 - accuracy: 0.9316 - val_loss: 0.2015 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.9382 - val_loss: 0.1997 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1537 - accuracy: 0.9373 - val_loss: 0.2030 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1477 - accuracy: 0.9395 - val_loss: 0.2048 - val_accuracy: 0.9198 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1416 - accuracy: 0.9424 - val_loss: 0.1989 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1410 - accuracy: 0.9421 - val_loss: 0.1956 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1411 - accuracy: 0.9458 - val_loss: 0.1970 - val_accuracy: 0.9288 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1366 - accuracy: 0.9445 - val_loss: 0.1965 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1355 - accuracy: 0.9454 - val_loss: 0.1971 - val_accuracy: 0.9261 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1323 - accuracy: 0.9476 - val_loss: 0.1969 - val_accuracy: 0.9276 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1304 - accuracy: 0.9475 - val_loss: 0.1965 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1316 - accuracy: 0.9476 - val_loss: 0.1957 - val_accuracy: 0.9265 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9510 - val_loss: 0.1969 - val_accuracy: 0.9265 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9472 - val_loss: 0.1967 - val_accuracy: 0.9272 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1302 - accuracy: 0.9498 - val_loss: 0.1965 - val_accuracy: 0.9276 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1281 - accuracy: 0.9494 - val_loss: 0.1967 - val_accuracy: 0.9284 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1271 - accuracy: 0.9510 - val_loss: 0.1961 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9473 - val_loss: 0.1964 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9508 - val_loss: 0.1965 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1238 - accuracy: 0.9517 - val_loss: 0.1965 - val_accuracy: 0.9284 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9525 - val_loss: 0.1963 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9497 - val_loss: 0.1964 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1273 - accuracy: 0.9507 - val_loss: 0.1963 - val_accuracy: 0.9284 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1267 - accuracy: 0.9497 - val_loss: 0.1964 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9523 - val_loss: 0.1964 - val_accuracy: 0.9288 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1252 - accuracy: 0.9523 - val_loss: 0.1965 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9507 - val_loss: 0.1965 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1253 - accuracy: 0.9507 - val_loss: 0.1967 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1224 - accuracy: 0.9507 - val_loss: 0.1966 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9482 - val_loss: 0.1967 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1297 - accuracy: 0.9480 - val_loss: 0.1966 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9481 - val_loss: 0.1965 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1236 - accuracy: 0.9511 - val_loss: 0.1966 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9497 - val_loss: 0.1965 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9511 - val_loss: 0.1965 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1236 - accuracy: 0.9500 - val_loss: 0.1966 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.9541 - val_loss: 0.1966 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9209809264305178 0.9386464263124604 0.8927125506072875 0.8328045510450356 0.915679488459874 0.9752827734201948\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 1.0175 - accuracy: 0.8323"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 7s 23ms/step - loss: 1.0147 - accuracy: 0.8325 - val_loss: 0.2907 - val_accuracy: 0.8879 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2561 - accuracy: 0.8885 - val_loss: 0.2565 - val_accuracy: 0.8844 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2107 - accuracy: 0.9076 - val_loss: 0.2216 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1935 - accuracy: 0.9203 - val_loss: 0.2434 - val_accuracy: 0.8945 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1807 - accuracy: 0.9203 - val_loss: 0.2179 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1585 - accuracy: 0.9318 - val_loss: 0.2092 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1481 - accuracy: 0.9359 - val_loss: 0.2192 - val_accuracy: 0.9116 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1430 - accuracy: 0.9403 - val_loss: 0.2134 - val_accuracy: 0.9120 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1244 - accuracy: 0.9494 - val_loss: 0.2053 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1155 - accuracy: 0.9524 - val_loss: 0.2037 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1093 - accuracy: 0.9552 - val_loss: 0.2097 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1013 - accuracy: 0.9604 - val_loss: 0.1992 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0952 - accuracy: 0.9633 - val_loss: 0.2073 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0926 - accuracy: 0.9626 - val_loss: 0.2139 - val_accuracy: 0.9155 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0853 - accuracy: 0.9685 - val_loss: 0.2095 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0811 - accuracy: 0.9699 - val_loss: 0.2033 - val_accuracy: 0.9264 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0797 - accuracy: 0.9708 - val_loss: 0.2037 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0737 - accuracy: 0.9753 - val_loss: 0.2076 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 0.2061 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0708 - accuracy: 0.9751 - val_loss: 0.2077 - val_accuracy: 0.9229 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0681 - accuracy: 0.9759 - val_loss: 0.2072 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0664 - accuracy: 0.9792 - val_loss: 0.2099 - val_accuracy: 0.9225 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0670 - accuracy: 0.9766 - val_loss: 0.2092 - val_accuracy: 0.9221 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0643 - accuracy: 0.9794 - val_loss: 0.2086 - val_accuracy: 0.9229 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0657 - accuracy: 0.9786 - val_loss: 0.2089 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0633 - accuracy: 0.9792 - val_loss: 0.2101 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.2097 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.2109 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.2106 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.2105 - val_accuracy: 0.9229 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0620 - accuracy: 0.9805 - val_loss: 0.2104 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.2104 - val_accuracy: 0.9229 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.2105 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0603 - accuracy: 0.9799 - val_loss: 0.2103 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0605 - accuracy: 0.9804 - val_loss: 0.2101 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.2103 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9264591439688716 0.9354640442532268 0.9109225874867445 0.8425722094408281 0.9231933158699857 0.9760832739670761\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 4.0200 - accuracy: 0.6057"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 6s 22ms/step - loss: 4.0090 - accuracy: 0.6056 - val_loss: 0.6992 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.6836 - accuracy: 0.6289 - val_loss: 0.6575 - val_accuracy: 0.6354 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.6392 - accuracy: 0.6578 - val_loss: 0.5866 - val_accuracy: 0.7054 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.6222 - accuracy: 0.6786 - val_loss: 0.6596 - val_accuracy: 0.7109 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.5791 - accuracy: 0.7020 - val_loss: 0.5258 - val_accuracy: 0.7350 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.4219 - accuracy: 0.7990 - val_loss: 0.3443 - val_accuracy: 0.8346 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.3479 - accuracy: 0.8424 - val_loss: 0.3072 - val_accuracy: 0.8564 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.3088 - accuracy: 0.8677 - val_loss: 0.2692 - val_accuracy: 0.8840 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2717 - accuracy: 0.8871 - val_loss: 0.2721 - val_accuracy: 0.8770 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 5s 19ms/step - loss: 0.2577 - accuracy: 0.8931 - val_loss: 0.2485 - val_accuracy: 0.8926 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2535 - accuracy: 0.8939 - val_loss: 0.2416 - val_accuracy: 0.9066 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2368 - accuracy: 0.8992 - val_loss: 0.2359 - val_accuracy: 0.9031 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2283 - accuracy: 0.9062 - val_loss: 0.2312 - val_accuracy: 0.9051 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2243 - accuracy: 0.9040 - val_loss: 0.2268 - val_accuracy: 0.9089 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2111 - accuracy: 0.9107 - val_loss: 0.2248 - val_accuracy: 0.9101 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2099 - accuracy: 0.9112 - val_loss: 0.2237 - val_accuracy: 0.9054 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2085 - accuracy: 0.9142 - val_loss: 0.2252 - val_accuracy: 0.9086 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2050 - accuracy: 0.9150 - val_loss: 0.2204 - val_accuracy: 0.9097 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2001 - accuracy: 0.9184 - val_loss: 0.2192 - val_accuracy: 0.9093 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2025 - accuracy: 0.9149 - val_loss: 0.2151 - val_accuracy: 0.9093 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1962 - accuracy: 0.9168 - val_loss: 0.2164 - val_accuracy: 0.9117 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1936 - accuracy: 0.9199 - val_loss: 0.2172 - val_accuracy: 0.9082 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1940 - accuracy: 0.9186 - val_loss: 0.2161 - val_accuracy: 0.9089 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1886 - accuracy: 0.9224 - val_loss: 0.2156 - val_accuracy: 0.9082 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1916 - accuracy: 0.9193 - val_loss: 0.2146 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1900 - accuracy: 0.9190 - val_loss: 0.2144 - val_accuracy: 0.9109 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1898 - accuracy: 0.9184 - val_loss: 0.2145 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1852 - accuracy: 0.9220 - val_loss: 0.2153 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1876 - accuracy: 0.9210 - val_loss: 0.2154 - val_accuracy: 0.9101 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1837 - accuracy: 0.9219 - val_loss: 0.2147 - val_accuracy: 0.9097 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1809 - accuracy: 0.9272 - val_loss: 0.2143 - val_accuracy: 0.9121 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1823 - accuracy: 0.9249 - val_loss: 0.2143 - val_accuracy: 0.9113 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1825 - accuracy: 0.9232 - val_loss: 0.2140 - val_accuracy: 0.9113 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1824 - accuracy: 0.9242 - val_loss: 0.2138 - val_accuracy: 0.9117 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1832 - accuracy: 0.9245 - val_loss: 0.2136 - val_accuracy: 0.9113 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1836 - accuracy: 0.9244 - val_loss: 0.2135 - val_accuracy: 0.9109 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1834 - accuracy: 0.9228 - val_loss: 0.2135 - val_accuracy: 0.9117 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1832 - accuracy: 0.9212 - val_loss: 0.2136 - val_accuracy: 0.9093 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1832 - accuracy: 0.9229 - val_loss: 0.2136 - val_accuracy: 0.9105 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1878 - accuracy: 0.9210 - val_loss: 0.2136 - val_accuracy: 0.9125 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1808 - accuracy: 0.9257 - val_loss: 0.2136 - val_accuracy: 0.9121 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1846 - accuracy: 0.9212 - val_loss: 0.2135 - val_accuracy: 0.9125 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1821 - accuracy: 0.9259 - val_loss: 0.2134 - val_accuracy: 0.9125 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1808 - accuracy: 0.9255 - val_loss: 0.2134 - val_accuracy: 0.9117 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1815 - accuracy: 0.9255 - val_loss: 0.2134 - val_accuracy: 0.9121 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1853 - accuracy: 0.9232 - val_loss: 0.2134 - val_accuracy: 0.9121 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1821 - accuracy: 0.9259 - val_loss: 0.2133 - val_accuracy: 0.9117 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1816 - accuracy: 0.9254 - val_loss: 0.2133 - val_accuracy: 0.9121 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1824 - accuracy: 0.9258 - val_loss: 0.2133 - val_accuracy: 0.9121 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1820 - accuracy: 0.9249 - val_loss: 0.2132 - val_accuracy: 0.9121 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1814 - accuracy: 0.9251 - val_loss: 0.2132 - val_accuracy: 0.9121 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1840 - accuracy: 0.9233 - val_loss: 0.2132 - val_accuracy: 0.9121 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1821 - accuracy: 0.9263 - val_loss: 0.2132 - val_accuracy: 0.9121 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1809 - accuracy: 0.9231 - val_loss: 0.2132 - val_accuracy: 0.9125 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1841 - accuracy: 0.9227 - val_loss: 0.2132 - val_accuracy: 0.9121 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1843 - accuracy: 0.9249 - val_loss: 0.2132 - val_accuracy: 0.9125 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1818 - accuracy: 0.9242 - val_loss: 0.2132 - val_accuracy: 0.9125 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1844 - accuracy: 0.9225 - val_loss: 0.2132 - val_accuracy: 0.9125 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1801 - accuracy: 0.9259 - val_loss: 0.2132 - val_accuracy: 0.9125 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1789 - accuracy: 0.9232 - val_loss: 0.2132 - val_accuracy: 0.9125 - lr: 3.6562e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.908524717789023 0.9328311362209667 0.8688524590163934 0.8051602805519511 0.90084179761868 0.9667632084015106\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 1.3196 - accuracy: 0.8525"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 6s 22ms/step - loss: 1.3158 - accuracy: 0.8526 - val_loss: 0.2772 - val_accuracy: 0.8977 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2388 - accuracy: 0.9026 - val_loss: 0.2390 - val_accuracy: 0.9019 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1956 - accuracy: 0.9202 - val_loss: 0.2157 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1775 - accuracy: 0.9267 - val_loss: 0.2133 - val_accuracy: 0.9082 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1625 - accuracy: 0.9299 - val_loss: 0.2165 - val_accuracy: 0.9097 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1404 - accuracy: 0.9406 - val_loss: 0.2051 - val_accuracy: 0.9179 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1310 - accuracy: 0.9456 - val_loss: 0.2103 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1221 - accuracy: 0.9506 - val_loss: 0.2092 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1047 - accuracy: 0.9585 - val_loss: 0.2087 - val_accuracy: 0.9226 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0977 - accuracy: 0.9606 - val_loss: 0.2032 - val_accuracy: 0.9241 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0929 - accuracy: 0.9634 - val_loss: 0.2100 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0839 - accuracy: 0.9698 - val_loss: 0.2083 - val_accuracy: 0.9261 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0802 - accuracy: 0.9713 - val_loss: 0.2120 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0780 - accuracy: 0.9711 - val_loss: 0.2112 - val_accuracy: 0.9257 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0732 - accuracy: 0.9740 - val_loss: 0.2088 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0694 - accuracy: 0.9770 - val_loss: 0.2087 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0676 - accuracy: 0.9764 - val_loss: 0.2116 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.2112 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0628 - accuracy: 0.9799 - val_loss: 0.2128 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0609 - accuracy: 0.9798 - val_loss: 0.2145 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0588 - accuracy: 0.9835 - val_loss: 0.2122 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.2136 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 0.2140 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 0.2135 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0554 - accuracy: 0.9826 - val_loss: 0.2132 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0556 - accuracy: 0.9830 - val_loss: 0.2146 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0542 - accuracy: 0.9846 - val_loss: 0.2149 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0551 - accuracy: 0.9843 - val_loss: 0.2149 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0536 - accuracy: 0.9847 - val_loss: 0.2154 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0543 - accuracy: 0.9847 - val_loss: 0.2156 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0529 - accuracy: 0.9851 - val_loss: 0.2154 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.2155 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9108602569093033 0.9374613003095975 0.8658280922431866 0.8081761676426945 0.901644696276392 0.9689867009365812\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.4464 - accuracy: 0.8414"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 6s 22ms/step - loss: 1.4464 - accuracy: 0.8414 - val_loss: 0.2980 - val_accuracy: 0.8844 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2575 - accuracy: 0.8891 - val_loss: 0.2409 - val_accuracy: 0.8969 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2118 - accuracy: 0.9093 - val_loss: 0.2305 - val_accuracy: 0.8981 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1972 - accuracy: 0.9149 - val_loss: 0.2296 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1825 - accuracy: 0.9202 - val_loss: 0.2196 - val_accuracy: 0.9047 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1581 - accuracy: 0.9356 - val_loss: 0.2156 - val_accuracy: 0.9093 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1465 - accuracy: 0.9397 - val_loss: 0.2193 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 5s 21ms/step - loss: 0.1370 - accuracy: 0.9449 - val_loss: 0.2218 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1214 - accuracy: 0.9524 - val_loss: 0.2199 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1130 - accuracy: 0.9555 - val_loss: 0.2283 - val_accuracy: 0.9062 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1118 - accuracy: 0.9567 - val_loss: 0.2211 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0989 - accuracy: 0.9628 - val_loss: 0.2225 - val_accuracy: 0.9125 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0964 - accuracy: 0.9656 - val_loss: 0.2198 - val_accuracy: 0.9163 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0918 - accuracy: 0.9654 - val_loss: 0.2185 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0849 - accuracy: 0.9687 - val_loss: 0.2201 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0811 - accuracy: 0.9707 - val_loss: 0.2203 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0796 - accuracy: 0.9715 - val_loss: 0.2233 - val_accuracy: 0.9183 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0764 - accuracy: 0.9729 - val_loss: 0.2210 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0736 - accuracy: 0.9750 - val_loss: 0.2219 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0737 - accuracy: 0.9731 - val_loss: 0.2249 - val_accuracy: 0.9167 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0705 - accuracy: 0.9760 - val_loss: 0.2262 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0676 - accuracy: 0.9787 - val_loss: 0.2256 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0695 - accuracy: 0.9766 - val_loss: 0.2242 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0682 - accuracy: 0.9792 - val_loss: 0.2243 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0674 - accuracy: 0.9768 - val_loss: 0.2248 - val_accuracy: 0.9183 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0655 - accuracy: 0.9792 - val_loss: 0.2251 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0643 - accuracy: 0.9799 - val_loss: 0.2265 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0661 - accuracy: 0.9798 - val_loss: 0.2256 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0635 - accuracy: 0.9796 - val_loss: 0.2269 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.2263 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0643 - accuracy: 0.9795 - val_loss: 0.2269 - val_accuracy: 0.9179 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0631 - accuracy: 0.9817 - val_loss: 0.2268 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0635 - accuracy: 0.9798 - val_loss: 0.2270 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0632 - accuracy: 0.9805 - val_loss: 0.2271 - val_accuracy: 0.9191 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0630 - accuracy: 0.9821 - val_loss: 0.2271 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 0.2271 - val_accuracy: 0.9187 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0622 - accuracy: 0.9805 - val_loss: 0.2273 - val_accuracy: 0.9191 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.0632 - accuracy: 0.9816 - val_loss: 0.2275 - val_accuracy: 0.9191 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9318801089918256 0.9454432734035958 0.9089958158995816 0.854257402177915 0.9272195446515887 0.9783136233583307\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 1.5810 - accuracy: 0.8469"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 6s 22ms/step - loss: 1.5765 - accuracy: 0.8472 - val_loss: 0.2929 - val_accuracy: 0.8813 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2399 - accuracy: 0.8991 - val_loss: 0.2406 - val_accuracy: 0.8992 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2032 - accuracy: 0.9132 - val_loss: 0.2228 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1831 - accuracy: 0.9227 - val_loss: 0.2222 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1729 - accuracy: 0.9273 - val_loss: 0.2214 - val_accuracy: 0.9117 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 8s 34ms/step - loss: 0.1506 - accuracy: 0.9362 - val_loss: 0.2065 - val_accuracy: 0.9191 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1374 - accuracy: 0.9439 - val_loss: 0.2134 - val_accuracy: 0.9191 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1322 - accuracy: 0.9454 - val_loss: 0.1944 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.1162 - accuracy: 0.9535 - val_loss: 0.2005 - val_accuracy: 0.9237 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 5s 21ms/step - loss: 0.1077 - accuracy: 0.9596 - val_loss: 0.2029 - val_accuracy: 0.9253 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1032 - accuracy: 0.9604 - val_loss: 0.2066 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0929 - accuracy: 0.9637 - val_loss: 0.2034 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0905 - accuracy: 0.9657 - val_loss: 0.2010 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0868 - accuracy: 0.9694 - val_loss: 0.2167 - val_accuracy: 0.9198 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.2026 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.2020 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0761 - accuracy: 0.9743 - val_loss: 0.2026 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0749 - accuracy: 0.9757 - val_loss: 0.1995 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0703 - accuracy: 0.9770 - val_loss: 0.2022 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.2014 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0667 - accuracy: 0.9772 - val_loss: 0.1997 - val_accuracy: 0.9300 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0647 - accuracy: 0.9798 - val_loss: 0.1996 - val_accuracy: 0.9284 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0648 - accuracy: 0.9794 - val_loss: 0.2005 - val_accuracy: 0.9296 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0647 - accuracy: 0.9791 - val_loss: 0.2019 - val_accuracy: 0.9288 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0645 - accuracy: 0.9798 - val_loss: 0.2005 - val_accuracy: 0.9300 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0630 - accuracy: 0.9807 - val_loss: 0.2025 - val_accuracy: 0.9292 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 0.2022 - val_accuracy: 0.9300 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0610 - accuracy: 0.9820 - val_loss: 0.2020 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0613 - accuracy: 0.9821 - val_loss: 0.2024 - val_accuracy: 0.9288 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0634 - accuracy: 0.9805 - val_loss: 0.2028 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0611 - accuracy: 0.9818 - val_loss: 0.2034 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.2021 - val_accuracy: 0.9304 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0602 - accuracy: 0.9798 - val_loss: 0.2026 - val_accuracy: 0.9288 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 0.2023 - val_accuracy: 0.9296 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0603 - accuracy: 0.9795 - val_loss: 0.2025 - val_accuracy: 0.9288 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 0.2027 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.2027 - val_accuracy: 0.9300 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.0609 - accuracy: 0.9813 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0609 - accuracy: 0.9800 - val_loss: 0.2026 - val_accuracy: 0.9304 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0598 - accuracy: 0.9826 - val_loss: 0.2027 - val_accuracy: 0.9304 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 0.2027 - val_accuracy: 0.9304 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.2025 - val_accuracy: 0.9307 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0604 - accuracy: 0.9814 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0602 - accuracy: 0.9827 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0607 - accuracy: 0.9805 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0596 - accuracy: 0.9834 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.2028 - val_accuracy: 0.9307 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0585 - accuracy: 0.9829 - val_loss: 0.2028 - val_accuracy: 0.9307 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0596 - accuracy: 0.9818 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0596 - accuracy: 0.9824 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0598 - accuracy: 0.9816 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0617 - accuracy: 0.9807 - val_loss: 0.2027 - val_accuracy: 0.9307 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.0598 - accuracy: 0.9821 - val_loss: 0.2026 - val_accuracy: 0.9307 - lr: 6.0936e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9174776177500973 0.931056293485136 0.895748987854251 0.8258747304711185 0.9134026406696936 0.975105759947965\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.8356"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 8ms/step - loss: 0.6220 - accuracy: 0.8356 - val_loss: 0.3113 - val_accuracy: 0.8832 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2592 - accuracy: 0.8852 - val_loss: 0.2333 - val_accuracy: 0.9011 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2192 - accuracy: 0.9071 - val_loss: 0.2242 - val_accuracy: 0.9046 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1986 - accuracy: 0.9162 - val_loss: 0.2319 - val_accuracy: 0.8984 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1875 - accuracy: 0.9223 - val_loss: 0.2095 - val_accuracy: 0.9144 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1656 - accuracy: 0.9311 - val_loss: 0.2011 - val_accuracy: 0.9171 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1540 - accuracy: 0.9347 - val_loss: 0.2013 - val_accuracy: 0.9155 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1496 - accuracy: 0.9389 - val_loss: 0.2023 - val_accuracy: 0.9194 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1343 - accuracy: 0.9437 - val_loss: 0.2095 - val_accuracy: 0.9151 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9481 - val_loss: 0.2004 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1222 - accuracy: 0.9529 - val_loss: 0.2036 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9561 - val_loss: 0.1968 - val_accuracy: 0.9221 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1107 - accuracy: 0.9581 - val_loss: 0.1964 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1068 - accuracy: 0.9587 - val_loss: 0.1978 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9617 - val_loss: 0.1996 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9638 - val_loss: 0.2007 - val_accuracy: 0.9214 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9637 - val_loss: 0.1999 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0924 - accuracy: 0.9644 - val_loss: 0.2001 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0930 - accuracy: 0.9672 - val_loss: 0.1966 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.0907 - accuracy: 0.9678 - val_loss: 0.1984 - val_accuracy: 0.9288 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9683 - val_loss: 0.1989 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9661 - val_loss: 0.1963 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9687 - val_loss: 0.1969 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9712 - val_loss: 0.1972 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.1987 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9691 - val_loss: 0.1977 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9703 - val_loss: 0.1975 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0828 - accuracy: 0.9713 - val_loss: 0.1975 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9700 - val_loss: 0.1977 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9691 - val_loss: 0.1974 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9716 - val_loss: 0.1976 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9705 - val_loss: 0.1974 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0830 - accuracy: 0.9713 - val_loss: 0.1973 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0837 - accuracy: 0.9718 - val_loss: 0.1972 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9713 - val_loss: 0.1978 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9703 - val_loss: 0.1977 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0798 - accuracy: 0.9724 - val_loss: 0.1976 - val_accuracy: 0.9241 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0806 - accuracy: 0.9722 - val_loss: 0.1977 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9728 - val_loss: 0.1978 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 0.1977 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9229571984435798 0.9262446220036877 0.9172852598091198 0.8362138305270743 0.9217649409064037 0.9781960174963713\n",
            "Epoch 1/200\n",
            "233/241 [============================>.] - ETA: 0s - loss: 1.0062 - accuracy: 0.8263"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.9852 - accuracy: 0.8265 - val_loss: 0.2743 - val_accuracy: 0.8840 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2727 - accuracy: 0.8847 - val_loss: 0.2530 - val_accuracy: 0.8872 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2322 - accuracy: 0.9000 - val_loss: 0.2422 - val_accuracy: 0.8946 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2160 - accuracy: 0.9081 - val_loss: 0.2235 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2037 - accuracy: 0.9146 - val_loss: 0.2196 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1867 - accuracy: 0.9228 - val_loss: 0.2166 - val_accuracy: 0.9039 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1790 - accuracy: 0.9242 - val_loss: 0.2086 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1723 - accuracy: 0.9275 - val_loss: 0.2055 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1581 - accuracy: 0.9332 - val_loss: 0.2064 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1533 - accuracy: 0.9385 - val_loss: 0.2017 - val_accuracy: 0.9117 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1503 - accuracy: 0.9389 - val_loss: 0.2057 - val_accuracy: 0.9117 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1423 - accuracy: 0.9399 - val_loss: 0.2036 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1368 - accuracy: 0.9467 - val_loss: 0.2054 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1349 - accuracy: 0.9458 - val_loss: 0.2034 - val_accuracy: 0.9152 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1308 - accuracy: 0.9468 - val_loss: 0.2023 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1274 - accuracy: 0.9478 - val_loss: 0.2010 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1261 - accuracy: 0.9482 - val_loss: 0.2015 - val_accuracy: 0.9144 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1239 - accuracy: 0.9524 - val_loss: 0.2022 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1234 - accuracy: 0.9502 - val_loss: 0.2009 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1215 - accuracy: 0.9515 - val_loss: 0.2039 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9545 - val_loss: 0.2029 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1195 - accuracy: 0.9541 - val_loss: 0.2015 - val_accuracy: 0.9128 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9533 - val_loss: 0.2012 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1163 - accuracy: 0.9565 - val_loss: 0.2010 - val_accuracy: 0.9140 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1153 - accuracy: 0.9551 - val_loss: 0.2012 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9543 - val_loss: 0.2006 - val_accuracy: 0.9152 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9565 - val_loss: 0.2010 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9543 - val_loss: 0.2007 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1147 - accuracy: 0.9560 - val_loss: 0.2009 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9555 - val_loss: 0.2007 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1125 - accuracy: 0.9560 - val_loss: 0.2004 - val_accuracy: 0.9160 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9574 - val_loss: 0.2006 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1125 - accuracy: 0.9551 - val_loss: 0.2006 - val_accuracy: 0.9163 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9563 - val_loss: 0.2008 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9581 - val_loss: 0.2009 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9586 - val_loss: 0.2010 - val_accuracy: 0.9152 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9563 - val_loss: 0.2009 - val_accuracy: 0.9152 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9561 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9564 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9586 - val_loss: 0.2007 - val_accuracy: 0.9156 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9556 - val_loss: 0.2008 - val_accuracy: 0.9152 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9564 - val_loss: 0.2008 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9551 - val_loss: 0.2008 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9565 - val_loss: 0.2008 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9577 - val_loss: 0.2008 - val_accuracy: 0.9152 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9574 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9571 - val_loss: 0.2007 - val_accuracy: 0.9156 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9560 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9555 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9583 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9578 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1120 - accuracy: 0.9569 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1121 - accuracy: 0.9568 - val_loss: 0.2008 - val_accuracy: 0.9156 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9237057220708447 0.9441305712492153 0.8903688524590164 0.8375838851914258 0.9172497118541159 0.9729551289967378\n",
            "Epoch 1/200\n",
            "234/241 [============================>.] - ETA: 0s - loss: 0.9484 - accuracy: 0.8397"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.9293 - accuracy: 0.8408 - val_loss: 0.3436 - val_accuracy: 0.8311 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2481 - accuracy: 0.8923 - val_loss: 0.2490 - val_accuracy: 0.8938 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2094 - accuracy: 0.9098 - val_loss: 0.2242 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1925 - accuracy: 0.9181 - val_loss: 0.2288 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1840 - accuracy: 0.9218 - val_loss: 0.2233 - val_accuracy: 0.9051 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1621 - accuracy: 0.9325 - val_loss: 0.2161 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1550 - accuracy: 0.9363 - val_loss: 0.2128 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1445 - accuracy: 0.9429 - val_loss: 0.2172 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1352 - accuracy: 0.9456 - val_loss: 0.2089 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1278 - accuracy: 0.9493 - val_loss: 0.2064 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9493 - val_loss: 0.2106 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9541 - val_loss: 0.2040 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1125 - accuracy: 0.9565 - val_loss: 0.2075 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1111 - accuracy: 0.9581 - val_loss: 0.2004 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1058 - accuracy: 0.9600 - val_loss: 0.2023 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1028 - accuracy: 0.9608 - val_loss: 0.2014 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.2012 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0981 - accuracy: 0.9621 - val_loss: 0.2001 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9634 - val_loss: 0.2013 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0938 - accuracy: 0.9665 - val_loss: 0.2019 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9650 - val_loss: 0.2012 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9678 - val_loss: 0.2022 - val_accuracy: 0.9222 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9668 - val_loss: 0.2042 - val_accuracy: 0.9226 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9667 - val_loss: 0.2016 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9680 - val_loss: 0.2019 - val_accuracy: 0.9265 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9664 - val_loss: 0.2022 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9700 - val_loss: 0.2017 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9694 - val_loss: 0.2024 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0883 - accuracy: 0.9691 - val_loss: 0.2022 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0881 - accuracy: 0.9682 - val_loss: 0.2022 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9690 - val_loss: 0.2021 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0894 - accuracy: 0.9677 - val_loss: 0.2023 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0885 - accuracy: 0.9694 - val_loss: 0.2023 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9703 - val_loss: 0.2020 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9704 - val_loss: 0.2020 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0859 - accuracy: 0.9680 - val_loss: 0.2020 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0858 - accuracy: 0.9709 - val_loss: 0.2021 - val_accuracy: 0.9268 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9689 - val_loss: 0.2020 - val_accuracy: 0.9261 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9699 - val_loss: 0.2019 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0870 - accuracy: 0.9699 - val_loss: 0.2020 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9669 - val_loss: 0.2020 - val_accuracy: 0.9265 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9704 - val_loss: 0.2021 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9704 - val_loss: 0.2021 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9692 - val_loss: 0.2019 - val_accuracy: 0.9265 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0848 - accuracy: 0.9698 - val_loss: 0.2020 - val_accuracy: 0.9261 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9699 - val_loss: 0.2019 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9713 - val_loss: 0.2020 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9703 - val_loss: 0.2020 - val_accuracy: 0.9265 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9703 - val_loss: 0.2020 - val_accuracy: 0.9265 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9096924873491631 0.9312693498452013 0.8731656184486373 0.8061924222745797 0.9022174841469193 0.9700621791252085\n",
            "Epoch 1/200\n",
            "231/241 [===========================>..] - ETA: 0s - loss: 0.6976 - accuracy: 0.8277"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.6816 - accuracy: 0.8298 - val_loss: 0.3189 - val_accuracy: 0.8720 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2704 - accuracy: 0.8763 - val_loss: 0.3217 - val_accuracy: 0.8529 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2268 - accuracy: 0.9042 - val_loss: 0.2400 - val_accuracy: 0.8942 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2154 - accuracy: 0.9058 - val_loss: 0.2284 - val_accuracy: 0.9000 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1988 - accuracy: 0.9154 - val_loss: 0.2170 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1777 - accuracy: 0.9221 - val_loss: 0.2143 - val_accuracy: 0.9062 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1698 - accuracy: 0.9289 - val_loss: 0.2143 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1605 - accuracy: 0.9330 - val_loss: 0.2130 - val_accuracy: 0.9089 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9375 - val_loss: 0.2130 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1432 - accuracy: 0.9423 - val_loss: 0.2136 - val_accuracy: 0.9113 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9437 - val_loss: 0.2153 - val_accuracy: 0.9101 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1285 - accuracy: 0.9465 - val_loss: 0.2125 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1261 - accuracy: 0.9494 - val_loss: 0.2142 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9532 - val_loss: 0.2139 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1155 - accuracy: 0.9548 - val_loss: 0.2118 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9546 - val_loss: 0.2165 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9552 - val_loss: 0.2124 - val_accuracy: 0.9136 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9586 - val_loss: 0.2129 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9607 - val_loss: 0.2119 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1028 - accuracy: 0.9607 - val_loss: 0.2129 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9608 - val_loss: 0.2122 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1025 - accuracy: 0.9603 - val_loss: 0.2118 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9624 - val_loss: 0.2130 - val_accuracy: 0.9132 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9630 - val_loss: 0.2128 - val_accuracy: 0.9156 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0998 - accuracy: 0.9612 - val_loss: 0.2123 - val_accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9635 - val_loss: 0.2125 - val_accuracy: 0.9140 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9654 - val_loss: 0.2125 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0971 - accuracy: 0.9673 - val_loss: 0.2126 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9611 - val_loss: 0.2124 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9644 - val_loss: 0.2121 - val_accuracy: 0.9152 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9660 - val_loss: 0.2122 - val_accuracy: 0.9160 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0959 - accuracy: 0.9652 - val_loss: 0.2122 - val_accuracy: 0.9152 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9657 - val_loss: 0.2124 - val_accuracy: 0.9156 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9656 - val_loss: 0.2125 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9609 - val_loss: 0.2122 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9663 - val_loss: 0.2123 - val_accuracy: 0.9152 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9668 - val_loss: 0.2123 - val_accuracy: 0.9152 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0946 - accuracy: 0.9651 - val_loss: 0.2125 - val_accuracy: 0.9148 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9628 - val_loss: 0.2125 - val_accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9661 - val_loss: 0.2126 - val_accuracy: 0.9152 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9660 - val_loss: 0.2126 - val_accuracy: 0.9152 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9664 - val_loss: 0.2126 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9652 - val_loss: 0.2126 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9663 - val_loss: 0.2124 - val_accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0960 - accuracy: 0.9637 - val_loss: 0.2125 - val_accuracy: 0.9148 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0942 - accuracy: 0.9643 - val_loss: 0.2126 - val_accuracy: 0.9152 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9641 - val_loss: 0.2126 - val_accuracy: 0.9152 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9638 - val_loss: 0.2125 - val_accuracy: 0.9148 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9295445698715453 0.9411035337879727 0.9100418410041841 0.8495403961893974 0.9255726873960783 0.980264949793389\n",
            "Epoch 1/200\n",
            "236/241 [============================>.] - ETA: 0s - loss: 0.7483 - accuracy: 0.8387"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.7396 - accuracy: 0.8394 - val_loss: 0.2907 - val_accuracy: 0.8942 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2571 - accuracy: 0.8871 - val_loss: 0.2231 - val_accuracy: 0.9058 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9083 - val_loss: 0.2342 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2013 - accuracy: 0.9122 - val_loss: 0.2273 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1904 - accuracy: 0.9180 - val_loss: 0.2144 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1749 - accuracy: 0.9268 - val_loss: 0.2174 - val_accuracy: 0.9058 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1653 - accuracy: 0.9310 - val_loss: 0.1995 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1578 - accuracy: 0.9345 - val_loss: 0.2093 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1450 - accuracy: 0.9390 - val_loss: 0.2005 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9421 - val_loss: 0.2029 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1346 - accuracy: 0.9438 - val_loss: 0.1934 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9499 - val_loss: 0.2053 - val_accuracy: 0.9163 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1227 - accuracy: 0.9498 - val_loss: 0.1949 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9526 - val_loss: 0.1967 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1139 - accuracy: 0.9548 - val_loss: 0.1935 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9563 - val_loss: 0.1962 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1108 - accuracy: 0.9578 - val_loss: 0.1930 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9638 - val_loss: 0.1994 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9573 - val_loss: 0.1933 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9611 - val_loss: 0.1940 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1009 - accuracy: 0.9622 - val_loss: 0.1946 - val_accuracy: 0.9218 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9641 - val_loss: 0.1941 - val_accuracy: 0.9222 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9641 - val_loss: 0.1944 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0987 - accuracy: 0.9619 - val_loss: 0.1943 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9613 - val_loss: 0.1946 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9625 - val_loss: 0.1945 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0960 - accuracy: 0.9638 - val_loss: 0.1955 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9632 - val_loss: 0.1939 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9657 - val_loss: 0.1939 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9632 - val_loss: 0.1937 - val_accuracy: 0.9230 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9646 - val_loss: 0.1939 - val_accuracy: 0.9222 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0959 - accuracy: 0.9630 - val_loss: 0.1938 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9632 - val_loss: 0.1939 - val_accuracy: 0.9222 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9652 - val_loss: 0.1942 - val_accuracy: 0.9218 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9663 - val_loss: 0.1941 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0946 - accuracy: 0.9656 - val_loss: 0.1941 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9648 - val_loss: 0.1944 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9190346438302841 0.9430740037950665 0.8805668016194332 0.8282636908231024 0.9118204027072498 0.9750068500692688\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.8360"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 8ms/step - loss: 0.7246 - accuracy: 0.8360 - val_loss: 0.3237 - val_accuracy: 0.8497 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2545 - accuracy: 0.8896 - val_loss: 0.2334 - val_accuracy: 0.9007 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2194 - accuracy: 0.9046 - val_loss: 0.2264 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9163 - val_loss: 0.2375 - val_accuracy: 0.8968 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1898 - accuracy: 0.9196 - val_loss: 0.2226 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1677 - accuracy: 0.9299 - val_loss: 0.2103 - val_accuracy: 0.9120 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9320 - val_loss: 0.2093 - val_accuracy: 0.9120 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9369 - val_loss: 0.2119 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1374 - accuracy: 0.9410 - val_loss: 0.2030 - val_accuracy: 0.9163 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1335 - accuracy: 0.9449 - val_loss: 0.2039 - val_accuracy: 0.9159 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1317 - accuracy: 0.9442 - val_loss: 0.2046 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1191 - accuracy: 0.9524 - val_loss: 0.2014 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1185 - accuracy: 0.9525 - val_loss: 0.2009 - val_accuracy: 0.9186 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1154 - accuracy: 0.9548 - val_loss: 0.2055 - val_accuracy: 0.9194 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1099 - accuracy: 0.9577 - val_loss: 0.2000 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1066 - accuracy: 0.9567 - val_loss: 0.2006 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9587 - val_loss: 0.1986 - val_accuracy: 0.9221 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9596 - val_loss: 0.2016 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9591 - val_loss: 0.2021 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9607 - val_loss: 0.2004 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0972 - accuracy: 0.9617 - val_loss: 0.2005 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9616 - val_loss: 0.2014 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 0.9626 - val_loss: 0.1998 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9647 - val_loss: 0.2005 - val_accuracy: 0.9214 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9642 - val_loss: 0.2008 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 0.2005 - val_accuracy: 0.9225 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9665 - val_loss: 0.2011 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9635 - val_loss: 0.2011 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9669 - val_loss: 0.2014 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9642 - val_loss: 0.2015 - val_accuracy: 0.9214 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9643 - val_loss: 0.2013 - val_accuracy: 0.9210 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9647 - val_loss: 0.2010 - val_accuracy: 0.9210 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9663 - val_loss: 0.2009 - val_accuracy: 0.9210 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0938 - accuracy: 0.9663 - val_loss: 0.2012 - val_accuracy: 0.9210 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9664 - val_loss: 0.2012 - val_accuracy: 0.9218 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9681 - val_loss: 0.2009 - val_accuracy: 0.9218 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.930739299610895 0.9483712354025814 0.9003181336161188 0.8506153651220973 0.9243446845093501 0.9791961732716924\n",
            "Epoch 1/200\n",
            "232/241 [===========================>..] - ETA: 0s - loss: 0.5094 - accuracy: 0.8471"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.4995 - accuracy: 0.8488 - val_loss: 0.3093 - val_accuracy: 0.8654 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2485 - accuracy: 0.8915 - val_loss: 0.2306 - val_accuracy: 0.9008 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2070 - accuracy: 0.9112 - val_loss: 0.2184 - val_accuracy: 0.9086 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1932 - accuracy: 0.9176 - val_loss: 0.2138 - val_accuracy: 0.9117 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1808 - accuracy: 0.9242 - val_loss: 0.2069 - val_accuracy: 0.9128 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1624 - accuracy: 0.9325 - val_loss: 0.1999 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1557 - accuracy: 0.9372 - val_loss: 0.1952 - val_accuracy: 0.9195 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9389 - val_loss: 0.1942 - val_accuracy: 0.9171 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1317 - accuracy: 0.9476 - val_loss: 0.1981 - val_accuracy: 0.9245 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1276 - accuracy: 0.9464 - val_loss: 0.1896 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1194 - accuracy: 0.9534 - val_loss: 0.1944 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.9545 - val_loss: 0.1937 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9577 - val_loss: 0.1964 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9589 - val_loss: 0.1909 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9606 - val_loss: 0.1890 - val_accuracy: 0.9214 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9626 - val_loss: 0.1925 - val_accuracy: 0.9195 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0974 - accuracy: 0.9646 - val_loss: 0.1916 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0954 - accuracy: 0.9656 - val_loss: 0.1915 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9664 - val_loss: 0.1931 - val_accuracy: 0.9218 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9657 - val_loss: 0.1925 - val_accuracy: 0.9198 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9669 - val_loss: 0.1926 - val_accuracy: 0.9222 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9670 - val_loss: 0.1915 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9691 - val_loss: 0.1922 - val_accuracy: 0.9214 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9670 - val_loss: 0.1922 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9694 - val_loss: 0.1918 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 0.1921 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9721 - val_loss: 0.1918 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0830 - accuracy: 0.9687 - val_loss: 0.1919 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9696 - val_loss: 0.1920 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9213701829505644 0.9591964846202135 0.8596311475409836 0.8322119592748696 0.9094138160805985 0.973305663610262\n",
            "Epoch 1/200\n",
            "234/241 [============================>.] - ETA: 0s - loss: 0.8936 - accuracy: 0.8140"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.8765 - accuracy: 0.8164 - val_loss: 0.3143 - val_accuracy: 0.8708 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2760 - accuracy: 0.8801 - val_loss: 0.2476 - val_accuracy: 0.8946 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2365 - accuracy: 0.9013 - val_loss: 0.2386 - val_accuracy: 0.8938 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2203 - accuracy: 0.9084 - val_loss: 0.2320 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9131 - val_loss: 0.2228 - val_accuracy: 0.8973 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1847 - accuracy: 0.9211 - val_loss: 0.2192 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1760 - accuracy: 0.9272 - val_loss: 0.2136 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1713 - accuracy: 0.9290 - val_loss: 0.2131 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1562 - accuracy: 0.9337 - val_loss: 0.2095 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1547 - accuracy: 0.9350 - val_loss: 0.2032 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.9376 - val_loss: 0.2227 - val_accuracy: 0.9047 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1376 - accuracy: 0.9429 - val_loss: 0.2075 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1348 - accuracy: 0.9449 - val_loss: 0.2065 - val_accuracy: 0.9179 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1318 - accuracy: 0.9484 - val_loss: 0.2079 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1292 - accuracy: 0.9482 - val_loss: 0.2071 - val_accuracy: 0.9144 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9500 - val_loss: 0.2072 - val_accuracy: 0.9156 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.2077 - val_accuracy: 0.9160 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1219 - accuracy: 0.9511 - val_loss: 0.2023 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9563 - val_loss: 0.2049 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9559 - val_loss: 0.2055 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9559 - val_loss: 0.2046 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1147 - accuracy: 0.9564 - val_loss: 0.2068 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1111 - accuracy: 0.9573 - val_loss: 0.2028 - val_accuracy: 0.9206 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9569 - val_loss: 0.2046 - val_accuracy: 0.9187 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1103 - accuracy: 0.9571 - val_loss: 0.2012 - val_accuracy: 0.9214 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1122 - accuracy: 0.9556 - val_loss: 0.2057 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9583 - val_loss: 0.2069 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9583 - val_loss: 0.2026 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9546 - val_loss: 0.2076 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9548 - val_loss: 0.2066 - val_accuracy: 0.9152 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9564 - val_loss: 0.2044 - val_accuracy: 0.9183 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9573 - val_loss: 0.2050 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9582 - val_loss: 0.2050 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9586 - val_loss: 0.2041 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1096 - accuracy: 0.9587 - val_loss: 0.2051 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9551 - val_loss: 0.2051 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9551 - val_loss: 0.2047 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9577 - val_loss: 0.2053 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9582 - val_loss: 0.2049 - val_accuracy: 0.9187 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9604 - val_loss: 0.2047 - val_accuracy: 0.9187 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9576 - val_loss: 0.2048 - val_accuracy: 0.9187 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9598 - val_loss: 0.2046 - val_accuracy: 0.9191 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.9585 - val_loss: 0.2047 - val_accuracy: 0.9191 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9581 - val_loss: 0.2047 - val_accuracy: 0.9191 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1088 - accuracy: 0.9583 - val_loss: 0.2047 - val_accuracy: 0.9191 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9124172829894901 0.9343653250773993 0.8752620545073375 0.8119394164516628 0.9048136897923684 0.9698720070616793\n",
            "Epoch 1/200\n",
            "236/241 [============================>.] - ETA: 0s - loss: 0.8394 - accuracy: 0.8298"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 8ms/step - loss: 0.8286 - accuracy: 0.8305 - val_loss: 0.3122 - val_accuracy: 0.8802 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2658 - accuracy: 0.8863 - val_loss: 0.2408 - val_accuracy: 0.8922 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2272 - accuracy: 0.9019 - val_loss: 0.2346 - val_accuracy: 0.8957 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2153 - accuracy: 0.9055 - val_loss: 0.2155 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1991 - accuracy: 0.9149 - val_loss: 0.2345 - val_accuracy: 0.8969 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1776 - accuracy: 0.9273 - val_loss: 0.2096 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1731 - accuracy: 0.9285 - val_loss: 0.2043 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1635 - accuracy: 0.9332 - val_loss: 0.2041 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1533 - accuracy: 0.9377 - val_loss: 0.1983 - val_accuracy: 0.9074 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1503 - accuracy: 0.9388 - val_loss: 0.2011 - val_accuracy: 0.9093 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9406 - val_loss: 0.2002 - val_accuracy: 0.9074 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1338 - accuracy: 0.9456 - val_loss: 0.1975 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1311 - accuracy: 0.9482 - val_loss: 0.1976 - val_accuracy: 0.9086 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1256 - accuracy: 0.9494 - val_loss: 0.2001 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1194 - accuracy: 0.9532 - val_loss: 0.2026 - val_accuracy: 0.9156 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1210 - accuracy: 0.9525 - val_loss: 0.1966 - val_accuracy: 0.9105 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9555 - val_loss: 0.1972 - val_accuracy: 0.9148 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9538 - val_loss: 0.1965 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9580 - val_loss: 0.1994 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9546 - val_loss: 0.1984 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9608 - val_loss: 0.1981 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1088 - accuracy: 0.9600 - val_loss: 0.1983 - val_accuracy: 0.9117 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9569 - val_loss: 0.1997 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9598 - val_loss: 0.2001 - val_accuracy: 0.9152 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9608 - val_loss: 0.1992 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9574 - val_loss: 0.1997 - val_accuracy: 0.9128 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9606 - val_loss: 0.1994 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9619 - val_loss: 0.1994 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9619 - val_loss: 0.1993 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9637 - val_loss: 0.1992 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9633 - val_loss: 0.1995 - val_accuracy: 0.9140 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9642 - val_loss: 0.1994 - val_accuracy: 0.9136 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9621 - val_loss: 0.1993 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1058 - accuracy: 0.9576 - val_loss: 0.1992 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1054 - accuracy: 0.9609 - val_loss: 0.1992 - val_accuracy: 0.9132 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.928766056831452 0.9597024178549287 0.8765690376569037 0.8466658234722602 0.9181357277559162 0.9812895745083747\n",
            "Epoch 1/200\n",
            "232/241 [===========================>..] - ETA: 0s - loss: 0.4468 - accuracy: 0.8576"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.4402 - accuracy: 0.8587 - val_loss: 0.3542 - val_accuracy: 0.8728 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2397 - accuracy: 0.8954 - val_loss: 0.2222 - val_accuracy: 0.9027 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9159 - val_loss: 0.2297 - val_accuracy: 0.8977 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1862 - accuracy: 0.9224 - val_loss: 0.2145 - val_accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1766 - accuracy: 0.9271 - val_loss: 0.2509 - val_accuracy: 0.8973 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1510 - accuracy: 0.9369 - val_loss: 0.1947 - val_accuracy: 0.9179 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1447 - accuracy: 0.9404 - val_loss: 0.1961 - val_accuracy: 0.9198 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1354 - accuracy: 0.9449 - val_loss: 0.2022 - val_accuracy: 0.9210 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1245 - accuracy: 0.9523 - val_loss: 0.1909 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1190 - accuracy: 0.9529 - val_loss: 0.2016 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1125 - accuracy: 0.9547 - val_loss: 0.1963 - val_accuracy: 0.9230 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9619 - val_loss: 0.1968 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1014 - accuracy: 0.9633 - val_loss: 0.1931 - val_accuracy: 0.9241 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9633 - val_loss: 0.1941 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0917 - accuracy: 0.9672 - val_loss: 0.1973 - val_accuracy: 0.9296 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9657 - val_loss: 0.1969 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9699 - val_loss: 0.1954 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9694 - val_loss: 0.1961 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9703 - val_loss: 0.1957 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9711 - val_loss: 0.1985 - val_accuracy: 0.9288 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0828 - accuracy: 0.9704 - val_loss: 0.1975 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9726 - val_loss: 0.1989 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.9730 - val_loss: 0.1990 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0774 - accuracy: 0.9738 - val_loss: 0.2003 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9729 - val_loss: 0.1999 - val_accuracy: 0.9265 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0771 - accuracy: 0.9721 - val_loss: 0.1987 - val_accuracy: 0.9284 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9748 - val_loss: 0.1993 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0787 - accuracy: 0.9726 - val_loss: 0.1984 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0755 - accuracy: 0.9753 - val_loss: 0.1990 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0764 - accuracy: 0.9730 - val_loss: 0.1990 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9738 - val_loss: 0.1991 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0765 - accuracy: 0.9730 - val_loss: 0.1985 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0774 - accuracy: 0.9737 - val_loss: 0.1984 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0762 - accuracy: 0.9751 - val_loss: 0.1985 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0776 - accuracy: 0.9721 - val_loss: 0.1983 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9190346438302841 0.9297912713472486 0.9018218623481782 0.8294637060144309 0.9158065668477133 0.9758192554806956\n",
            "Epoch 1/200\n",
            "232/241 [===========================>..] - ETA: 0s - loss: 0.7863 - accuracy: 0.8427"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.7686 - accuracy: 0.8439 - val_loss: 0.2795 - val_accuracy: 0.8828 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2554 - accuracy: 0.8850 - val_loss: 0.2462 - val_accuracy: 0.8972 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2162 - accuracy: 0.9081 - val_loss: 0.2211 - val_accuracy: 0.9085 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1990 - accuracy: 0.9146 - val_loss: 0.2174 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1886 - accuracy: 0.9220 - val_loss: 0.2179 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1680 - accuracy: 0.9341 - val_loss: 0.2272 - val_accuracy: 0.8984 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1611 - accuracy: 0.9334 - val_loss: 0.2102 - val_accuracy: 0.9120 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.9358 - val_loss: 0.1994 - val_accuracy: 0.9186 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1391 - accuracy: 0.9433 - val_loss: 0.2044 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1346 - accuracy: 0.9437 - val_loss: 0.2025 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9499 - val_loss: 0.2039 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1187 - accuracy: 0.9524 - val_loss: 0.1964 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9541 - val_loss: 0.2052 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9578 - val_loss: 0.1995 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1070 - accuracy: 0.9578 - val_loss: 0.1962 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1043 - accuracy: 0.9593 - val_loss: 0.1967 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1037 - accuracy: 0.9581 - val_loss: 0.1955 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0991 - accuracy: 0.9612 - val_loss: 0.1943 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9626 - val_loss: 0.1984 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9641 - val_loss: 0.1946 - val_accuracy: 0.9264 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9643 - val_loss: 0.1949 - val_accuracy: 0.9260 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9657 - val_loss: 0.1960 - val_accuracy: 0.9260 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9665 - val_loss: 0.1982 - val_accuracy: 0.9264 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9672 - val_loss: 0.1965 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0893 - accuracy: 0.9669 - val_loss: 0.1960 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9638 - val_loss: 0.1965 - val_accuracy: 0.9260 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 0.9660 - val_loss: 0.1962 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9667 - val_loss: 0.1963 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9656 - val_loss: 0.1958 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9667 - val_loss: 0.1956 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9635 - val_loss: 0.1952 - val_accuracy: 0.9260 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0882 - accuracy: 0.9685 - val_loss: 0.1950 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9664 - val_loss: 0.1954 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9685 - val_loss: 0.1954 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9673 - val_loss: 0.1954 - val_accuracy: 0.9264 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9657 - val_loss: 0.1954 - val_accuracy: 0.9260 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0893 - accuracy: 0.9678 - val_loss: 0.1954 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9287937743190662 0.9391518131530424 0.9109225874867445 0.8473079621336322 0.9250372003198934 0.9789572960532791\n",
            "Epoch 1/200\n",
            "230/241 [===========================>..] - ETA: 0s - loss: 1.2049 - accuracy: 0.8015"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 1.1639 - accuracy: 0.8049 - val_loss: 0.3197 - val_accuracy: 0.8747 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2841 - accuracy: 0.8796 - val_loss: 0.2508 - val_accuracy: 0.8926 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2330 - accuracy: 0.8991 - val_loss: 0.2283 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2206 - accuracy: 0.9079 - val_loss: 0.2194 - val_accuracy: 0.9051 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2075 - accuracy: 0.9142 - val_loss: 0.2145 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1868 - accuracy: 0.9207 - val_loss: 0.2128 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1789 - accuracy: 0.9276 - val_loss: 0.2104 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9275 - val_loss: 0.2388 - val_accuracy: 0.8938 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1576 - accuracy: 0.9346 - val_loss: 0.2002 - val_accuracy: 0.9140 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1533 - accuracy: 0.9358 - val_loss: 0.2000 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1493 - accuracy: 0.9377 - val_loss: 0.2126 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1402 - accuracy: 0.9432 - val_loss: 0.1931 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1362 - accuracy: 0.9442 - val_loss: 0.1992 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1331 - accuracy: 0.9485 - val_loss: 0.1921 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9498 - val_loss: 0.2015 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9526 - val_loss: 0.1928 - val_accuracy: 0.9191 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1236 - accuracy: 0.9529 - val_loss: 0.1937 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.9521 - val_loss: 0.1932 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9573 - val_loss: 0.1925 - val_accuracy: 0.9183 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9560 - val_loss: 0.1908 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1145 - accuracy: 0.9546 - val_loss: 0.1928 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1124 - accuracy: 0.9573 - val_loss: 0.1936 - val_accuracy: 0.9171 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1120 - accuracy: 0.9581 - val_loss: 0.1914 - val_accuracy: 0.9195 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9581 - val_loss: 0.1923 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9573 - val_loss: 0.1925 - val_accuracy: 0.9187 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9596 - val_loss: 0.1926 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9585 - val_loss: 0.1934 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9587 - val_loss: 0.1929 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9585 - val_loss: 0.1929 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9571 - val_loss: 0.1929 - val_accuracy: 0.9191 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9564 - val_loss: 0.1938 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9571 - val_loss: 0.1927 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9600 - val_loss: 0.1921 - val_accuracy: 0.9202 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9578 - val_loss: 0.1924 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9612 - val_loss: 0.1927 - val_accuracy: 0.9198 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9604 - val_loss: 0.1929 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9580 - val_loss: 0.1927 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9233164655507979 0.9535467671060891 0.8739754098360656 0.8363460201850038 0.9137610884710774 0.9714568347174627\n",
            "Epoch 1/200\n",
            "230/241 [===========================>..] - ETA: 0s - loss: 0.7219 - accuracy: 0.8481"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.7032 - accuracy: 0.8488 - val_loss: 0.2677 - val_accuracy: 0.8965 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2383 - accuracy: 0.8988 - val_loss: 0.2298 - val_accuracy: 0.9074 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9133 - val_loss: 0.2199 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1903 - accuracy: 0.9219 - val_loss: 0.2179 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1743 - accuracy: 0.9273 - val_loss: 0.2076 - val_accuracy: 0.9082 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1529 - accuracy: 0.9334 - val_loss: 0.2109 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9423 - val_loss: 0.2167 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1372 - accuracy: 0.9455 - val_loss: 0.2120 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1250 - accuracy: 0.9498 - val_loss: 0.2029 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1174 - accuracy: 0.9529 - val_loss: 0.2027 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1160 - accuracy: 0.9543 - val_loss: 0.2048 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1060 - accuracy: 0.9576 - val_loss: 0.2003 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1033 - accuracy: 0.9595 - val_loss: 0.1956 - val_accuracy: 0.9261 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.9602 - val_loss: 0.1964 - val_accuracy: 0.9241 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9625 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9681 - val_loss: 0.1994 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9652 - val_loss: 0.2010 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9692 - val_loss: 0.1986 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0874 - accuracy: 0.9677 - val_loss: 0.2006 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9680 - val_loss: 0.2000 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9716 - val_loss: 0.2004 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9729 - val_loss: 0.2007 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9704 - val_loss: 0.2010 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0791 - accuracy: 0.9715 - val_loss: 0.2008 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9717 - val_loss: 0.2016 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0787 - accuracy: 0.9725 - val_loss: 0.2016 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9715 - val_loss: 0.2019 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9721 - val_loss: 0.2018 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9739 - val_loss: 0.2015 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9712 - val_loss: 0.2014 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0754 - accuracy: 0.9746 - val_loss: 0.2017 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9721 - val_loss: 0.2014 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9740 - val_loss: 0.2016 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0760 - accuracy: 0.9725 - val_loss: 0.2015 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9734 - val_loss: 0.2014 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0746 - accuracy: 0.9742 - val_loss: 0.2015 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9726 - val_loss: 0.2016 - val_accuracy: 0.9241 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0769 - accuracy: 0.9743 - val_loss: 0.2017 - val_accuracy: 0.9237 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9738 - val_loss: 0.2017 - val_accuracy: 0.9237 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9124172829894901 0.9331269349845202 0.8773584905660378 0.812076127147161 0.9052427127752789 0.970090088335897\n",
            "Epoch 1/200\n",
            "238/241 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.8242"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.9706 - accuracy: 0.8255 - val_loss: 0.3725 - val_accuracy: 0.8541 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2701 - accuracy: 0.8869 - val_loss: 0.2537 - val_accuracy: 0.8844 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2300 - accuracy: 0.9023 - val_loss: 0.2285 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2137 - accuracy: 0.9096 - val_loss: 0.2161 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2015 - accuracy: 0.9151 - val_loss: 0.2151 - val_accuracy: 0.9097 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1822 - accuracy: 0.9220 - val_loss: 0.2090 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9303 - val_loss: 0.2389 - val_accuracy: 0.8988 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1655 - accuracy: 0.9297 - val_loss: 0.2067 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9381 - val_loss: 0.2088 - val_accuracy: 0.9093 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1451 - accuracy: 0.9402 - val_loss: 0.2036 - val_accuracy: 0.9160 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1420 - accuracy: 0.9430 - val_loss: 0.2042 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1318 - accuracy: 0.9454 - val_loss: 0.2118 - val_accuracy: 0.9117 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1306 - accuracy: 0.9477 - val_loss: 0.2012 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9515 - val_loss: 0.2025 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1218 - accuracy: 0.9529 - val_loss: 0.2010 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9552 - val_loss: 0.2070 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9551 - val_loss: 0.2034 - val_accuracy: 0.9171 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9572 - val_loss: 0.2018 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9585 - val_loss: 0.2031 - val_accuracy: 0.9148 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9587 - val_loss: 0.2009 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1085 - accuracy: 0.9599 - val_loss: 0.2007 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9609 - val_loss: 0.2001 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9598 - val_loss: 0.2020 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9624 - val_loss: 0.2008 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9626 - val_loss: 0.2002 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1000 - accuracy: 0.9650 - val_loss: 0.2013 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9628 - val_loss: 0.2008 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9594 - val_loss: 0.2009 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9619 - val_loss: 0.2004 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9633 - val_loss: 0.1999 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9626 - val_loss: 0.2009 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9626 - val_loss: 0.2007 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9639 - val_loss: 0.2010 - val_accuracy: 0.9175 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1003 - accuracy: 0.9626 - val_loss: 0.2009 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0986 - accuracy: 0.9659 - val_loss: 0.2010 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0968 - accuracy: 0.9668 - val_loss: 0.2010 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9644 - val_loss: 0.2014 - val_accuracy: 0.9167 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9626 - val_loss: 0.2012 - val_accuracy: 0.9167 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9654 - val_loss: 0.2012 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9647 - val_loss: 0.2013 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9637 - val_loss: 0.2012 - val_accuracy: 0.9167 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9373297002724795 0.9442033477991321 0.9257322175732218 0.866536278839092 0.9349677826861769 0.9801517871270821\n",
            "Epoch 1/200\n",
            "233/241 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.8407"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.6808 - accuracy: 0.8420 - val_loss: 0.3529 - val_accuracy: 0.8942 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2435 - accuracy: 0.8962 - val_loss: 0.2311 - val_accuracy: 0.9047 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2103 - accuracy: 0.9101 - val_loss: 0.2175 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1927 - accuracy: 0.9203 - val_loss: 0.2287 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1782 - accuracy: 0.9263 - val_loss: 0.2134 - val_accuracy: 0.9132 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1573 - accuracy: 0.9359 - val_loss: 0.2071 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1492 - accuracy: 0.9388 - val_loss: 0.2089 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1462 - accuracy: 0.9386 - val_loss: 0.1931 - val_accuracy: 0.9237 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9475 - val_loss: 0.2018 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9511 - val_loss: 0.2059 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1223 - accuracy: 0.9515 - val_loss: 0.2151 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9590 - val_loss: 0.1945 - val_accuracy: 0.9222 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1068 - accuracy: 0.9606 - val_loss: 0.1944 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1938 - val_accuracy: 0.9249 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9642 - val_loss: 0.1976 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9622 - val_loss: 0.1946 - val_accuracy: 0.9257 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0978 - accuracy: 0.9652 - val_loss: 0.1927 - val_accuracy: 0.9292 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9691 - val_loss: 0.1920 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0895 - accuracy: 0.9677 - val_loss: 0.1946 - val_accuracy: 0.9268 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0887 - accuracy: 0.9661 - val_loss: 0.1937 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.1923 - val_accuracy: 0.9268 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.1934 - val_accuracy: 0.9272 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9690 - val_loss: 0.1931 - val_accuracy: 0.9284 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9704 - val_loss: 0.1948 - val_accuracy: 0.9276 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0828 - accuracy: 0.9720 - val_loss: 0.1958 - val_accuracy: 0.9272 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0816 - accuracy: 0.9707 - val_loss: 0.1937 - val_accuracy: 0.9265 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9711 - val_loss: 0.1938 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9708 - val_loss: 0.1930 - val_accuracy: 0.9253 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0820 - accuracy: 0.9704 - val_loss: 0.1930 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9731 - val_loss: 0.1932 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0796 - accuracy: 0.9731 - val_loss: 0.1940 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9700 - val_loss: 0.1944 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0814 - accuracy: 0.9704 - val_loss: 0.1943 - val_accuracy: 0.9268 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9730 - val_loss: 0.1942 - val_accuracy: 0.9268 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0816 - accuracy: 0.9713 - val_loss: 0.1945 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0797 - accuracy: 0.9724 - val_loss: 0.1944 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9712 - val_loss: 0.1945 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9194239003503308 0.9335863377609108 0.8967611336032388 0.8298774198812677 0.9151737356820748 0.97676994266428\n",
            "Epoch 1/200\n",
            "238/241 [============================>.] - ETA: 0s - loss: 0.7221 - accuracy: 0.8410"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.7160 - accuracy: 0.8414 - val_loss: 0.2783 - val_accuracy: 0.8848 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2483 - accuracy: 0.8943 - val_loss: 0.2348 - val_accuracy: 0.9035 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2072 - accuracy: 0.9111 - val_loss: 0.2185 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1921 - accuracy: 0.9179 - val_loss: 0.2141 - val_accuracy: 0.9148 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1780 - accuracy: 0.9251 - val_loss: 0.2128 - val_accuracy: 0.9167 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9337 - val_loss: 0.2094 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.9408 - val_loss: 0.2148 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1354 - accuracy: 0.9429 - val_loss: 0.2016 - val_accuracy: 0.9206 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1220 - accuracy: 0.9523 - val_loss: 0.2001 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9516 - val_loss: 0.2101 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9577 - val_loss: 0.2001 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1030 - accuracy: 0.9611 - val_loss: 0.1982 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0967 - accuracy: 0.9637 - val_loss: 0.1959 - val_accuracy: 0.9241 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9670 - val_loss: 0.1963 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9667 - val_loss: 0.1985 - val_accuracy: 0.9229 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0852 - accuracy: 0.9690 - val_loss: 0.2011 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0843 - accuracy: 0.9686 - val_loss: 0.1985 - val_accuracy: 0.9272 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.9731 - val_loss: 0.2006 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9728 - val_loss: 0.1991 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9728 - val_loss: 0.2009 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0724 - accuracy: 0.9751 - val_loss: 0.1983 - val_accuracy: 0.9264 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0714 - accuracy: 0.9755 - val_loss: 0.1984 - val_accuracy: 0.9276 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9763 - val_loss: 0.1975 - val_accuracy: 0.9260 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9747 - val_loss: 0.1977 - val_accuracy: 0.9272 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0691 - accuracy: 0.9772 - val_loss: 0.2004 - val_accuracy: 0.9260 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0699 - accuracy: 0.9759 - val_loss: 0.2005 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.1989 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9766 - val_loss: 0.1996 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 0.2000 - val_accuracy: 0.9264 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9768 - val_loss: 0.2001 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9777 - val_loss: 0.2002 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9786 - val_loss: 0.1998 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9783 - val_loss: 0.1997 - val_accuracy: 0.9264 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0664 - accuracy: 0.9764 - val_loss: 0.1995 - val_accuracy: 0.9260 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0657 - accuracy: 0.9774 - val_loss: 0.1996 - val_accuracy: 0.9264 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0670 - accuracy: 0.9759 - val_loss: 0.1996 - val_accuracy: 0.9264 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 0.9770 - val_loss: 0.1997 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.1998 - val_accuracy: 0.9268 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.1999 - val_accuracy: 0.9272 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9766 - val_loss: 0.1999 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 0.1996 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.1998 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9229571984435798 0.9256299938537185 0.9183457051961824 0.8363354987346303 0.9219878495249505 0.978390899592703\n",
            "Epoch 1/200\n",
            "239/241 [============================>.] - ETA: 0s - loss: 1.6132 - accuracy: 0.8194"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 1.6025 - accuracy: 0.8199 - val_loss: 0.3107 - val_accuracy: 0.8638 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2697 - accuracy: 0.8827 - val_loss: 0.2544 - val_accuracy: 0.8891 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2294 - accuracy: 0.9061 - val_loss: 0.2397 - val_accuracy: 0.8957 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2116 - accuracy: 0.9107 - val_loss: 0.2270 - val_accuracy: 0.9031 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1982 - accuracy: 0.9172 - val_loss: 0.2152 - val_accuracy: 0.9054 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1816 - accuracy: 0.9264 - val_loss: 0.2124 - val_accuracy: 0.9058 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1717 - accuracy: 0.9279 - val_loss: 0.2070 - val_accuracy: 0.9051 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1639 - accuracy: 0.9320 - val_loss: 0.2066 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1500 - accuracy: 0.9381 - val_loss: 0.2053 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9430 - val_loss: 0.1992 - val_accuracy: 0.9113 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1397 - accuracy: 0.9446 - val_loss: 0.2038 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1300 - accuracy: 0.9497 - val_loss: 0.1992 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1292 - accuracy: 0.9475 - val_loss: 0.2069 - val_accuracy: 0.9101 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1223 - accuracy: 0.9526 - val_loss: 0.2002 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9545 - val_loss: 0.1988 - val_accuracy: 0.9156 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.9556 - val_loss: 0.2010 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9556 - val_loss: 0.1960 - val_accuracy: 0.9148 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9560 - val_loss: 0.1973 - val_accuracy: 0.9191 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9591 - val_loss: 0.1991 - val_accuracy: 0.9183 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1060 - accuracy: 0.9576 - val_loss: 0.1974 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9598 - val_loss: 0.1975 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.1983 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9615 - val_loss: 0.1985 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9621 - val_loss: 0.1989 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9620 - val_loss: 0.1986 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9624 - val_loss: 0.2008 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9624 - val_loss: 0.1986 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9642 - val_loss: 0.1985 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9628 - val_loss: 0.1983 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9648 - val_loss: 0.1984 - val_accuracy: 0.9179 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9630 - val_loss: 0.1986 - val_accuracy: 0.9175 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9650 - val_loss: 0.1988 - val_accuracy: 0.9175 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9652 - val_loss: 0.1988 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0968 - accuracy: 0.9646 - val_loss: 0.1988 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9225379525107046 0.9478970495919649 0.8811475409836066 0.8348233151767783 0.9145222952877857 0.9716726225391829\n",
            "Epoch 1/200\n",
            "237/241 [============================>.] - ETA: 0s - loss: 1.2350 - accuracy: 0.8356"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 1.2203 - accuracy: 0.8357 - val_loss: 0.2635 - val_accuracy: 0.8887 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2515 - accuracy: 0.8902 - val_loss: 0.2357 - val_accuracy: 0.8984 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2115 - accuracy: 0.9115 - val_loss: 0.2404 - val_accuracy: 0.8988 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1974 - accuracy: 0.9166 - val_loss: 0.2203 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1860 - accuracy: 0.9209 - val_loss: 0.2138 - val_accuracy: 0.9082 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1656 - accuracy: 0.9284 - val_loss: 0.2147 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1574 - accuracy: 0.9334 - val_loss: 0.2059 - val_accuracy: 0.9179 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1497 - accuracy: 0.9385 - val_loss: 0.2108 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1343 - accuracy: 0.9437 - val_loss: 0.2102 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9473 - val_loss: 0.2060 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1255 - accuracy: 0.9482 - val_loss: 0.2095 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1201 - accuracy: 0.9547 - val_loss: 0.2052 - val_accuracy: 0.9222 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.9541 - val_loss: 0.2013 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1135 - accuracy: 0.9546 - val_loss: 0.2001 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1052 - accuracy: 0.9577 - val_loss: 0.2013 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9604 - val_loss: 0.2035 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9598 - val_loss: 0.2054 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 0.9641 - val_loss: 0.2056 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9624 - val_loss: 0.2025 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9596 - val_loss: 0.2047 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0949 - accuracy: 0.9642 - val_loss: 0.2047 - val_accuracy: 0.9218 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9639 - val_loss: 0.2062 - val_accuracy: 0.9202 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9622 - val_loss: 0.2056 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0926 - accuracy: 0.9652 - val_loss: 0.2043 - val_accuracy: 0.9222 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9685 - val_loss: 0.2038 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9674 - val_loss: 0.2052 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9668 - val_loss: 0.2052 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0887 - accuracy: 0.9690 - val_loss: 0.2050 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0890 - accuracy: 0.9681 - val_loss: 0.2049 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9685 - val_loss: 0.2050 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0876 - accuracy: 0.9682 - val_loss: 0.2057 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9687 - val_loss: 0.2057 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0896 - accuracy: 0.9676 - val_loss: 0.2055 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0887 - accuracy: 0.9682 - val_loss: 0.2055 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9690 - val_loss: 0.2054 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9660 - val_loss: 0.2054 - val_accuracy: 0.9241 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9687 - val_loss: 0.2054 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9680 - val_loss: 0.2056 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9657 - val_loss: 0.2056 - val_accuracy: 0.9241 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9682 - val_loss: 0.2056 - val_accuracy: 0.9241 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0883 - accuracy: 0.9695 - val_loss: 0.2057 - val_accuracy: 0.9249 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0899 - accuracy: 0.9669 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9673 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9681 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0870 - accuracy: 0.9680 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9659 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0883 - accuracy: 0.9685 - val_loss: 0.2056 - val_accuracy: 0.9257 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9683 - val_loss: 0.2056 - val_accuracy: 0.9257 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0895 - accuracy: 0.9667 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9663 - val_loss: 0.2055 - val_accuracy: 0.9253 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9689 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0859 - accuracy: 0.9707 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9676 - val_loss: 0.2055 - val_accuracy: 0.9249 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9698 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9661 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9694 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0858 - accuracy: 0.9699 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9708 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9665 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9681 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0878 - accuracy: 0.9687 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9674 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9670 - val_loss: 0.2056 - val_accuracy: 0.9253 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0872 - accuracy: 0.9667 - val_loss: 0.2055 - val_accuracy: 0.9253 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0882 - accuracy: 0.9669 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0856 - accuracy: 0.9704 - val_loss: 0.2057 - val_accuracy: 0.9253 - lr: 1.3162e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9124172829894901 0.9337461300309597 0.8763102725366876 0.8120066625377059 0.9050282012838237 0.9704314893782736\n",
            "Epoch 1/200\n",
            "236/241 [============================>.] - ETA: 0s - loss: 1.0770 - accuracy: 0.8336"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 1.0595 - accuracy: 0.8353 - val_loss: 0.2935 - val_accuracy: 0.8693 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2572 - accuracy: 0.8861 - val_loss: 0.2475 - val_accuracy: 0.8942 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2165 - accuracy: 0.9079 - val_loss: 0.2350 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2037 - accuracy: 0.9137 - val_loss: 0.2196 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1915 - accuracy: 0.9203 - val_loss: 0.2181 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1708 - accuracy: 0.9258 - val_loss: 0.2073 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1607 - accuracy: 0.9327 - val_loss: 0.2285 - val_accuracy: 0.9043 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1520 - accuracy: 0.9354 - val_loss: 0.2085 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1391 - accuracy: 0.9441 - val_loss: 0.2124 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1326 - accuracy: 0.9468 - val_loss: 0.2256 - val_accuracy: 0.9012 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1260 - accuracy: 0.9472 - val_loss: 0.2073 - val_accuracy: 0.9109 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9556 - val_loss: 0.2100 - val_accuracy: 0.9105 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9587 - val_loss: 0.2110 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1126 - accuracy: 0.9554 - val_loss: 0.2118 - val_accuracy: 0.9117 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9603 - val_loss: 0.2111 - val_accuracy: 0.9089 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0998 - accuracy: 0.9620 - val_loss: 0.2120 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9612 - val_loss: 0.2121 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 0.9634 - val_loss: 0.2101 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9659 - val_loss: 0.2110 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0953 - accuracy: 0.9641 - val_loss: 0.2109 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9659 - val_loss: 0.2116 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.2121 - val_accuracy: 0.9132 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0894 - accuracy: 0.9672 - val_loss: 0.2120 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9683 - val_loss: 0.2121 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9683 - val_loss: 0.2131 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9677 - val_loss: 0.2150 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9708 - val_loss: 0.2127 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0863 - accuracy: 0.9715 - val_loss: 0.2128 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.9699 - val_loss: 0.2135 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9686 - val_loss: 0.2126 - val_accuracy: 0.9128 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9691 - val_loss: 0.2128 - val_accuracy: 0.9125 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0848 - accuracy: 0.9715 - val_loss: 0.2140 - val_accuracy: 0.9132 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0850 - accuracy: 0.9696 - val_loss: 0.2134 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9676 - val_loss: 0.2132 - val_accuracy: 0.9140 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 0.2134 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 0.2135 - val_accuracy: 0.9132 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9295445698715453 0.9516429014259145 0.8922594142259415 0.8486068228763571 0.921951157825928 0.9792425948166958\n",
            "Epoch 1/200\n",
            "235/241 [============================>.] - ETA: 0s - loss: 0.9000 - accuracy: 0.8411"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.8851 - accuracy: 0.8425 - val_loss: 0.2599 - val_accuracy: 0.8907 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.2504 - accuracy: 0.8922 - val_loss: 0.2452 - val_accuracy: 0.9016 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2081 - accuracy: 0.9110 - val_loss: 0.2190 - val_accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1934 - accuracy: 0.9193 - val_loss: 0.2267 - val_accuracy: 0.9054 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1846 - accuracy: 0.9238 - val_loss: 0.2164 - val_accuracy: 0.9113 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1606 - accuracy: 0.9330 - val_loss: 0.2078 - val_accuracy: 0.9171 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1533 - accuracy: 0.9354 - val_loss: 0.2039 - val_accuracy: 0.9191 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1473 - accuracy: 0.9415 - val_loss: 0.2014 - val_accuracy: 0.9198 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1308 - accuracy: 0.9476 - val_loss: 0.2000 - val_accuracy: 0.9253 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1252 - accuracy: 0.9515 - val_loss: 0.1961 - val_accuracy: 0.9241 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1193 - accuracy: 0.9508 - val_loss: 0.1953 - val_accuracy: 0.9253 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9568 - val_loss: 0.1955 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9556 - val_loss: 0.1933 - val_accuracy: 0.9249 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1047 - accuracy: 0.9590 - val_loss: 0.1979 - val_accuracy: 0.9307 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9632 - val_loss: 0.1933 - val_accuracy: 0.9272 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9641 - val_loss: 0.1991 - val_accuracy: 0.9265 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9669 - val_loss: 0.1985 - val_accuracy: 0.9272 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9657 - val_loss: 0.1929 - val_accuracy: 0.9292 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0863 - accuracy: 0.9678 - val_loss: 0.1934 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9680 - val_loss: 0.1926 - val_accuracy: 0.9296 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0861 - accuracy: 0.9704 - val_loss: 0.1942 - val_accuracy: 0.9288 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.1952 - val_accuracy: 0.9300 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0827 - accuracy: 0.9721 - val_loss: 0.1946 - val_accuracy: 0.9319 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9709 - val_loss: 0.1951 - val_accuracy: 0.9304 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0806 - accuracy: 0.9721 - val_loss: 0.1956 - val_accuracy: 0.9292 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9709 - val_loss: 0.1945 - val_accuracy: 0.9311 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9739 - val_loss: 0.1958 - val_accuracy: 0.9288 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.1946 - val_accuracy: 0.9311 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 0.1950 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9713 - val_loss: 0.1943 - val_accuracy: 0.9307 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9734 - val_loss: 0.1942 - val_accuracy: 0.9304 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0778 - accuracy: 0.9734 - val_loss: 0.1951 - val_accuracy: 0.9307 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0796 - accuracy: 0.9729 - val_loss: 0.1946 - val_accuracy: 0.9304 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9738 - val_loss: 0.1946 - val_accuracy: 0.9304 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9744 - val_loss: 0.1947 - val_accuracy: 0.9315 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0797 - accuracy: 0.9725 - val_loss: 0.1946 - val_accuracy: 0.9311 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 0.1948 - val_accuracy: 0.9311 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0777 - accuracy: 0.9717 - val_loss: 0.1947 - val_accuracy: 0.9315 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0785 - accuracy: 0.9715 - val_loss: 0.1946 - val_accuracy: 0.9311 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 0.9733 - val_loss: 0.1947 - val_accuracy: 0.9311 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9733 - val_loss: 0.1947 - val_accuracy: 0.9311 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9708 - val_loss: 0.1949 - val_accuracy: 0.9315 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0779 - accuracy: 0.9740 - val_loss: 0.1948 - val_accuracy: 0.9315 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9213701829505644 0.9361163820366857 0.8977732793522267 0.8338896613889124 0.9169448306944562 0.977402133636529\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.9573 - accuracy: 0.8259 - val_loss: 0.3988 - val_accuracy: 0.8630 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2157 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2671 - accuracy: 0.8857 - val_loss: 0.2469 - val_accuracy: 0.8957 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2272 - accuracy: 0.9036 - val_loss: 0.2276 - val_accuracy: 0.8976 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9107 - val_loss: 0.2374 - val_accuracy: 0.8945 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1979 - accuracy: 0.9161 - val_loss: 0.2167 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9251 - val_loss: 0.2087 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1705 - accuracy: 0.9275 - val_loss: 0.2140 - val_accuracy: 0.9155 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1616 - accuracy: 0.9319 - val_loss: 0.2123 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1503 - accuracy: 0.9373 - val_loss: 0.2015 - val_accuracy: 0.9190 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9386 - val_loss: 0.1989 - val_accuracy: 0.9190 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9389 - val_loss: 0.1998 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9432 - val_loss: 0.2005 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9468 - val_loss: 0.2001 - val_accuracy: 0.9179 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1269 - accuracy: 0.9504 - val_loss: 0.1990 - val_accuracy: 0.9198 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9478 - val_loss: 0.1987 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9528 - val_loss: 0.2012 - val_accuracy: 0.9186 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.9511 - val_loss: 0.1993 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1161 - accuracy: 0.9548 - val_loss: 0.1983 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9555 - val_loss: 0.1963 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1142 - accuracy: 0.9541 - val_loss: 0.2004 - val_accuracy: 0.9198 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9529 - val_loss: 0.1963 - val_accuracy: 0.9202 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9573 - val_loss: 0.1977 - val_accuracy: 0.9194 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9551 - val_loss: 0.1964 - val_accuracy: 0.9202 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1091 - accuracy: 0.9586 - val_loss: 0.1966 - val_accuracy: 0.9186 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9558 - val_loss: 0.1963 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1093 - accuracy: 0.9594 - val_loss: 0.1969 - val_accuracy: 0.9194 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9599 - val_loss: 0.1969 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9589 - val_loss: 0.1965 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9568 - val_loss: 0.1967 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9598 - val_loss: 0.1964 - val_accuracy: 0.9194 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9598 - val_loss: 0.1965 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9583 - val_loss: 0.1967 - val_accuracy: 0.9179 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1058 - accuracy: 0.9580 - val_loss: 0.1970 - val_accuracy: 0.9186 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9567 - val_loss: 0.1971 - val_accuracy: 0.9194 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9596 - val_loss: 0.1970 - val_accuracy: 0.9190 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9593 - val_loss: 0.1970 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9594 - val_loss: 0.1970 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9576 - val_loss: 0.1967 - val_accuracy: 0.9190 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9245136186770428 0.9262446220036877 0.9215270413573701 0.8397778941425406 0.923885831680529 0.9800939996519498\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5249 - accuracy: 0.8313 - val_loss: 0.3449 - val_accuracy: 0.8879 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2675 - accuracy: 0.8438"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2616 - accuracy: 0.8914 - val_loss: 0.2393 - val_accuracy: 0.8992 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9116 - val_loss: 0.2191 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2006 - accuracy: 0.9112 - val_loss: 0.2109 - val_accuracy: 0.9125 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1903 - accuracy: 0.9206 - val_loss: 0.2138 - val_accuracy: 0.9097 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1701 - accuracy: 0.9282 - val_loss: 0.2017 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1587 - accuracy: 0.9333 - val_loss: 0.2257 - val_accuracy: 0.9004 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9342 - val_loss: 0.1957 - val_accuracy: 0.9210 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1392 - accuracy: 0.9437 - val_loss: 0.2012 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9442 - val_loss: 0.2041 - val_accuracy: 0.9125 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9475 - val_loss: 0.1921 - val_accuracy: 0.9237 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9516 - val_loss: 0.1938 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1916 - val_accuracy: 0.9253 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9532 - val_loss: 0.1902 - val_accuracy: 0.9241 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9560 - val_loss: 0.1888 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1089 - accuracy: 0.9578 - val_loss: 0.1924 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9593 - val_loss: 0.1926 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9620 - val_loss: 0.1896 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9607 - val_loss: 0.1912 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9620 - val_loss: 0.1926 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9620 - val_loss: 0.1922 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9641 - val_loss: 0.1926 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9620 - val_loss: 0.1914 - val_accuracy: 0.9265 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9642 - val_loss: 0.1915 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0934 - accuracy: 0.9656 - val_loss: 0.1922 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9644 - val_loss: 0.1912 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9660 - val_loss: 0.1914 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9635 - val_loss: 0.1925 - val_accuracy: 0.9253 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9674 - val_loss: 0.1919 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9678 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9691 - val_loss: 0.1917 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9654 - val_loss: 0.1913 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0901 - accuracy: 0.9667 - val_loss: 0.1915 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9678 - val_loss: 0.1915 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9683 - val_loss: 0.1916 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9647 - val_loss: 0.1914 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9673 - val_loss: 0.1917 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9646 - val_loss: 0.1916 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9676 - val_loss: 0.1915 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9660 - val_loss: 0.1916 - val_accuracy: 0.9253 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9678 - val_loss: 0.1915 - val_accuracy: 0.9253 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9667 - val_loss: 0.1915 - val_accuracy: 0.9253 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9672 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9659 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9669 - val_loss: 0.1916 - val_accuracy: 0.9253 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9668 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9673 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0893 - accuracy: 0.9692 - val_loss: 0.1917 - val_accuracy: 0.9253 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9663 - val_loss: 0.1917 - val_accuracy: 0.9257 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0887 - accuracy: 0.9661 - val_loss: 0.1917 - val_accuracy: 0.9253 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0890 - accuracy: 0.9677 - val_loss: 0.1917 - val_accuracy: 0.9253 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9655 - val_loss: 0.1916 - val_accuracy: 0.9253 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9248734916309849 0.943502824858757 0.8944672131147541 0.8401858695583776 0.9189850189867556 0.9750162082059831\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6851 - accuracy: 0.8215 - val_loss: 0.3897 - val_accuracy: 0.8206 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.3275 - accuracy: 0.8438"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2558 - accuracy: 0.8901 - val_loss: 0.2484 - val_accuracy: 0.8930 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9094 - val_loss: 0.2240 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9154 - val_loss: 0.2189 - val_accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1883 - accuracy: 0.9207 - val_loss: 0.2117 - val_accuracy: 0.9163 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1677 - accuracy: 0.9319 - val_loss: 0.2034 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.9332 - val_loss: 0.2048 - val_accuracy: 0.9214 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9371 - val_loss: 0.2112 - val_accuracy: 0.9210 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9424 - val_loss: 0.2188 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9465 - val_loss: 0.1982 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9436 - val_loss: 0.2022 - val_accuracy: 0.9245 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1244 - accuracy: 0.9512 - val_loss: 0.2004 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1166 - accuracy: 0.9529 - val_loss: 0.2015 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9537 - val_loss: 0.1988 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9560 - val_loss: 0.2002 - val_accuracy: 0.9195 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1102 - accuracy: 0.9567 - val_loss: 0.1991 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9611 - val_loss: 0.2029 - val_accuracy: 0.9222 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9598 - val_loss: 0.2011 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9585 - val_loss: 0.1995 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9617 - val_loss: 0.1992 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0997 - accuracy: 0.9616 - val_loss: 0.1994 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 0.1975 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9630 - val_loss: 0.1974 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9637 - val_loss: 0.1977 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9642 - val_loss: 0.1991 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9633 - val_loss: 0.1983 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9635 - val_loss: 0.1981 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9632 - val_loss: 0.1988 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9661 - val_loss: 0.1981 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.1980 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0946 - accuracy: 0.9663 - val_loss: 0.1983 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9089139743090697 0.9380804953560371 0.859538784067086 0.8038071260287423 0.8988096397115615 0.9690370024209618\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4977 - accuracy: 0.8372 - val_loss: 0.3732 - val_accuracy: 0.8728 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2012 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2617 - accuracy: 0.8883 - val_loss: 0.2473 - val_accuracy: 0.8946 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9049 - val_loss: 0.2225 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9120 - val_loss: 0.2246 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9193 - val_loss: 0.2232 - val_accuracy: 0.9047 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1743 - accuracy: 0.9250 - val_loss: 0.2044 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9282 - val_loss: 0.2157 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9381 - val_loss: 0.2075 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9414 - val_loss: 0.2076 - val_accuracy: 0.9066 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1400 - accuracy: 0.9398 - val_loss: 0.2028 - val_accuracy: 0.9156 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1355 - accuracy: 0.9464 - val_loss: 0.1988 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1273 - accuracy: 0.9478 - val_loss: 0.2009 - val_accuracy: 0.9163 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9528 - val_loss: 0.2039 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9521 - val_loss: 0.2025 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1126 - accuracy: 0.9564 - val_loss: 0.2014 - val_accuracy: 0.9187 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9551 - val_loss: 0.2022 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9582 - val_loss: 0.2019 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9622 - val_loss: 0.2021 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9615 - val_loss: 0.2021 - val_accuracy: 0.9187 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1038 - accuracy: 0.9586 - val_loss: 0.2012 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9637 - val_loss: 0.2039 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9644 - val_loss: 0.2027 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9609 - val_loss: 0.2022 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9642 - val_loss: 0.2021 - val_accuracy: 0.9187 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9628 - val_loss: 0.2017 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9626 - val_loss: 0.2012 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9641 - val_loss: 0.2006 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9641 - val_loss: 0.2014 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9616 - val_loss: 0.2011 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9664 - val_loss: 0.2009 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9650 - val_loss: 0.2008 - val_accuracy: 0.9230 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9643 - val_loss: 0.2012 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0951 - accuracy: 0.9652 - val_loss: 0.2011 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0937 - accuracy: 0.9670 - val_loss: 0.2009 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9647 - val_loss: 0.2010 - val_accuracy: 0.9214 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9644 - val_loss: 0.2010 - val_accuracy: 0.9222 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.2010 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9657 - val_loss: 0.2010 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9660 - val_loss: 0.2009 - val_accuracy: 0.9222 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0937 - accuracy: 0.9673 - val_loss: 0.2009 - val_accuracy: 0.9222 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9624 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0948 - accuracy: 0.9664 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9663 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9669 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0929 - accuracy: 0.9669 - val_loss: 0.2010 - val_accuracy: 0.9222 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9646 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9630 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9654 - val_loss: 0.2011 - val_accuracy: 0.9222 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9664 - val_loss: 0.2012 - val_accuracy: 0.9222 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9311015959517321 0.9448233106013639 0.9079497907949791 0.852591768525184 0.9263865506981714 0.9806261624302542\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5686 - accuracy: 0.8347 - val_loss: 0.3631 - val_accuracy: 0.8568 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.1921 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2551 - accuracy: 0.8905 - val_loss: 0.2382 - val_accuracy: 0.8977 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2142 - accuracy: 0.9071 - val_loss: 0.2180 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1998 - accuracy: 0.9175 - val_loss: 0.2126 - val_accuracy: 0.9125 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9209 - val_loss: 0.2255 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1679 - accuracy: 0.9293 - val_loss: 0.2075 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1613 - accuracy: 0.9319 - val_loss: 0.2007 - val_accuracy: 0.9202 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9372 - val_loss: 0.2017 - val_accuracy: 0.9210 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1425 - accuracy: 0.9414 - val_loss: 0.1948 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1376 - accuracy: 0.9450 - val_loss: 0.2021 - val_accuracy: 0.9226 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9478 - val_loss: 0.1992 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9511 - val_loss: 0.1998 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1205 - accuracy: 0.9526 - val_loss: 0.1933 - val_accuracy: 0.9257 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.1967 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9563 - val_loss: 0.1954 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9591 - val_loss: 0.1920 - val_accuracy: 0.9265 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9585 - val_loss: 0.1923 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9624 - val_loss: 0.1924 - val_accuracy: 0.9280 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9593 - val_loss: 0.1921 - val_accuracy: 0.9261 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9613 - val_loss: 0.1910 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9621 - val_loss: 0.1918 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1000 - accuracy: 0.9632 - val_loss: 0.1908 - val_accuracy: 0.9300 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9619 - val_loss: 0.1907 - val_accuracy: 0.9284 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9644 - val_loss: 0.1914 - val_accuracy: 0.9284 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.1914 - val_accuracy: 0.9280 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9616 - val_loss: 0.1917 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9642 - val_loss: 0.1918 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9657 - val_loss: 0.1915 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9661 - val_loss: 0.1917 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9669 - val_loss: 0.1916 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9652 - val_loss: 0.1915 - val_accuracy: 0.9284 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9659 - val_loss: 0.1917 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0941 - accuracy: 0.9657 - val_loss: 0.1918 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9672 - val_loss: 0.1919 - val_accuracy: 0.9280 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9683 - val_loss: 0.1917 - val_accuracy: 0.9288 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9668 - val_loss: 0.1917 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9668 - val_loss: 0.1918 - val_accuracy: 0.9280 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9661 - val_loss: 0.1919 - val_accuracy: 0.9284 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9660 - val_loss: 0.1918 - val_accuracy: 0.9280 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9650 - val_loss: 0.1919 - val_accuracy: 0.9276 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.1919 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 0.1919 - val_accuracy: 0.9280 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9240949785908914 0.9380139152435167 0.9018218623481782 0.8396766762494643 0.9199178887958475 0.9767020821649804\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7958"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.6925 - accuracy: 0.7958 - val_loss: 0.3655 - val_accuracy: 0.8513 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2748 - accuracy: 0.8796 - val_loss: 0.2692 - val_accuracy: 0.8735 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2267 - accuracy: 0.8978 - val_loss: 0.2258 - val_accuracy: 0.9011 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9102 - val_loss: 0.2319 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1976 - accuracy: 0.9137 - val_loss: 0.2193 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9227 - val_loss: 0.2076 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9307 - val_loss: 0.2029 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1586 - accuracy: 0.9363 - val_loss: 0.2033 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1448 - accuracy: 0.9399 - val_loss: 0.2004 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1351 - accuracy: 0.9447 - val_loss: 0.2020 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1326 - accuracy: 0.9458 - val_loss: 0.1957 - val_accuracy: 0.9221 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1214 - accuracy: 0.9487 - val_loss: 0.1966 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1201 - accuracy: 0.9517 - val_loss: 0.1970 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9547 - val_loss: 0.1965 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9587 - val_loss: 0.1898 - val_accuracy: 0.9276 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9554 - val_loss: 0.1951 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9600 - val_loss: 0.1947 - val_accuracy: 0.9202 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9598 - val_loss: 0.1915 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9624 - val_loss: 0.1932 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9648 - val_loss: 0.1914 - val_accuracy: 0.9264 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9650 - val_loss: 0.1913 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0938 - accuracy: 0.9635 - val_loss: 0.1923 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9629 - val_loss: 0.1914 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9650 - val_loss: 0.1915 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9655 - val_loss: 0.1920 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9676 - val_loss: 0.1915 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9669 - val_loss: 0.1915 - val_accuracy: 0.9264 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9672 - val_loss: 0.1914 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9676 - val_loss: 0.1913 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9695 - val_loss: 0.1912 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9676 - val_loss: 0.1914 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9690 - val_loss: 0.1916 - val_accuracy: 0.9264 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0870 - accuracy: 0.9676 - val_loss: 0.1916 - val_accuracy: 0.9260 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9674 - val_loss: 0.1914 - val_accuracy: 0.9264 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9687 - val_loss: 0.1916 - val_accuracy: 0.9260 - lr: 3.6280e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9280155642023347 0.9323909035033805 0.9204665959703076 0.8466133967843582 0.926428749736844 0.9798528412049841\n",
            "Epoch 1/200\n",
            "234/241 [============================>.] - ETA: 0s - loss: 0.6561 - accuracy: 0.8206"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 4s 7ms/step - loss: 0.6458 - accuracy: 0.8219 - val_loss: 0.3827 - val_accuracy: 0.8658 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2636 - accuracy: 0.8863 - val_loss: 0.2636 - val_accuracy: 0.8848 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2194 - accuracy: 0.9079 - val_loss: 0.2118 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2054 - accuracy: 0.9119 - val_loss: 0.2177 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1930 - accuracy: 0.9197 - val_loss: 0.1976 - val_accuracy: 0.9144 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9298 - val_loss: 0.2061 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1609 - accuracy: 0.9315 - val_loss: 0.1980 - val_accuracy: 0.9171 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9334 - val_loss: 0.2024 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1377 - accuracy: 0.9417 - val_loss: 0.1884 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1330 - accuracy: 0.9442 - val_loss: 0.1904 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1244 - accuracy: 0.9481 - val_loss: 0.1927 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1145 - accuracy: 0.9530 - val_loss: 0.1876 - val_accuracy: 0.9222 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9565 - val_loss: 0.1879 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1070 - accuracy: 0.9563 - val_loss: 0.1932 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0996 - accuracy: 0.9625 - val_loss: 0.1889 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0978 - accuracy: 0.9612 - val_loss: 0.1903 - val_accuracy: 0.9214 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9617 - val_loss: 0.1883 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9632 - val_loss: 0.1902 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9654 - val_loss: 0.1892 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0895 - accuracy: 0.9674 - val_loss: 0.1878 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9700 - val_loss: 0.1882 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0836 - accuracy: 0.9716 - val_loss: 0.1911 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9677 - val_loss: 0.1896 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9683 - val_loss: 0.1893 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0837 - accuracy: 0.9705 - val_loss: 0.1896 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0840 - accuracy: 0.9694 - val_loss: 0.1892 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.0833 - accuracy: 0.9702 - val_loss: 0.1891 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9713 - val_loss: 0.1895 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9699 - val_loss: 0.1893 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.1891 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9720 - val_loss: 0.1889 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9713 - val_loss: 0.1892 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.1893 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9705 - val_loss: 0.1891 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0803 - accuracy: 0.9699 - val_loss: 0.1891 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 0.1893 - val_accuracy: 0.9249 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0812 - accuracy: 0.9702 - val_loss: 0.1892 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9695 - val_loss: 0.1892 - val_accuracy: 0.9261 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0812 - accuracy: 0.9724 - val_loss: 0.1892 - val_accuracy: 0.9265 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9720 - val_loss: 0.1893 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9738 - val_loss: 0.1891 - val_accuracy: 0.9265 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9733 - val_loss: 0.1892 - val_accuracy: 0.9265 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9711 - val_loss: 0.1893 - val_accuracy: 0.9261 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 0.1892 - val_accuracy: 0.9265 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 0.1891 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9731 - val_loss: 0.1893 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9744 - val_loss: 0.1893 - val_accuracy: 0.9261 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9256520046710782 0.943502824858757 0.8965163934426229 0.8418916075120794 0.92000960915069 0.975513710084077\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 0.8105 - accuracy: 0.8099"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.8088 - accuracy: 0.8102 - val_loss: 0.3740 - val_accuracy: 0.8623 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2621 - accuracy: 0.8854 - val_loss: 0.3419 - val_accuracy: 0.8268 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2217 - accuracy: 0.9036 - val_loss: 0.2218 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9084 - val_loss: 0.2240 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1951 - accuracy: 0.9153 - val_loss: 0.2239 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.9280 - val_loss: 0.2250 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1652 - accuracy: 0.9319 - val_loss: 0.2252 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1597 - accuracy: 0.9347 - val_loss: 0.2330 - val_accuracy: 0.8973 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1464 - accuracy: 0.9364 - val_loss: 0.2047 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1366 - accuracy: 0.9404 - val_loss: 0.2137 - val_accuracy: 0.9148 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1346 - accuracy: 0.9429 - val_loss: 0.2043 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9508 - val_loss: 0.2129 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9532 - val_loss: 0.2023 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1174 - accuracy: 0.9516 - val_loss: 0.2048 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9593 - val_loss: 0.2081 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1091 - accuracy: 0.9541 - val_loss: 0.2026 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1078 - accuracy: 0.9581 - val_loss: 0.2024 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9611 - val_loss: 0.2043 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1007 - accuracy: 0.9616 - val_loss: 0.2047 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9615 - val_loss: 0.2065 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.0985 - accuracy: 0.9637 - val_loss: 0.2034 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9641 - val_loss: 0.2021 - val_accuracy: 0.9230 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9647 - val_loss: 0.2021 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0926 - accuracy: 0.9657 - val_loss: 0.2028 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9642 - val_loss: 0.2026 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0923 - accuracy: 0.9654 - val_loss: 0.2032 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.2033 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9655 - val_loss: 0.2039 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.2038 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0899 - accuracy: 0.9663 - val_loss: 0.2040 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9677 - val_loss: 0.2041 - val_accuracy: 0.9249 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0890 - accuracy: 0.9661 - val_loss: 0.2041 - val_accuracy: 0.9249 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9664 - val_loss: 0.2043 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9681 - val_loss: 0.2043 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9660 - val_loss: 0.2044 - val_accuracy: 0.9249 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0901 - accuracy: 0.9660 - val_loss: 0.2043 - val_accuracy: 0.9249 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0861 - accuracy: 0.9686 - val_loss: 0.2044 - val_accuracy: 0.9253 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0895 - accuracy: 0.9681 - val_loss: 0.2045 - val_accuracy: 0.9253 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0882 - accuracy: 0.9659 - val_loss: 0.2044 - val_accuracy: 0.9249 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9634 - val_loss: 0.2045 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9669 - val_loss: 0.2046 - val_accuracy: 0.9249 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9128065395095368 0.9411764705882353 0.8647798742138365 0.8122088694853613 0.902978172401036 0.9695147042597243\n",
            "Epoch 1/200\n",
            "229/241 [===========================>..] - ETA: 0s - loss: 0.6413 - accuracy: 0.8195"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.6248 - accuracy: 0.8228 - val_loss: 0.4013 - val_accuracy: 0.8440 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2705 - accuracy: 0.8824 - val_loss: 0.2468 - val_accuracy: 0.8953 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2277 - accuracy: 0.9029 - val_loss: 0.2226 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2136 - accuracy: 0.9061 - val_loss: 0.2441 - val_accuracy: 0.8953 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9141 - val_loss: 0.2456 - val_accuracy: 0.8988 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1770 - accuracy: 0.9258 - val_loss: 0.2028 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1688 - accuracy: 0.9303 - val_loss: 0.2003 - val_accuracy: 0.9152 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1571 - accuracy: 0.9336 - val_loss: 0.2304 - val_accuracy: 0.9004 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1431 - accuracy: 0.9412 - val_loss: 0.2013 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1367 - accuracy: 0.9436 - val_loss: 0.1983 - val_accuracy: 0.9183 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1308 - accuracy: 0.9468 - val_loss: 0.2023 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1246 - accuracy: 0.9503 - val_loss: 0.2026 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9528 - val_loss: 0.2026 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.2047 - val_accuracy: 0.9171 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1068 - accuracy: 0.9583 - val_loss: 0.2058 - val_accuracy: 0.9140 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9624 - val_loss: 0.2024 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9630 - val_loss: 0.2077 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9637 - val_loss: 0.2057 - val_accuracy: 0.9179 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9628 - val_loss: 0.2030 - val_accuracy: 0.9191 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0942 - accuracy: 0.9659 - val_loss: 0.2025 - val_accuracy: 0.9187 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9686 - val_loss: 0.2017 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9661 - val_loss: 0.2038 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9669 - val_loss: 0.2045 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9691 - val_loss: 0.2032 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9694 - val_loss: 0.2036 - val_accuracy: 0.9183 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9690 - val_loss: 0.2062 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 0.2052 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0852 - accuracy: 0.9715 - val_loss: 0.2056 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9702 - val_loss: 0.2055 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9680 - val_loss: 0.2059 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.2057 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9711 - val_loss: 0.2054 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9291553133514986 0.949163050216987 0.895397489539749 0.8479075770752416 0.922280269878368 0.9811290715862487\n",
            "Epoch 1/200\n",
            "234/241 [============================>.] - ETA: 0s - loss: 0.7874 - accuracy: 0.7831"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.7735 - accuracy: 0.7854 - val_loss: 0.4190 - val_accuracy: 0.8315 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2744 - accuracy: 0.8798 - val_loss: 0.2732 - val_accuracy: 0.8852 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2254 - accuracy: 0.9033 - val_loss: 0.2257 - val_accuracy: 0.9086 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9076 - val_loss: 0.2112 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1982 - accuracy: 0.9151 - val_loss: 0.2121 - val_accuracy: 0.9136 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1782 - accuracy: 0.9227 - val_loss: 0.2056 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1684 - accuracy: 0.9288 - val_loss: 0.1992 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1604 - accuracy: 0.9323 - val_loss: 0.2058 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1458 - accuracy: 0.9417 - val_loss: 0.2000 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1400 - accuracy: 0.9419 - val_loss: 0.1958 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1382 - accuracy: 0.9421 - val_loss: 0.2009 - val_accuracy: 0.9156 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1272 - accuracy: 0.9480 - val_loss: 0.1929 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1251 - accuracy: 0.9485 - val_loss: 0.1917 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9515 - val_loss: 0.1933 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9528 - val_loss: 0.1912 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1123 - accuracy: 0.9558 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9560 - val_loss: 0.1961 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1065 - accuracy: 0.9586 - val_loss: 0.1900 - val_accuracy: 0.9276 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9587 - val_loss: 0.1896 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9599 - val_loss: 0.1904 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9643 - val_loss: 0.1899 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9619 - val_loss: 0.1900 - val_accuracy: 0.9272 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9638 - val_loss: 0.1928 - val_accuracy: 0.9268 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0966 - accuracy: 0.9643 - val_loss: 0.1918 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0949 - accuracy: 0.9660 - val_loss: 0.1911 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9643 - val_loss: 0.1918 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0935 - accuracy: 0.9665 - val_loss: 0.1920 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9641 - val_loss: 0.1918 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9655 - val_loss: 0.1920 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9647 - val_loss: 0.1915 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9651 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9673 - val_loss: 0.1914 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9677 - val_loss: 0.1915 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 0.9690 - val_loss: 0.1916 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9677 - val_loss: 0.1916 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9651 - val_loss: 0.1918 - val_accuracy: 0.9261 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9664 - val_loss: 0.1918 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0934 - accuracy: 0.9670 - val_loss: 0.1917 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9194239003503308 0.931056293485136 0.9008097165991903 0.8301665233950568 0.9159330050421631 0.9761726422317654\n",
            "Epoch 1/200\n",
            "231/241 [===========================>..] - ETA: 0s - loss: 0.9868 - accuracy: 0.7961"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.9587 - accuracy: 0.8002 - val_loss: 0.3096 - val_accuracy: 0.8412 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2744 - accuracy: 0.8805 - val_loss: 0.2429 - val_accuracy: 0.8988 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9040 - val_loss: 0.2523 - val_accuracy: 0.8937 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9079 - val_loss: 0.2352 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2042 - accuracy: 0.9144 - val_loss: 0.2204 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1808 - accuracy: 0.9257 - val_loss: 0.2330 - val_accuracy: 0.8972 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9253 - val_loss: 0.2153 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9320 - val_loss: 0.2322 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1537 - accuracy: 0.9378 - val_loss: 0.2035 - val_accuracy: 0.9186 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1498 - accuracy: 0.9367 - val_loss: 0.2031 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9386 - val_loss: 0.2027 - val_accuracy: 0.9159 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1349 - accuracy: 0.9445 - val_loss: 0.2013 - val_accuracy: 0.9151 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9499 - val_loss: 0.1989 - val_accuracy: 0.9186 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9486 - val_loss: 0.2104 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1250 - accuracy: 0.9506 - val_loss: 0.1979 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9520 - val_loss: 0.2042 - val_accuracy: 0.9186 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9519 - val_loss: 0.1988 - val_accuracy: 0.9190 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1146 - accuracy: 0.9583 - val_loss: 0.1948 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1126 - accuracy: 0.9555 - val_loss: 0.2021 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9564 - val_loss: 0.1994 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9574 - val_loss: 0.1953 - val_accuracy: 0.9229 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9602 - val_loss: 0.1952 - val_accuracy: 0.9229 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9578 - val_loss: 0.1963 - val_accuracy: 0.9229 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9603 - val_loss: 0.1960 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9577 - val_loss: 0.1956 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9593 - val_loss: 0.1948 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9602 - val_loss: 0.1950 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9567 - val_loss: 0.1967 - val_accuracy: 0.9229 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9600 - val_loss: 0.1973 - val_accuracy: 0.9229 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9629 - val_loss: 0.1958 - val_accuracy: 0.9229 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9625 - val_loss: 0.1964 - val_accuracy: 0.9229 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1044 - accuracy: 0.9582 - val_loss: 0.1955 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9609 - val_loss: 0.1952 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9633 - val_loss: 0.1956 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9620 - val_loss: 0.1956 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9634 - val_loss: 0.1958 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9629 - val_loss: 0.1959 - val_accuracy: 0.9229 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9607 - val_loss: 0.1959 - val_accuracy: 0.9229 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9609 - val_loss: 0.1958 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1042 - accuracy: 0.9596 - val_loss: 0.1959 - val_accuracy: 0.9229 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9603 - val_loss: 0.1958 - val_accuracy: 0.9229 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9628 - val_loss: 0.1959 - val_accuracy: 0.9229 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9622 - val_loss: 0.1957 - val_accuracy: 0.9233 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9609 - val_loss: 0.1958 - val_accuracy: 0.9233 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9620 - val_loss: 0.1958 - val_accuracy: 0.9233 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9613 - val_loss: 0.1958 - val_accuracy: 0.9233 - lr: 4.7018e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9252918287937744 0.9244007375537799 0.926829268292683 0.8419467143431284 0.9256150029232315 0.9783087753648173\n",
            "Epoch 1/200\n",
            "239/241 [============================>.] - ETA: 0s - loss: 0.7877 - accuracy: 0.8358"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 8ms/step - loss: 0.7831 - accuracy: 0.8365 - val_loss: 0.2912 - val_accuracy: 0.8654 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2611 - accuracy: 0.8910 - val_loss: 0.2334 - val_accuracy: 0.8957 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2160 - accuracy: 0.9103 - val_loss: 0.2232 - val_accuracy: 0.9000 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2028 - accuracy: 0.9149 - val_loss: 0.2141 - val_accuracy: 0.9105 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1953 - accuracy: 0.9183 - val_loss: 0.2139 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1728 - accuracy: 0.9293 - val_loss: 0.2039 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1640 - accuracy: 0.9305 - val_loss: 0.2028 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1574 - accuracy: 0.9372 - val_loss: 0.1979 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1464 - accuracy: 0.9423 - val_loss: 0.2043 - val_accuracy: 0.9160 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1402 - accuracy: 0.9438 - val_loss: 0.2010 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1378 - accuracy: 0.9436 - val_loss: 0.1951 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1270 - accuracy: 0.9508 - val_loss: 0.1960 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1260 - accuracy: 0.9497 - val_loss: 0.1949 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9534 - val_loss: 0.1983 - val_accuracy: 0.9183 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1164 - accuracy: 0.9550 - val_loss: 0.1925 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9563 - val_loss: 0.1950 - val_accuracy: 0.9195 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9571 - val_loss: 0.1965 - val_accuracy: 0.9191 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9582 - val_loss: 0.1929 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9577 - val_loss: 0.1921 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9600 - val_loss: 0.1914 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9596 - val_loss: 0.1928 - val_accuracy: 0.9191 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9615 - val_loss: 0.1922 - val_accuracy: 0.9195 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9615 - val_loss: 0.1958 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1016 - accuracy: 0.9609 - val_loss: 0.1919 - val_accuracy: 0.9218 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9633 - val_loss: 0.1923 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9626 - val_loss: 0.1912 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9642 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9633 - val_loss: 0.1919 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9642 - val_loss: 0.1922 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9641 - val_loss: 0.1923 - val_accuracy: 0.9191 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0959 - accuracy: 0.9637 - val_loss: 0.1920 - val_accuracy: 0.9210 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1016 - accuracy: 0.9624 - val_loss: 0.1924 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9644 - val_loss: 0.1920 - val_accuracy: 0.9202 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9634 - val_loss: 0.1924 - val_accuracy: 0.9198 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9637 - val_loss: 0.1919 - val_accuracy: 0.9218 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9202024133904243 0.938480853735091 0.8903688524590164 0.830355547889695 0.9144248530970538 0.9727608877980509\n",
            "Epoch 1/200\n",
            "235/241 [============================>.] - ETA: 0s - loss: 0.5560 - accuracy: 0.8496"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.5475 - accuracy: 0.8513 - val_loss: 0.3128 - val_accuracy: 0.8911 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2419 - accuracy: 0.8987 - val_loss: 0.2307 - val_accuracy: 0.9035 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2044 - accuracy: 0.9129 - val_loss: 0.2345 - val_accuracy: 0.9047 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1867 - accuracy: 0.9196 - val_loss: 0.2143 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9257 - val_loss: 0.2107 - val_accuracy: 0.9144 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1535 - accuracy: 0.9363 - val_loss: 0.2045 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9416 - val_loss: 0.2099 - val_accuracy: 0.9156 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1380 - accuracy: 0.9432 - val_loss: 0.2046 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1229 - accuracy: 0.9502 - val_loss: 0.2017 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9523 - val_loss: 0.2026 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1157 - accuracy: 0.9560 - val_loss: 0.2098 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1037 - accuracy: 0.9622 - val_loss: 0.2017 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9617 - val_loss: 0.2015 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 0.9648 - val_loss: 0.2122 - val_accuracy: 0.9222 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9656 - val_loss: 0.2066 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9680 - val_loss: 0.2029 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9676 - val_loss: 0.2035 - val_accuracy: 0.9222 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9694 - val_loss: 0.2102 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0829 - accuracy: 0.9718 - val_loss: 0.2046 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0834 - accuracy: 0.9707 - val_loss: 0.2053 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9709 - val_loss: 0.2042 - val_accuracy: 0.9222 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 0.2032 - val_accuracy: 0.9226 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.9734 - val_loss: 0.2029 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0774 - accuracy: 0.9712 - val_loss: 0.2050 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9742 - val_loss: 0.2037 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9744 - val_loss: 0.2041 - val_accuracy: 0.9218 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.9753 - val_loss: 0.2043 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.9729 - val_loss: 0.2047 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 0.2048 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 0.2048 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9747 - val_loss: 0.2050 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9740 - val_loss: 0.2052 - val_accuracy: 0.9222 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9170883612300506 0.9405572755417957 0.8773584905660378 0.8217440323789083 0.9089578830539167 0.971275905264456\n",
            "Epoch 1/200\n",
            "236/241 [============================>.] - ETA: 0s - loss: 0.7906 - accuracy: 0.8244"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.7812 - accuracy: 0.8247 - val_loss: 0.3091 - val_accuracy: 0.8467 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.2671 - accuracy: 0.8862 - val_loss: 0.2526 - val_accuracy: 0.8930 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2251 - accuracy: 0.9044 - val_loss: 0.2215 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9081 - val_loss: 0.2182 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9157 - val_loss: 0.2345 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1773 - accuracy: 0.9247 - val_loss: 0.2054 - val_accuracy: 0.9093 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1692 - accuracy: 0.9284 - val_loss: 0.2165 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1590 - accuracy: 0.9340 - val_loss: 0.2100 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1471 - accuracy: 0.9423 - val_loss: 0.2150 - val_accuracy: 0.9062 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1414 - accuracy: 0.9434 - val_loss: 0.2039 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1357 - accuracy: 0.9450 - val_loss: 0.2131 - val_accuracy: 0.9093 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9486 - val_loss: 0.2078 - val_accuracy: 0.9125 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9511 - val_loss: 0.2138 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1195 - accuracy: 0.9534 - val_loss: 0.2067 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9555 - val_loss: 0.2103 - val_accuracy: 0.9140 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9550 - val_loss: 0.2087 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9555 - val_loss: 0.2075 - val_accuracy: 0.9144 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9604 - val_loss: 0.2084 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1038 - accuracy: 0.9603 - val_loss: 0.2086 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9606 - val_loss: 0.2096 - val_accuracy: 0.9148 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9641 - val_loss: 0.2074 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9651 - val_loss: 0.2100 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0968 - accuracy: 0.9626 - val_loss: 0.2108 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9646 - val_loss: 0.2088 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9620 - val_loss: 0.2082 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0966 - accuracy: 0.9641 - val_loss: 0.2107 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9648 - val_loss: 0.2092 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9652 - val_loss: 0.2093 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9663 - val_loss: 0.2099 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9674 - val_loss: 0.2094 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9639 - val_loss: 0.2101 - val_accuracy: 0.9152 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9676 - val_loss: 0.2098 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0941 - accuracy: 0.9646 - val_loss: 0.2099 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9634 - val_loss: 0.2104 - val_accuracy: 0.9140 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9330478785519657 0.9454432734035958 0.9121338912133892 0.8568517725136777 0.9287885823084925 0.9789510955702491\n",
            "Epoch 1/200\n",
            "230/241 [===========================>..] - ETA: 0s - loss: 0.8291 - accuracy: 0.8351"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 7ms/step - loss: 0.8065 - accuracy: 0.8359 - val_loss: 0.3120 - val_accuracy: 0.8541 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2574 - accuracy: 0.8902 - val_loss: 0.2431 - val_accuracy: 0.8957 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2168 - accuracy: 0.9084 - val_loss: 0.2153 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2005 - accuracy: 0.9136 - val_loss: 0.2228 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1911 - accuracy: 0.9194 - val_loss: 0.2177 - val_accuracy: 0.9140 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1710 - accuracy: 0.9307 - val_loss: 0.2048 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9333 - val_loss: 0.2059 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.9347 - val_loss: 0.2018 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1399 - accuracy: 0.9426 - val_loss: 0.1977 - val_accuracy: 0.9253 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1351 - accuracy: 0.9445 - val_loss: 0.1977 - val_accuracy: 0.9226 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9475 - val_loss: 0.1971 - val_accuracy: 0.9237 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9477 - val_loss: 0.1958 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1194 - accuracy: 0.9528 - val_loss: 0.1963 - val_accuracy: 0.9276 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9548 - val_loss: 0.1967 - val_accuracy: 0.9249 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9568 - val_loss: 0.1961 - val_accuracy: 0.9257 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1079 - accuracy: 0.9568 - val_loss: 0.1957 - val_accuracy: 0.9288 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1054 - accuracy: 0.9561 - val_loss: 0.1948 - val_accuracy: 0.9265 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: 0.1973 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9593 - val_loss: 0.1960 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9639 - val_loss: 0.1952 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0959 - accuracy: 0.9625 - val_loss: 0.1943 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0966 - accuracy: 0.9629 - val_loss: 0.1937 - val_accuracy: 0.9284 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.9680 - val_loss: 0.1939 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9650 - val_loss: 0.1949 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9656 - val_loss: 0.1945 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9655 - val_loss: 0.1935 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0935 - accuracy: 0.9660 - val_loss: 0.1946 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 0.9668 - val_loss: 0.1945 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9674 - val_loss: 0.1950 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9667 - val_loss: 0.1946 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9661 - val_loss: 0.1943 - val_accuracy: 0.9249 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9659 - val_loss: 0.1941 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0894 - accuracy: 0.9677 - val_loss: 0.1943 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9674 - val_loss: 0.1950 - val_accuracy: 0.9268 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0920 - accuracy: 0.9639 - val_loss: 0.1945 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9643 - val_loss: 0.1943 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9174776177500973 0.9259962049335864 0.9038461538461539 0.8265255097721891 0.9149211793898702 0.976339732706456\n",
            "Epoch 1/200\n",
            "239/241 [============================>.] - ETA: 0s - loss: 1.1393 - accuracy: 0.8372"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 1.1328 - accuracy: 0.8373 - val_loss: 0.3351 - val_accuracy: 0.8521 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2541 - accuracy: 0.8910 - val_loss: 0.2679 - val_accuracy: 0.8750 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.2120 - accuracy: 0.9087 - val_loss: 0.2212 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1974 - accuracy: 0.9138 - val_loss: 0.2167 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1830 - accuracy: 0.9221 - val_loss: 0.2014 - val_accuracy: 0.9198 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1660 - accuracy: 0.9288 - val_loss: 0.2056 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1583 - accuracy: 0.9355 - val_loss: 0.2233 - val_accuracy: 0.9027 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1479 - accuracy: 0.9377 - val_loss: 0.1979 - val_accuracy: 0.9159 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1340 - accuracy: 0.9455 - val_loss: 0.1929 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1293 - accuracy: 0.9499 - val_loss: 0.1927 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9497 - val_loss: 0.1990 - val_accuracy: 0.9183 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1151 - accuracy: 0.9542 - val_loss: 0.1912 - val_accuracy: 0.9264 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: 0.1891 - val_accuracy: 0.9276 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9558 - val_loss: 0.1898 - val_accuracy: 0.9229 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9600 - val_loss: 0.1928 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9591 - val_loss: 0.1890 - val_accuracy: 0.9272 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9617 - val_loss: 0.1932 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9648 - val_loss: 0.1909 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9648 - val_loss: 0.1926 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0920 - accuracy: 0.9633 - val_loss: 0.1916 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9660 - val_loss: 0.1916 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9655 - val_loss: 0.1909 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0890 - accuracy: 0.9659 - val_loss: 0.1905 - val_accuracy: 0.9264 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9682 - val_loss: 0.1903 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9707 - val_loss: 0.1905 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.1905 - val_accuracy: 0.9264 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0829 - accuracy: 0.9716 - val_loss: 0.1910 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9681 - val_loss: 0.1914 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9694 - val_loss: 0.1910 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9698 - val_loss: 0.1912 - val_accuracy: 0.9249 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0833 - accuracy: 0.9709 - val_loss: 0.1918 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9672 - val_loss: 0.1913 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.1915 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9260700389105059 0.9280885064535955 0.9225874867444327 0.8429751375943167 0.9253379965990141 0.978854314878629\n",
            "Epoch 1/200\n",
            "235/241 [============================>.] - ETA: 0s - loss: 1.1484 - accuracy: 0.8375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 10ms/step - loss: 1.1285 - accuracy: 0.8378 - val_loss: 0.2926 - val_accuracy: 0.8844 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2586 - accuracy: 0.8893 - val_loss: 0.2876 - val_accuracy: 0.8782 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2205 - accuracy: 0.9040 - val_loss: 0.2248 - val_accuracy: 0.9023 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.2084 - accuracy: 0.9131 - val_loss: 0.2143 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1915 - accuracy: 0.9177 - val_loss: 0.2222 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1738 - accuracy: 0.9272 - val_loss: 0.2075 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1652 - accuracy: 0.9305 - val_loss: 0.2166 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1566 - accuracy: 0.9340 - val_loss: 0.2151 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.9386 - val_loss: 0.2108 - val_accuracy: 0.9074 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1420 - accuracy: 0.9423 - val_loss: 0.2042 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1384 - accuracy: 0.9425 - val_loss: 0.2023 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9494 - val_loss: 0.2072 - val_accuracy: 0.9160 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9506 - val_loss: 0.1990 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9516 - val_loss: 0.2031 - val_accuracy: 0.9125 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1170 - accuracy: 0.9521 - val_loss: 0.2026 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1149 - accuracy: 0.9525 - val_loss: 0.1993 - val_accuracy: 0.9195 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9576 - val_loss: 0.2006 - val_accuracy: 0.9179 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9572 - val_loss: 0.1992 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9572 - val_loss: 0.2016 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9569 - val_loss: 0.2026 - val_accuracy: 0.9183 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1041 - accuracy: 0.9603 - val_loss: 0.2004 - val_accuracy: 0.9206 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9604 - val_loss: 0.1991 - val_accuracy: 0.9167 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9603 - val_loss: 0.2007 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9617 - val_loss: 0.1994 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9619 - val_loss: 0.1999 - val_accuracy: 0.9187 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9622 - val_loss: 0.1992 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9626 - val_loss: 0.1997 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0987 - accuracy: 0.9626 - val_loss: 0.1994 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9616 - val_loss: 0.1998 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9634 - val_loss: 0.1996 - val_accuracy: 0.9198 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9621 - val_loss: 0.1997 - val_accuracy: 0.9198 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9625 - val_loss: 0.1999 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9620 - val_loss: 0.1997 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1000 - accuracy: 0.9619 - val_loss: 0.1998 - val_accuracy: 0.9210 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0967 - accuracy: 0.9637 - val_loss: 0.1994 - val_accuracy: 0.9206 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9660 - val_loss: 0.1994 - val_accuracy: 0.9202 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9661 - val_loss: 0.1993 - val_accuracy: 0.9202 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9639 - val_loss: 0.1994 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9660 - val_loss: 0.1995 - val_accuracy: 0.9195 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9639 - val_loss: 0.1994 - val_accuracy: 0.9198 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9625 - val_loss: 0.1996 - val_accuracy: 0.9198 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1000 - accuracy: 0.9619 - val_loss: 0.1995 - val_accuracy: 0.9198 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9616 - val_loss: 0.1996 - val_accuracy: 0.9198 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9644 - val_loss: 0.1996 - val_accuracy: 0.9198 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0997 - accuracy: 0.9602 - val_loss: 0.1996 - val_accuracy: 0.9202 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9643 - val_loss: 0.1996 - val_accuracy: 0.9202 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9647 - val_loss: 0.1996 - val_accuracy: 0.9202 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1996 - val_accuracy: 0.9202 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0946 - accuracy: 0.9643 - val_loss: 0.1995 - val_accuracy: 0.9202 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9622 - val_loss: 0.1995 - val_accuracy: 0.9202 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9635 - val_loss: 0.1995 - val_accuracy: 0.9202 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9633 - val_loss: 0.1996 - val_accuracy: 0.9198 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9641 - val_loss: 0.1995 - val_accuracy: 0.9202 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0970 - accuracy: 0.9646 - val_loss: 0.1995 - val_accuracy: 0.9202 - lr: 1.0156e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9225379525107046 0.9391086001255493 0.8954918032786885 0.835436382710724 0.9173002017021189 0.9734310842517985\n",
            "Epoch 1/200\n",
            "232/241 [===========================>..] - ETA: 0s - loss: 1.2190 - accuracy: 0.8442"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 10ms/step - loss: 1.1829 - accuracy: 0.8461 - val_loss: 0.3582 - val_accuracy: 0.8070 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2407 - accuracy: 0.8993 - val_loss: 0.2381 - val_accuracy: 0.8942 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2035 - accuracy: 0.9166 - val_loss: 0.2159 - val_accuracy: 0.9097 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9237 - val_loss: 0.2167 - val_accuracy: 0.9097 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1744 - accuracy: 0.9275 - val_loss: 0.2217 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1547 - accuracy: 0.9372 - val_loss: 0.2063 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1454 - accuracy: 0.9411 - val_loss: 0.1981 - val_accuracy: 0.9214 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1356 - accuracy: 0.9439 - val_loss: 0.2033 - val_accuracy: 0.9152 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9502 - val_loss: 0.1970 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1221 - accuracy: 0.9525 - val_loss: 0.2003 - val_accuracy: 0.9183 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1140 - accuracy: 0.9532 - val_loss: 0.1977 - val_accuracy: 0.9249 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1068 - accuracy: 0.9596 - val_loss: 0.1982 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9625 - val_loss: 0.1959 - val_accuracy: 0.9230 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.0987 - accuracy: 0.9619 - val_loss: 0.1941 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0938 - accuracy: 0.9651 - val_loss: 0.1959 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9651 - val_loss: 0.1954 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9685 - val_loss: 0.2006 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0852 - accuracy: 0.9682 - val_loss: 0.1962 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9702 - val_loss: 0.1952 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0835 - accuracy: 0.9692 - val_loss: 0.1945 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9713 - val_loss: 0.1947 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9725 - val_loss: 0.1955 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0812 - accuracy: 0.9699 - val_loss: 0.1945 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9740 - val_loss: 0.1945 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0809 - accuracy: 0.9700 - val_loss: 0.1957 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9722 - val_loss: 0.1944 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9728 - val_loss: 0.1949 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9726 - val_loss: 0.1951 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0776 - accuracy: 0.9722 - val_loss: 0.1950 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0757 - accuracy: 0.9729 - val_loss: 0.1948 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0780 - accuracy: 0.9720 - val_loss: 0.1950 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0788 - accuracy: 0.9721 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9733 - val_loss: 0.1951 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0769 - accuracy: 0.9726 - val_loss: 0.1952 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9709 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0754 - accuracy: 0.9728 - val_loss: 0.1954 - val_accuracy: 0.9280 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0771 - accuracy: 0.9733 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9737 - val_loss: 0.1952 - val_accuracy: 0.9280 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.9726 - val_loss: 0.1951 - val_accuracy: 0.9276 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0750 - accuracy: 0.9751 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0747 - accuracy: 0.9746 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0740 - accuracy: 0.9733 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.9746 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9743 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9733 - val_loss: 0.1953 - val_accuracy: 0.9276 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 0.1953 - val_accuracy: 0.9276 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0747 - accuracy: 0.9755 - val_loss: 0.1953 - val_accuracy: 0.9280 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9731 - val_loss: 0.1952 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0748 - accuracy: 0.9746 - val_loss: 0.1952 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9734 - val_loss: 0.1953 - val_accuracy: 0.9276 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9756 - val_loss: 0.1954 - val_accuracy: 0.9276 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.9756 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9755 - val_loss: 0.1952 - val_accuracy: 0.9276 - lr: 1.0156e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9104710003892565 0.9269349845201238 0.8825995807127882 0.8085040671687354 0.904767282616456 0.9715803103763849\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 0.8625 - accuracy: 0.8322"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 10ms/step - loss: 0.8625 - accuracy: 0.8322 - val_loss: 0.2825 - val_accuracy: 0.8802 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2670 - accuracy: 0.8793 - val_loss: 0.2465 - val_accuracy: 0.8907 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.2241 - accuracy: 0.9014 - val_loss: 0.2339 - val_accuracy: 0.8914 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2072 - accuracy: 0.9118 - val_loss: 0.2423 - val_accuracy: 0.8922 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1944 - accuracy: 0.9159 - val_loss: 0.2169 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1733 - accuracy: 0.9257 - val_loss: 0.2122 - val_accuracy: 0.9051 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1634 - accuracy: 0.9307 - val_loss: 0.2172 - val_accuracy: 0.9058 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1568 - accuracy: 0.9329 - val_loss: 0.2082 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1422 - accuracy: 0.9415 - val_loss: 0.2135 - val_accuracy: 0.9047 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1369 - accuracy: 0.9447 - val_loss: 0.2110 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1323 - accuracy: 0.9456 - val_loss: 0.2104 - val_accuracy: 0.9121 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1228 - accuracy: 0.9515 - val_loss: 0.2169 - val_accuracy: 0.9066 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 4s 15ms/step - loss: 0.1219 - accuracy: 0.9528 - val_loss: 0.2065 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9563 - val_loss: 0.2109 - val_accuracy: 0.9101 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9554 - val_loss: 0.2124 - val_accuracy: 0.9093 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9578 - val_loss: 0.2107 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9574 - val_loss: 0.2116 - val_accuracy: 0.9136 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9600 - val_loss: 0.2078 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9632 - val_loss: 0.2098 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0993 - accuracy: 0.9634 - val_loss: 0.2103 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9625 - val_loss: 0.2099 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0953 - accuracy: 0.9665 - val_loss: 0.2099 - val_accuracy: 0.9156 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0987 - accuracy: 0.9638 - val_loss: 0.2110 - val_accuracy: 0.9144 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9628 - val_loss: 0.2108 - val_accuracy: 0.9128 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0963 - accuracy: 0.9626 - val_loss: 0.2102 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9617 - val_loss: 0.2101 - val_accuracy: 0.9160 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9647 - val_loss: 0.2104 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0941 - accuracy: 0.9664 - val_loss: 0.2104 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9673 - val_loss: 0.2099 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9647 - val_loss: 0.2102 - val_accuracy: 0.9160 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9683 - val_loss: 0.2104 - val_accuracy: 0.9163 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9676 - val_loss: 0.2108 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9665 - val_loss: 0.2107 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0930 - accuracy: 0.9667 - val_loss: 0.2106 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0905 - accuracy: 0.9673 - val_loss: 0.2108 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9659 - val_loss: 0.2107 - val_accuracy: 0.9140 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9685 - val_loss: 0.2109 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9698 - val_loss: 0.2108 - val_accuracy: 0.9156 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0923 - accuracy: 0.9646 - val_loss: 0.2107 - val_accuracy: 0.9156 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9683 - val_loss: 0.2108 - val_accuracy: 0.9163 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9673 - val_loss: 0.2109 - val_accuracy: 0.9152 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.2108 - val_accuracy: 0.9156 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9650 - val_loss: 0.2107 - val_accuracy: 0.9156 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9689 - val_loss: 0.2108 - val_accuracy: 0.9156 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9683 - val_loss: 0.2109 - val_accuracy: 0.9156 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9291553133514986 0.9404835709857409 0.9100418410041841 0.8487467014047503 0.9252627059949625 0.9803722759898004\n",
            "Epoch 1/200\n",
            "231/241 [===========================>..] - ETA: 0s - loss: 0.9553 - accuracy: 0.8267"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 10ms/step - loss: 0.9286 - accuracy: 0.8287 - val_loss: 0.2724 - val_accuracy: 0.8840 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2653 - accuracy: 0.8847 - val_loss: 0.2359 - val_accuracy: 0.9016 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2240 - accuracy: 0.9042 - val_loss: 0.2271 - val_accuracy: 0.9004 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9115 - val_loss: 0.2249 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1955 - accuracy: 0.9175 - val_loss: 0.2190 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1769 - accuracy: 0.9253 - val_loss: 0.2135 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1720 - accuracy: 0.9272 - val_loss: 0.2156 - val_accuracy: 0.9066 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1677 - accuracy: 0.9280 - val_loss: 0.2103 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1516 - accuracy: 0.9356 - val_loss: 0.2079 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9404 - val_loss: 0.2022 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9467 - val_loss: 0.2031 - val_accuracy: 0.9148 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1319 - accuracy: 0.9481 - val_loss: 0.1975 - val_accuracy: 0.9179 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9498 - val_loss: 0.2008 - val_accuracy: 0.9171 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.1252 - accuracy: 0.9515 - val_loss: 0.1996 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1177 - accuracy: 0.9546 - val_loss: 0.1978 - val_accuracy: 0.9202 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1167 - accuracy: 0.9545 - val_loss: 0.1985 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9559 - val_loss: 0.1999 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1120 - accuracy: 0.9590 - val_loss: 0.1969 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1118 - accuracy: 0.9559 - val_loss: 0.1951 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9568 - val_loss: 0.1984 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9591 - val_loss: 0.1964 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9603 - val_loss: 0.1982 - val_accuracy: 0.9206 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1102 - accuracy: 0.9593 - val_loss: 0.1948 - val_accuracy: 0.9276 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9594 - val_loss: 0.1946 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9624 - val_loss: 0.1950 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9607 - val_loss: 0.1950 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1042 - accuracy: 0.9611 - val_loss: 0.1954 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9621 - val_loss: 0.1949 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9604 - val_loss: 0.1954 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9624 - val_loss: 0.1958 - val_accuracy: 0.9222 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9641 - val_loss: 0.1956 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9628 - val_loss: 0.1954 - val_accuracy: 0.9222 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9635 - val_loss: 0.1954 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9624 - val_loss: 0.1953 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9620 - val_loss: 0.1953 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9617 - val_loss: 0.1953 - val_accuracy: 0.9237 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9616 - val_loss: 0.1955 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9617 - val_loss: 0.1956 - val_accuracy: 0.9230 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9626 - val_loss: 0.1956 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.9644 - val_loss: 0.1954 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9609 - val_loss: 0.1955 - val_accuracy: 0.9233 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9630 - val_loss: 0.1955 - val_accuracy: 0.9230 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1003 - accuracy: 0.9637 - val_loss: 0.1955 - val_accuracy: 0.9230 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9155313351498637 0.9342188488298545 0.8856275303643725 0.8212719351157677 0.9099231895971135 0.9739482902995337\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 1.0266 - accuracy: 0.6668 - val_loss: 0.6570 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.5725 - accuracy: 0.6998"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.7650 - val_loss: 0.4763 - val_accuracy: 0.7727 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.3506 - val_accuracy: 0.8560 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3882 - accuracy: 0.8135 - val_loss: 0.3299 - val_accuracy: 0.8388 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8287 - val_loss: 0.3668 - val_accuracy: 0.8400 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3510 - accuracy: 0.8411 - val_loss: 0.3257 - val_accuracy: 0.8634 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3413 - accuracy: 0.8465 - val_loss: 0.2954 - val_accuracy: 0.8809 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8491 - val_loss: 0.2864 - val_accuracy: 0.8809 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8631 - val_loss: 0.3026 - val_accuracy: 0.8599 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3068 - accuracy: 0.8671 - val_loss: 0.2887 - val_accuracy: 0.8700 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2981 - accuracy: 0.8722 - val_loss: 0.2585 - val_accuracy: 0.8871 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2861 - accuracy: 0.8795 - val_loss: 0.2567 - val_accuracy: 0.8930 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2761 - accuracy: 0.8823 - val_loss: 0.2762 - val_accuracy: 0.8735 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.8818 - val_loss: 0.2518 - val_accuracy: 0.8918 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.8859 - val_loss: 0.2473 - val_accuracy: 0.8930 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2619 - accuracy: 0.8848 - val_loss: 0.2517 - val_accuracy: 0.8930 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2639 - accuracy: 0.8871 - val_loss: 0.2434 - val_accuracy: 0.8933 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.8892 - val_loss: 0.2426 - val_accuracy: 0.8996 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2519 - accuracy: 0.8926 - val_loss: 0.2402 - val_accuracy: 0.8996 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2486 - accuracy: 0.8959 - val_loss: 0.2411 - val_accuracy: 0.8984 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2426 - accuracy: 0.9001 - val_loss: 0.2353 - val_accuracy: 0.8992 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2394 - accuracy: 0.9000 - val_loss: 0.2350 - val_accuracy: 0.9031 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2438 - accuracy: 0.8957 - val_loss: 0.2347 - val_accuracy: 0.9007 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.8970 - val_loss: 0.2342 - val_accuracy: 0.9027 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2414 - accuracy: 0.8978 - val_loss: 0.2338 - val_accuracy: 0.8996 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2397 - accuracy: 0.8988 - val_loss: 0.2338 - val_accuracy: 0.9000 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2434 - accuracy: 0.8950 - val_loss: 0.2338 - val_accuracy: 0.8980 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2408 - accuracy: 0.8988 - val_loss: 0.2338 - val_accuracy: 0.8980 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2352 - accuracy: 0.8970 - val_loss: 0.2318 - val_accuracy: 0.9004 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2370 - accuracy: 0.8975 - val_loss: 0.2323 - val_accuracy: 0.9004 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2360 - accuracy: 0.9014 - val_loss: 0.2322 - val_accuracy: 0.9004 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2325 - accuracy: 0.9000 - val_loss: 0.2318 - val_accuracy: 0.9019 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2342 - accuracy: 0.9004 - val_loss: 0.2320 - val_accuracy: 0.9000 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2342 - accuracy: 0.8997 - val_loss: 0.2317 - val_accuracy: 0.9007 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2353 - accuracy: 0.8994 - val_loss: 0.2316 - val_accuracy: 0.9015 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2328 - accuracy: 0.9004 - val_loss: 0.2325 - val_accuracy: 0.8972 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2343 - accuracy: 0.9019 - val_loss: 0.2314 - val_accuracy: 0.9023 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2322 - accuracy: 0.9016 - val_loss: 0.2313 - val_accuracy: 0.9019 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2335 - accuracy: 0.9011 - val_loss: 0.2315 - val_accuracy: 0.9015 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2328 - accuracy: 0.9000 - val_loss: 0.2313 - val_accuracy: 0.9019 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2352 - accuracy: 0.9026 - val_loss: 0.2314 - val_accuracy: 0.9023 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2365 - accuracy: 0.9006 - val_loss: 0.2315 - val_accuracy: 0.9019 - lr: 7.8364e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9089494163424124 0.9287031346035648 0.8748674443266172 0.8039301131981389 0.9017852894650911 0.9700748438499056\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5277 - accuracy: 0.8376 - val_loss: 0.3041 - val_accuracy: 0.8829 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2749 - accuracy: 0.8808"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2620 - accuracy: 0.8917 - val_loss: 0.2533 - val_accuracy: 0.9012 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2268 - accuracy: 0.9045 - val_loss: 0.2250 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9131 - val_loss: 0.2302 - val_accuracy: 0.9004 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9168 - val_loss: 0.2115 - val_accuracy: 0.9086 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9234 - val_loss: 0.2059 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9281 - val_loss: 0.2025 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1710 - accuracy: 0.9293 - val_loss: 0.2013 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1583 - accuracy: 0.9337 - val_loss: 0.2043 - val_accuracy: 0.9105 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1542 - accuracy: 0.9360 - val_loss: 0.1966 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9389 - val_loss: 0.2060 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9420 - val_loss: 0.1944 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1409 - accuracy: 0.9430 - val_loss: 0.1946 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1347 - accuracy: 0.9491 - val_loss: 0.1938 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9471 - val_loss: 0.1892 - val_accuracy: 0.9195 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1258 - accuracy: 0.9485 - val_loss: 0.1930 - val_accuracy: 0.9179 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9489 - val_loss: 0.1905 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9495 - val_loss: 0.1892 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1229 - accuracy: 0.9512 - val_loss: 0.1901 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1204 - accuracy: 0.9530 - val_loss: 0.1880 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1210 - accuracy: 0.9517 - val_loss: 0.1890 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9537 - val_loss: 0.1885 - val_accuracy: 0.9195 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9511 - val_loss: 0.1883 - val_accuracy: 0.9191 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9546 - val_loss: 0.1888 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9559 - val_loss: 0.1879 - val_accuracy: 0.9206 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1166 - accuracy: 0.9533 - val_loss: 0.1875 - val_accuracy: 0.9222 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9530 - val_loss: 0.1870 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1143 - accuracy: 0.9576 - val_loss: 0.1880 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9533 - val_loss: 0.1874 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9564 - val_loss: 0.1877 - val_accuracy: 0.9198 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1118 - accuracy: 0.9548 - val_loss: 0.1879 - val_accuracy: 0.9195 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9571 - val_loss: 0.1881 - val_accuracy: 0.9183 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9561 - val_loss: 0.1880 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.1881 - val_accuracy: 0.9191 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9568 - val_loss: 0.1880 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9572 - val_loss: 0.1878 - val_accuracy: 0.9195 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9559 - val_loss: 0.1880 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9556 - val_loss: 0.1877 - val_accuracy: 0.9202 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9515 - val_loss: 0.1877 - val_accuracy: 0.9202 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9587 - val_loss: 0.1876 - val_accuracy: 0.9206 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.920591669910471 0.935969868173258 0.8954918032786885 0.8314616714519465 0.9157308357259732 0.9722167551686168\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.8073 - accuracy: 0.7748 - val_loss: 0.3512 - val_accuracy: 0.8459 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.3614 - accuracy: 0.8504"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8661 - val_loss: 0.2786 - val_accuracy: 0.8817 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2705 - accuracy: 0.8819 - val_loss: 0.2426 - val_accuracy: 0.9000 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2515 - accuracy: 0.8882 - val_loss: 0.2355 - val_accuracy: 0.8969 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.8966 - val_loss: 0.2423 - val_accuracy: 0.9004 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9071 - val_loss: 0.2167 - val_accuracy: 0.9054 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9083 - val_loss: 0.2328 - val_accuracy: 0.8973 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2073 - accuracy: 0.9135 - val_loss: 0.2175 - val_accuracy: 0.9035 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1968 - accuracy: 0.9197 - val_loss: 0.2160 - val_accuracy: 0.9066 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1904 - accuracy: 0.9192 - val_loss: 0.2154 - val_accuracy: 0.9070 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1883 - accuracy: 0.9207 - val_loss: 0.2089 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9231 - val_loss: 0.2079 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1743 - accuracy: 0.9285 - val_loss: 0.2069 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1729 - accuracy: 0.9271 - val_loss: 0.2077 - val_accuracy: 0.9152 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1664 - accuracy: 0.9330 - val_loss: 0.2095 - val_accuracy: 0.9109 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1651 - accuracy: 0.9329 - val_loss: 0.2061 - val_accuracy: 0.9144 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1653 - accuracy: 0.9319 - val_loss: 0.2028 - val_accuracy: 0.9160 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9333 - val_loss: 0.2056 - val_accuracy: 0.9140 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1601 - accuracy: 0.9341 - val_loss: 0.2041 - val_accuracy: 0.9152 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9363 - val_loss: 0.2023 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9360 - val_loss: 0.2026 - val_accuracy: 0.9171 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1548 - accuracy: 0.9359 - val_loss: 0.2060 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1530 - accuracy: 0.9373 - val_loss: 0.2014 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1522 - accuracy: 0.9381 - val_loss: 0.2034 - val_accuracy: 0.9160 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.9385 - val_loss: 0.2047 - val_accuracy: 0.9156 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1487 - accuracy: 0.9384 - val_loss: 0.2027 - val_accuracy: 0.9156 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1477 - accuracy: 0.9377 - val_loss: 0.2038 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1531 - accuracy: 0.9373 - val_loss: 0.2039 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9369 - val_loss: 0.2058 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9349 - val_loss: 0.2040 - val_accuracy: 0.9163 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1485 - accuracy: 0.9403 - val_loss: 0.2040 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9386 - val_loss: 0.2034 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1512 - accuracy: 0.9388 - val_loss: 0.2038 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1526 - accuracy: 0.9393 - val_loss: 0.2036 - val_accuracy: 0.9175 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.9436 - val_loss: 0.2033 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9394 - val_loss: 0.2034 - val_accuracy: 0.9171 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1486 - accuracy: 0.9369 - val_loss: 0.2033 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9349 - val_loss: 0.2032 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1470 - accuracy: 0.9394 - val_loss: 0.2035 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9382 - val_loss: 0.2036 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1473 - accuracy: 0.9398 - val_loss: 0.2034 - val_accuracy: 0.9175 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1442 - accuracy: 0.9399 - val_loss: 0.2033 - val_accuracy: 0.9171 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1492 - accuracy: 0.9406 - val_loss: 0.2032 - val_accuracy: 0.9167 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9104710003892565 0.9318885448916409 0.8742138364779874 0.8078634781578842 0.9030511906848142 0.9682019977802441\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4858 - accuracy: 0.8370 - val_loss: 0.2938 - val_accuracy: 0.8798 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.2841 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2665 - accuracy: 0.8843 - val_loss: 0.2389 - val_accuracy: 0.8907 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2326 - accuracy: 0.9016 - val_loss: 0.2192 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2178 - accuracy: 0.9083 - val_loss: 0.2129 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9148 - val_loss: 0.2146 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9210 - val_loss: 0.2059 - val_accuracy: 0.9093 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1835 - accuracy: 0.9223 - val_loss: 0.2044 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9294 - val_loss: 0.2058 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1585 - accuracy: 0.9332 - val_loss: 0.1996 - val_accuracy: 0.9117 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1512 - accuracy: 0.9366 - val_loss: 0.2149 - val_accuracy: 0.9054 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9380 - val_loss: 0.2068 - val_accuracy: 0.9105 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9441 - val_loss: 0.2032 - val_accuracy: 0.9117 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1350 - accuracy: 0.9468 - val_loss: 0.2006 - val_accuracy: 0.9125 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1300 - accuracy: 0.9455 - val_loss: 0.2072 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1258 - accuracy: 0.9494 - val_loss: 0.2018 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1241 - accuracy: 0.9520 - val_loss: 0.2024 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9506 - val_loss: 0.2025 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.9524 - val_loss: 0.2016 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9563 - val_loss: 0.2047 - val_accuracy: 0.9132 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9561 - val_loss: 0.2037 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 0.2019 - val_accuracy: 0.9144 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1137 - accuracy: 0.9551 - val_loss: 0.2027 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9556 - val_loss: 0.2009 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1126 - accuracy: 0.9563 - val_loss: 0.2019 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9589 - val_loss: 0.2026 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9586 - val_loss: 0.2029 - val_accuracy: 0.9136 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9585 - val_loss: 0.2027 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9560 - val_loss: 0.2024 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1076 - accuracy: 0.9591 - val_loss: 0.2027 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1093 - accuracy: 0.9582 - val_loss: 0.2031 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9595 - val_loss: 0.2032 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9591 - val_loss: 0.2029 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9607 - val_loss: 0.2029 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9591 - val_loss: 0.2031 - val_accuracy: 0.9144 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9574 - val_loss: 0.2029 - val_accuracy: 0.9140 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9586 - val_loss: 0.2030 - val_accuracy: 0.9132 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9604 - val_loss: 0.2031 - val_accuracy: 0.9144 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9573 - val_loss: 0.2031 - val_accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1060 - accuracy: 0.9602 - val_loss: 0.2030 - val_accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9594 - val_loss: 0.2029 - val_accuracy: 0.9144 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9615 - val_loss: 0.2029 - val_accuracy: 0.9144 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9607 - val_loss: 0.2031 - val_accuracy: 0.9144 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9578 - val_loss: 0.2029 - val_accuracy: 0.9136 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9561 - val_loss: 0.2029 - val_accuracy: 0.9136 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9573 - val_loss: 0.2030 - val_accuracy: 0.9132 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9583 - val_loss: 0.2030 - val_accuracy: 0.9136 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.928766056831452 0.9342839429634222 0.9194560669456067 0.8487427171913484 0.9268700049545144 0.980049000407256\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4659 - accuracy: 0.8411 - val_loss: 0.2915 - val_accuracy: 0.8938 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.2573 - accuracy: 0.8895"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2533 - accuracy: 0.8910 - val_loss: 0.2447 - val_accuracy: 0.8961 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9094 - val_loss: 0.2296 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9157 - val_loss: 0.2202 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1956 - accuracy: 0.9183 - val_loss: 0.2078 - val_accuracy: 0.9128 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1770 - accuracy: 0.9257 - val_loss: 0.2061 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1693 - accuracy: 0.9266 - val_loss: 0.2109 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1624 - accuracy: 0.9318 - val_loss: 0.1996 - val_accuracy: 0.9218 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9360 - val_loss: 0.1965 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9407 - val_loss: 0.2022 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1420 - accuracy: 0.9401 - val_loss: 0.2034 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1321 - accuracy: 0.9462 - val_loss: 0.1955 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1318 - accuracy: 0.9459 - val_loss: 0.1968 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9500 - val_loss: 0.2005 - val_accuracy: 0.9195 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1222 - accuracy: 0.9490 - val_loss: 0.1960 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1223 - accuracy: 0.9504 - val_loss: 0.1942 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9513 - val_loss: 0.1932 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9525 - val_loss: 0.1941 - val_accuracy: 0.9276 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1150 - accuracy: 0.9530 - val_loss: 0.1939 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1133 - accuracy: 0.9552 - val_loss: 0.1954 - val_accuracy: 0.9261 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9547 - val_loss: 0.1937 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9546 - val_loss: 0.1939 - val_accuracy: 0.9268 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9554 - val_loss: 0.1955 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9576 - val_loss: 0.1946 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9580 - val_loss: 0.1920 - val_accuracy: 0.9292 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9590 - val_loss: 0.1930 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9600 - val_loss: 0.1938 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9586 - val_loss: 0.1935 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9589 - val_loss: 0.1923 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9572 - val_loss: 0.1931 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9599 - val_loss: 0.1933 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9583 - val_loss: 0.1927 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9567 - val_loss: 0.1926 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1045 - accuracy: 0.9599 - val_loss: 0.1925 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9591 - val_loss: 0.1924 - val_accuracy: 0.9268 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9580 - val_loss: 0.1926 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9620 - val_loss: 0.1928 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9593 - val_loss: 0.1930 - val_accuracy: 0.9268 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9594 - val_loss: 0.1929 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1081 - accuracy: 0.9567 - val_loss: 0.1929 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9619 - val_loss: 0.1929 - val_accuracy: 0.9265 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9596 - val_loss: 0.1929 - val_accuracy: 0.9257 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9600 - val_loss: 0.1928 - val_accuracy: 0.9257 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9596 - val_loss: 0.1930 - val_accuracy: 0.9261 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9564 - val_loss: 0.1931 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9182561307901907 0.9297912713472486 0.8997975708502024 0.8277436117822903 0.9147944210987256 0.9766764744293958\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.7973 - val_loss: 0.4593 - val_accuracy: 0.8435 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8270"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.8727 - val_loss: 0.2510 - val_accuracy: 0.8875 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2417 - accuracy: 0.8909 - val_loss: 0.2263 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2270 - accuracy: 0.9016 - val_loss: 0.2372 - val_accuracy: 0.8945 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9071 - val_loss: 0.2124 - val_accuracy: 0.9105 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1910 - accuracy: 0.9171 - val_loss: 0.2092 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1856 - accuracy: 0.9214 - val_loss: 0.2037 - val_accuracy: 0.9085 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9254 - val_loss: 0.1965 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1595 - accuracy: 0.9297 - val_loss: 0.1990 - val_accuracy: 0.9163 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1589 - accuracy: 0.9354 - val_loss: 0.1956 - val_accuracy: 0.9140 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1540 - accuracy: 0.9347 - val_loss: 0.1964 - val_accuracy: 0.9194 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9416 - val_loss: 0.1936 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9407 - val_loss: 0.1909 - val_accuracy: 0.9186 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1385 - accuracy: 0.9421 - val_loss: 0.1903 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9465 - val_loss: 0.1873 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9486 - val_loss: 0.1892 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9493 - val_loss: 0.1895 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9512 - val_loss: 0.1879 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1192 - accuracy: 0.9524 - val_loss: 0.1873 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9507 - val_loss: 0.1876 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9521 - val_loss: 0.1882 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1157 - accuracy: 0.9523 - val_loss: 0.1882 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9545 - val_loss: 0.1889 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1075 - accuracy: 0.9563 - val_loss: 0.1905 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9547 - val_loss: 0.1880 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1109 - accuracy: 0.9548 - val_loss: 0.1887 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1121 - accuracy: 0.9546 - val_loss: 0.1884 - val_accuracy: 0.9264 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1086 - accuracy: 0.9582 - val_loss: 0.1904 - val_accuracy: 0.9229 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9565 - val_loss: 0.1887 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9550 - val_loss: 0.1885 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9573 - val_loss: 0.1885 - val_accuracy: 0.9260 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9581 - val_loss: 0.1893 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9545 - val_loss: 0.1888 - val_accuracy: 0.9257 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9556 - val_loss: 0.1885 - val_accuracy: 0.9260 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9583 - val_loss: 0.1881 - val_accuracy: 0.9268 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9574 - val_loss: 0.1882 - val_accuracy: 0.9264 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9587 - val_loss: 0.1883 - val_accuracy: 0.9264 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9587 - val_loss: 0.1883 - val_accuracy: 0.9260 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9571 - val_loss: 0.1883 - val_accuracy: 0.9264 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9574 - val_loss: 0.1883 - val_accuracy: 0.9264 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.9582 - val_loss: 0.1883 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9249027237354086 0.926859250153657 0.9215270413573701 0.8405461308901739 0.9241931457555135 0.9802478196343386\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5596 - accuracy: 0.8152 - val_loss: 0.3859 - val_accuracy: 0.8160 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 14/241 [>.............................] - ETA: 0s - loss: 0.3835 - accuracy: 0.8058"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2863 - accuracy: 0.8734 - val_loss: 0.2763 - val_accuracy: 0.8720 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2430 - accuracy: 0.8937 - val_loss: 0.2290 - val_accuracy: 0.8899 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2248 - accuracy: 0.9062 - val_loss: 0.2214 - val_accuracy: 0.9023 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2155 - accuracy: 0.9077 - val_loss: 0.2128 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1907 - accuracy: 0.9205 - val_loss: 0.2126 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1842 - accuracy: 0.9221 - val_loss: 0.2064 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1783 - accuracy: 0.9242 - val_loss: 0.2058 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9329 - val_loss: 0.1962 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9341 - val_loss: 0.2050 - val_accuracy: 0.9105 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1537 - accuracy: 0.9372 - val_loss: 0.1978 - val_accuracy: 0.9121 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9393 - val_loss: 0.1942 - val_accuracy: 0.9144 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1385 - accuracy: 0.9434 - val_loss: 0.1991 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.9454 - val_loss: 0.1927 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1330 - accuracy: 0.9445 - val_loss: 0.1913 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9482 - val_loss: 0.1923 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1266 - accuracy: 0.9493 - val_loss: 0.1897 - val_accuracy: 0.9195 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1250 - accuracy: 0.9490 - val_loss: 0.1882 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1222 - accuracy: 0.9516 - val_loss: 0.1899 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1210 - accuracy: 0.9516 - val_loss: 0.1903 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9530 - val_loss: 0.1891 - val_accuracy: 0.9214 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9551 - val_loss: 0.1904 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9537 - val_loss: 0.1905 - val_accuracy: 0.9198 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9547 - val_loss: 0.1908 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9532 - val_loss: 0.1895 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9534 - val_loss: 0.1887 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9547 - val_loss: 0.1892 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1150 - accuracy: 0.9525 - val_loss: 0.1889 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9580 - val_loss: 0.1894 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9578 - val_loss: 0.1887 - val_accuracy: 0.9218 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9585 - val_loss: 0.1887 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9568 - val_loss: 0.1891 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9560 - val_loss: 0.1892 - val_accuracy: 0.9206 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1125 - accuracy: 0.9572 - val_loss: 0.1891 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9547 - val_loss: 0.1890 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9583 - val_loss: 0.1893 - val_accuracy: 0.9195 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9564 - val_loss: 0.1891 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9568 - val_loss: 0.1890 - val_accuracy: 0.9191 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9538 - val_loss: 0.1892 - val_accuracy: 0.9198 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9233164655507979 0.9485247959824231 0.882172131147541 0.8364871690825957 0.915348463564982 0.9760707063690532\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6057 - accuracy: 0.8269 - val_loss: 0.3750 - val_accuracy: 0.8778 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 14/241 [>.............................] - ETA: 0s - loss: 0.2570 - accuracy: 0.8929"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2718 - accuracy: 0.8827 - val_loss: 0.2477 - val_accuracy: 0.8981 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9044 - val_loss: 0.2344 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9075 - val_loss: 0.2200 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9124 - val_loss: 0.2277 - val_accuracy: 0.9047 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.9237 - val_loss: 0.2097 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1720 - accuracy: 0.9253 - val_loss: 0.2157 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9282 - val_loss: 0.2061 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.9364 - val_loss: 0.2023 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1471 - accuracy: 0.9385 - val_loss: 0.1985 - val_accuracy: 0.9156 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1392 - accuracy: 0.9446 - val_loss: 0.1953 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1339 - accuracy: 0.9451 - val_loss: 0.2014 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1320 - accuracy: 0.9459 - val_loss: 0.2022 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1272 - accuracy: 0.9499 - val_loss: 0.1989 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.9521 - val_loss: 0.1939 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9538 - val_loss: 0.1998 - val_accuracy: 0.9191 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9530 - val_loss: 0.1949 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9532 - val_loss: 0.1939 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9586 - val_loss: 0.1965 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9589 - val_loss: 0.1980 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9551 - val_loss: 0.1955 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9580 - val_loss: 0.1943 - val_accuracy: 0.9198 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9558 - val_loss: 0.1940 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9598 - val_loss: 0.1955 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9593 - val_loss: 0.1954 - val_accuracy: 0.9206 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9609 - val_loss: 0.1944 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9613 - val_loss: 0.1951 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9608 - val_loss: 0.1947 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9608 - val_loss: 0.1946 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9577 - val_loss: 0.1951 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9615 - val_loss: 0.1948 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9604 - val_loss: 0.1947 - val_accuracy: 0.9195 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1009 - accuracy: 0.9617 - val_loss: 0.1946 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9594 - val_loss: 0.1947 - val_accuracy: 0.9198 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9577 - val_loss: 0.1947 - val_accuracy: 0.9198 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9135850525496302 0.9362229102167182 0.8752620545073375 0.8143526773786741 0.9057424823620279 0.9694955572430891\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.8155 - accuracy: 0.7788 - val_loss: 0.4280 - val_accuracy: 0.7739 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 14/241 [>.............................] - ETA: 0s - loss: 0.3083 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2973 - accuracy: 0.8658 - val_loss: 0.2598 - val_accuracy: 0.8899 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2460 - accuracy: 0.8927 - val_loss: 0.2396 - val_accuracy: 0.9012 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2324 - accuracy: 0.9011 - val_loss: 0.2245 - val_accuracy: 0.9082 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2229 - accuracy: 0.9045 - val_loss: 0.2182 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.9131 - val_loss: 0.2077 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1934 - accuracy: 0.9185 - val_loss: 0.2052 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9202 - val_loss: 0.2017 - val_accuracy: 0.9093 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9250 - val_loss: 0.1988 - val_accuracy: 0.9113 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9290 - val_loss: 0.2091 - val_accuracy: 0.9070 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9323 - val_loss: 0.2012 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9350 - val_loss: 0.1975 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1478 - accuracy: 0.9401 - val_loss: 0.1943 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1467 - accuracy: 0.9377 - val_loss: 0.1974 - val_accuracy: 0.9086 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1398 - accuracy: 0.9441 - val_loss: 0.1910 - val_accuracy: 0.9156 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1381 - accuracy: 0.9429 - val_loss: 0.1933 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1320 - accuracy: 0.9464 - val_loss: 0.1920 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1315 - accuracy: 0.9490 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1315 - accuracy: 0.9450 - val_loss: 0.1916 - val_accuracy: 0.9136 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.9506 - val_loss: 0.1921 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1278 - accuracy: 0.9497 - val_loss: 0.1912 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9487 - val_loss: 0.1914 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.9484 - val_loss: 0.1916 - val_accuracy: 0.9152 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1238 - accuracy: 0.9502 - val_loss: 0.1905 - val_accuracy: 0.9183 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.9512 - val_loss: 0.1908 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9516 - val_loss: 0.1915 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.9495 - val_loss: 0.1903 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1215 - accuracy: 0.9510 - val_loss: 0.1898 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9516 - val_loss: 0.1901 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.9533 - val_loss: 0.1900 - val_accuracy: 0.9175 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1171 - accuracy: 0.9545 - val_loss: 0.1903 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9543 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9523 - val_loss: 0.1899 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1176 - accuracy: 0.9534 - val_loss: 0.1901 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9560 - val_loss: 0.1902 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1200 - accuracy: 0.9515 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1206 - accuracy: 0.9502 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1178 - accuracy: 0.9532 - val_loss: 0.1901 - val_accuracy: 0.9171 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9537 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9542 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1227 - accuracy: 0.9513 - val_loss: 0.1901 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1194 - accuracy: 0.9532 - val_loss: 0.1902 - val_accuracy: 0.9171 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9507 - val_loss: 0.1901 - val_accuracy: 0.9179 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1193 - accuracy: 0.9535 - val_loss: 0.1902 - val_accuracy: 0.9175 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1170 - accuracy: 0.9552 - val_loss: 0.1902 - val_accuracy: 0.9175 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9547 - val_loss: 0.1902 - val_accuracy: 0.9175 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9532 - val_loss: 0.1901 - val_accuracy: 0.9175 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 0.1901 - val_accuracy: 0.9175 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.929933826391592 0.9404835709857409 0.9121338912133892 0.8504856852296732 0.926308731099565 0.9801741602616815\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5405 - accuracy: 0.8156 - val_loss: 0.3800 - val_accuracy: 0.8681 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 13/241 [>.............................] - ETA: 1s - loss: 0.2772 - accuracy: 0.8918"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.8824 - val_loss: 0.5033 - val_accuracy: 0.7623 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2349 - accuracy: 0.9004 - val_loss: 0.2333 - val_accuracy: 0.8981 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2184 - accuracy: 0.9070 - val_loss: 0.2451 - val_accuracy: 0.8981 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9112 - val_loss: 0.2152 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1841 - accuracy: 0.9251 - val_loss: 0.2052 - val_accuracy: 0.9156 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.9266 - val_loss: 0.1975 - val_accuracy: 0.9175 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.9292 - val_loss: 0.2167 - val_accuracy: 0.9089 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9353 - val_loss: 0.1980 - val_accuracy: 0.9195 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1519 - accuracy: 0.9355 - val_loss: 0.1889 - val_accuracy: 0.9261 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1487 - accuracy: 0.9385 - val_loss: 0.1937 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9423 - val_loss: 0.1903 - val_accuracy: 0.9249 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1349 - accuracy: 0.9445 - val_loss: 0.1906 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9472 - val_loss: 0.1911 - val_accuracy: 0.9276 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9489 - val_loss: 0.1883 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.9508 - val_loss: 0.1868 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9520 - val_loss: 0.1934 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1174 - accuracy: 0.9534 - val_loss: 0.1864 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.9530 - val_loss: 0.1856 - val_accuracy: 0.9288 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1154 - accuracy: 0.9555 - val_loss: 0.1883 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9580 - val_loss: 0.1867 - val_accuracy: 0.9288 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9583 - val_loss: 0.1867 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9581 - val_loss: 0.1857 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9599 - val_loss: 0.1857 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9580 - val_loss: 0.1842 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9563 - val_loss: 0.1860 - val_accuracy: 0.9284 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9608 - val_loss: 0.1855 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1043 - accuracy: 0.9600 - val_loss: 0.1856 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9599 - val_loss: 0.1844 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1041 - accuracy: 0.9612 - val_loss: 0.1846 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9625 - val_loss: 0.1846 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9603 - val_loss: 0.1847 - val_accuracy: 0.9272 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1034 - accuracy: 0.9576 - val_loss: 0.1849 - val_accuracy: 0.9296 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9615 - val_loss: 0.1848 - val_accuracy: 0.9292 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9598 - val_loss: 0.1849 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9594 - val_loss: 0.1848 - val_accuracy: 0.9284 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1016 - accuracy: 0.9609 - val_loss: 0.1849 - val_accuracy: 0.9292 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9609 - val_loss: 0.1849 - val_accuracy: 0.9284 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9589 - val_loss: 0.1850 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1060 - accuracy: 0.9589 - val_loss: 0.1848 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9622 - val_loss: 0.1848 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9604 - val_loss: 0.1848 - val_accuracy: 0.9284 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9604 - val_loss: 0.1848 - val_accuracy: 0.9280 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9598 - val_loss: 0.1849 - val_accuracy: 0.9284 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9600 - val_loss: 0.1850 - val_accuracy: 0.9280 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1042 - accuracy: 0.9595 - val_loss: 0.1850 - val_accuracy: 0.9284 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9606 - val_loss: 0.1850 - val_accuracy: 0.9284 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9563 - val_loss: 0.1849 - val_accuracy: 0.9284 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9628 - val_loss: 0.1850 - val_accuracy: 0.9280 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9611 - val_loss: 0.1849 - val_accuracy: 0.9284 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9622 - val_loss: 0.1851 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1041 - accuracy: 0.9590 - val_loss: 0.1849 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9604 - val_loss: 0.1850 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9221486959906579 0.941808981657179 0.8906882591093117 0.8351060298080905 0.9162486203832454 0.9769434350728666\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6569 - accuracy: 0.8221 - val_loss: 0.2993 - val_accuracy: 0.8914 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2175 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2594 - accuracy: 0.8872 - val_loss: 0.2450 - val_accuracy: 0.8992 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2222 - accuracy: 0.9042 - val_loss: 0.2241 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9119 - val_loss: 0.2143 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1946 - accuracy: 0.9193 - val_loss: 0.2127 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1767 - accuracy: 0.9269 - val_loss: 0.2077 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1687 - accuracy: 0.9277 - val_loss: 0.2137 - val_accuracy: 0.9089 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1592 - accuracy: 0.9319 - val_loss: 0.2010 - val_accuracy: 0.9210 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1497 - accuracy: 0.9382 - val_loss: 0.2155 - val_accuracy: 0.9151 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1425 - accuracy: 0.9414 - val_loss: 0.1964 - val_accuracy: 0.9221 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1399 - accuracy: 0.9412 - val_loss: 0.2021 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1298 - accuracy: 0.9471 - val_loss: 0.2014 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.9503 - val_loss: 0.1991 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1214 - accuracy: 0.9508 - val_loss: 0.2050 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9520 - val_loss: 0.1962 - val_accuracy: 0.9214 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1165 - accuracy: 0.9533 - val_loss: 0.1991 - val_accuracy: 0.9225 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9577 - val_loss: 0.1954 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9590 - val_loss: 0.1954 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9572 - val_loss: 0.1961 - val_accuracy: 0.9225 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9583 - val_loss: 0.1948 - val_accuracy: 0.9237 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1059 - accuracy: 0.9602 - val_loss: 0.1956 - val_accuracy: 0.9276 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9598 - val_loss: 0.1953 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9586 - val_loss: 0.1949 - val_accuracy: 0.9260 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9612 - val_loss: 0.1950 - val_accuracy: 0.9272 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9602 - val_loss: 0.1948 - val_accuracy: 0.9253 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9620 - val_loss: 0.1949 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9611 - val_loss: 0.1942 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9628 - val_loss: 0.1949 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9635 - val_loss: 0.1946 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9625 - val_loss: 0.1949 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0990 - accuracy: 0.9619 - val_loss: 0.1950 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9619 - val_loss: 0.1951 - val_accuracy: 0.9264 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9628 - val_loss: 0.1950 - val_accuracy: 0.9260 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.1950 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9616 - val_loss: 0.1949 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9617 - val_loss: 0.1950 - val_accuracy: 0.9249 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0990 - accuracy: 0.9620 - val_loss: 0.1949 - val_accuracy: 0.9253 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0966 - accuracy: 0.9634 - val_loss: 0.1950 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9622 - val_loss: 0.1950 - val_accuracy: 0.9257 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9629 - val_loss: 0.1950 - val_accuracy: 0.9253 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0966 - accuracy: 0.9629 - val_loss: 0.1949 - val_accuracy: 0.9257 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9245136186770428 0.9299323909035033 0.9151643690349947 0.839075208886799 0.922548379969249 0.97854146067716\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6634 - accuracy: 0.8287 - val_loss: 0.3144 - val_accuracy: 0.8669 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.3030 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2599 - accuracy: 0.8889 - val_loss: 0.2506 - val_accuracy: 0.8887 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2199 - accuracy: 0.9102 - val_loss: 0.2277 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2065 - accuracy: 0.9098 - val_loss: 0.2130 - val_accuracy: 0.9128 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1898 - accuracy: 0.9225 - val_loss: 0.2351 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9288 - val_loss: 0.2089 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1634 - accuracy: 0.9346 - val_loss: 0.2037 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9325 - val_loss: 0.1971 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9399 - val_loss: 0.1924 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1399 - accuracy: 0.9421 - val_loss: 0.1953 - val_accuracy: 0.9202 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1343 - accuracy: 0.9445 - val_loss: 0.1929 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1266 - accuracy: 0.9493 - val_loss: 0.1877 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1250 - accuracy: 0.9490 - val_loss: 0.1891 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1200 - accuracy: 0.9547 - val_loss: 0.1901 - val_accuracy: 0.9257 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1148 - accuracy: 0.9543 - val_loss: 0.1873 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9537 - val_loss: 0.1903 - val_accuracy: 0.9214 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9559 - val_loss: 0.1887 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9590 - val_loss: 0.1899 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9615 - val_loss: 0.1878 - val_accuracy: 0.9202 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9599 - val_loss: 0.1885 - val_accuracy: 0.9222 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9595 - val_loss: 0.1876 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9629 - val_loss: 0.1871 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1042 - accuracy: 0.9599 - val_loss: 0.1887 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9641 - val_loss: 0.1878 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9599 - val_loss: 0.1875 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9619 - val_loss: 0.1873 - val_accuracy: 0.9222 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0968 - accuracy: 0.9661 - val_loss: 0.1873 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9621 - val_loss: 0.1873 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9620 - val_loss: 0.1873 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9609 - val_loss: 0.1877 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 0.1874 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9632 - val_loss: 0.1876 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0949 - accuracy: 0.9634 - val_loss: 0.1875 - val_accuracy: 0.9233 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1877 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9229272090307513 0.9529190207156308 0.8739754098360656 0.8355156420086867 0.9134472152758482 0.9719263581447523\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6173 - accuracy: 0.8460 - val_loss: 0.3051 - val_accuracy: 0.8829 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2799 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2490 - accuracy: 0.8952 - val_loss: 0.2371 - val_accuracy: 0.9027 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2095 - accuracy: 0.9116 - val_loss: 0.2296 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1957 - accuracy: 0.9159 - val_loss: 0.2121 - val_accuracy: 0.9101 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1832 - accuracy: 0.9236 - val_loss: 0.2299 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9315 - val_loss: 0.1987 - val_accuracy: 0.9202 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9371 - val_loss: 0.2048 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1481 - accuracy: 0.9391 - val_loss: 0.2008 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9471 - val_loss: 0.2225 - val_accuracy: 0.9074 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1312 - accuracy: 0.9471 - val_loss: 0.2001 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9484 - val_loss: 0.1968 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9523 - val_loss: 0.1949 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9561 - val_loss: 0.1964 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9567 - val_loss: 0.1937 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9604 - val_loss: 0.1934 - val_accuracy: 0.9222 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9624 - val_loss: 0.1963 - val_accuracy: 0.9198 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9630 - val_loss: 0.1926 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0952 - accuracy: 0.9644 - val_loss: 0.1939 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0978 - accuracy: 0.9632 - val_loss: 0.1932 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0949 - accuracy: 0.9634 - val_loss: 0.1991 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9651 - val_loss: 0.1938 - val_accuracy: 0.9230 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0928 - accuracy: 0.9639 - val_loss: 0.1949 - val_accuracy: 0.9214 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9639 - val_loss: 0.1955 - val_accuracy: 0.9218 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9676 - val_loss: 0.1951 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9664 - val_loss: 0.1961 - val_accuracy: 0.9214 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9637 - val_loss: 0.1964 - val_accuracy: 0.9206 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9665 - val_loss: 0.1953 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9652 - val_loss: 0.1951 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9668 - val_loss: 0.1949 - val_accuracy: 0.9218 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9678 - val_loss: 0.1952 - val_accuracy: 0.9210 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9677 - val_loss: 0.1952 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9683 - val_loss: 0.1950 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9696 - val_loss: 0.1955 - val_accuracy: 0.9214 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9672 - val_loss: 0.1953 - val_accuracy: 0.9222 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9696 - val_loss: 0.1954 - val_accuracy: 0.9218 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0853 - accuracy: 0.9682 - val_loss: 0.1954 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9695 - val_loss: 0.1953 - val_accuracy: 0.9218 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.1953 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9709 - val_loss: 0.1954 - val_accuracy: 0.9218 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9147528221097704 0.9461300309597523 0.8616352201257862 0.8162245094590105 0.9038826255427692 0.9712775278929845\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 1.6777 - accuracy: 0.6153 - val_loss: 0.6487 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.7106 - accuracy: 0.5312"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6360 - accuracy: 0.6560 - val_loss: 0.5701 - val_accuracy: 0.7128 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5768 - accuracy: 0.7021 - val_loss: 0.4492 - val_accuracy: 0.7911 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.7792 - val_loss: 0.3713 - val_accuracy: 0.8284 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.3632 - accuracy: 0.8335 - val_loss: 0.3401 - val_accuracy: 0.8619 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8613 - val_loss: 0.2727 - val_accuracy: 0.8914 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2876 - accuracy: 0.8763 - val_loss: 0.2538 - val_accuracy: 0.8907 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2764 - accuracy: 0.8823 - val_loss: 0.3167 - val_accuracy: 0.8533 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2615 - accuracy: 0.8885 - val_loss: 0.2391 - val_accuracy: 0.8949 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2563 - accuracy: 0.8907 - val_loss: 0.2394 - val_accuracy: 0.8977 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.8970 - val_loss: 0.2378 - val_accuracy: 0.8957 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2371 - accuracy: 0.8997 - val_loss: 0.2313 - val_accuracy: 0.8981 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2339 - accuracy: 0.9026 - val_loss: 0.2276 - val_accuracy: 0.9039 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2281 - accuracy: 0.9062 - val_loss: 0.2262 - val_accuracy: 0.9004 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2218 - accuracy: 0.9037 - val_loss: 0.2224 - val_accuracy: 0.9027 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2163 - accuracy: 0.9109 - val_loss: 0.2232 - val_accuracy: 0.9035 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2185 - accuracy: 0.9089 - val_loss: 0.2204 - val_accuracy: 0.9027 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2133 - accuracy: 0.9080 - val_loss: 0.2202 - val_accuracy: 0.9023 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2089 - accuracy: 0.9103 - val_loss: 0.2199 - val_accuracy: 0.9023 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9128 - val_loss: 0.2186 - val_accuracy: 0.9051 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9116 - val_loss: 0.2166 - val_accuracy: 0.9051 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9110 - val_loss: 0.2162 - val_accuracy: 0.9047 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9180 - val_loss: 0.2168 - val_accuracy: 0.9051 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9123 - val_loss: 0.2163 - val_accuracy: 0.9070 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.9162 - val_loss: 0.2163 - val_accuracy: 0.9051 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2025 - accuracy: 0.9163 - val_loss: 0.2167 - val_accuracy: 0.9066 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1956 - accuracy: 0.9207 - val_loss: 0.2164 - val_accuracy: 0.9078 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9189 - val_loss: 0.2157 - val_accuracy: 0.9078 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1967 - accuracy: 0.9184 - val_loss: 0.2154 - val_accuracy: 0.9066 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.9148 - val_loss: 0.2151 - val_accuracy: 0.9066 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9168 - val_loss: 0.2163 - val_accuracy: 0.9054 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1965 - accuracy: 0.9162 - val_loss: 0.2148 - val_accuracy: 0.9066 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1943 - accuracy: 0.9192 - val_loss: 0.2155 - val_accuracy: 0.9074 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1972 - accuracy: 0.9159 - val_loss: 0.2156 - val_accuracy: 0.9082 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1967 - accuracy: 0.9158 - val_loss: 0.2155 - val_accuracy: 0.9078 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9157 - val_loss: 0.2153 - val_accuracy: 0.9066 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9192 - val_loss: 0.2154 - val_accuracy: 0.9082 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9179 - val_loss: 0.2152 - val_accuracy: 0.9066 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1929 - accuracy: 0.9198 - val_loss: 0.2153 - val_accuracy: 0.9070 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1984 - accuracy: 0.9162 - val_loss: 0.2152 - val_accuracy: 0.9066 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1974 - accuracy: 0.9202 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1942 - accuracy: 0.9170 - val_loss: 0.2151 - val_accuracy: 0.9070 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.9173 - val_loss: 0.2151 - val_accuracy: 0.9066 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1970 - accuracy: 0.9181 - val_loss: 0.2152 - val_accuracy: 0.9066 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1956 - accuracy: 0.9183 - val_loss: 0.2151 - val_accuracy: 0.9066 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1976 - accuracy: 0.9198 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1968 - accuracy: 0.9205 - val_loss: 0.2152 - val_accuracy: 0.9074 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1970 - accuracy: 0.9180 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1961 - accuracy: 0.9161 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1954 - accuracy: 0.9189 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9203 - val_loss: 0.2151 - val_accuracy: 0.9070 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1952 - accuracy: 0.9173 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1948 - accuracy: 0.9164 - val_loss: 0.2151 - val_accuracy: 0.9070 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1976 - accuracy: 0.9171 - val_loss: 0.2152 - val_accuracy: 0.9070 - lr: 1.0156e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9159205916699105 0.9287042777433354 0.8943514644351465 0.8206638059932803 0.9115278710892409 0.9740244664818019\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7354 - accuracy: 0.8368 - val_loss: 0.2642 - val_accuracy: 0.8953 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.3118 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2633 - accuracy: 0.8869 - val_loss: 0.2342 - val_accuracy: 0.9062 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.2210 - accuracy: 0.9067 - val_loss: 0.2222 - val_accuracy: 0.9136 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9144 - val_loss: 0.2172 - val_accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1986 - accuracy: 0.9157 - val_loss: 0.2210 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1813 - accuracy: 0.9247 - val_loss: 0.2116 - val_accuracy: 0.9152 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9298 - val_loss: 0.2106 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1653 - accuracy: 0.9307 - val_loss: 0.2055 - val_accuracy: 0.9198 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9384 - val_loss: 0.2025 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1475 - accuracy: 0.9410 - val_loss: 0.1999 - val_accuracy: 0.9230 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1417 - accuracy: 0.9434 - val_loss: 0.2008 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9452 - val_loss: 0.2004 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1318 - accuracy: 0.9473 - val_loss: 0.1967 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1270 - accuracy: 0.9478 - val_loss: 0.2168 - val_accuracy: 0.9152 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1219 - accuracy: 0.9523 - val_loss: 0.2005 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9542 - val_loss: 0.1965 - val_accuracy: 0.9257 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.9542 - val_loss: 0.1977 - val_accuracy: 0.9276 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.9568 - val_loss: 0.1985 - val_accuracy: 0.9261 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1138 - accuracy: 0.9556 - val_loss: 0.1983 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9555 - val_loss: 0.1993 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9582 - val_loss: 0.1976 - val_accuracy: 0.9265 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9576 - val_loss: 0.1975 - val_accuracy: 0.9268 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1088 - accuracy: 0.9596 - val_loss: 0.1970 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9590 - val_loss: 0.1967 - val_accuracy: 0.9272 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9620 - val_loss: 0.1966 - val_accuracy: 0.9265 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9569 - val_loss: 0.1978 - val_accuracy: 0.9276 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9612 - val_loss: 0.1979 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9606 - val_loss: 0.1974 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9586 - val_loss: 0.1976 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9608 - val_loss: 0.1976 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9580 - val_loss: 0.1972 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9638 - val_loss: 0.1969 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9615 - val_loss: 0.1970 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9616 - val_loss: 0.1970 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9606 - val_loss: 0.1969 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9598 - val_loss: 0.1970 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9593 - val_loss: 0.1968 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9613 - val_loss: 0.1969 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9596 - val_loss: 0.1969 - val_accuracy: 0.9272 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9607 - val_loss: 0.1970 - val_accuracy: 0.9272 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9596 - val_loss: 0.1970 - val_accuracy: 0.9272 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9622 - val_loss: 0.1970 - val_accuracy: 0.9272 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9615 - val_loss: 0.1969 - val_accuracy: 0.9272 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9604 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9628 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1043 - accuracy: 0.9607 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9607 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9569 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1038 - accuracy: 0.9586 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9616 - val_loss: 0.1972 - val_accuracy: 0.9272 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9625 - val_loss: 0.1971 - val_accuracy: 0.9272 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9198131568703776 0.9342188488298545 0.8967611336032388 0.8306657559113118 0.9154899912165466 0.9759773832479315\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4269 - accuracy: 0.8417 - val_loss: 0.3577 - val_accuracy: 0.8388 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 13/241 [>.............................] - ETA: 1s - loss: 0.2783 - accuracy: 0.8918"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2578 - accuracy: 0.8910 - val_loss: 0.2378 - val_accuracy: 0.9019 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9067 - val_loss: 0.2310 - val_accuracy: 0.9031 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9088 - val_loss: 0.2240 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1925 - accuracy: 0.9158 - val_loss: 0.2079 - val_accuracy: 0.9112 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1673 - accuracy: 0.9282 - val_loss: 0.2077 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1619 - accuracy: 0.9338 - val_loss: 0.2024 - val_accuracy: 0.9179 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9381 - val_loss: 0.2013 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1421 - accuracy: 0.9424 - val_loss: 0.2080 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1387 - accuracy: 0.9456 - val_loss: 0.1973 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1331 - accuracy: 0.9447 - val_loss: 0.2008 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1255 - accuracy: 0.9511 - val_loss: 0.1970 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9542 - val_loss: 0.1980 - val_accuracy: 0.9225 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9554 - val_loss: 0.1991 - val_accuracy: 0.9257 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1122 - accuracy: 0.9559 - val_loss: 0.1972 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9585 - val_loss: 0.1956 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1076 - accuracy: 0.9580 - val_loss: 0.1944 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9591 - val_loss: 0.1936 - val_accuracy: 0.9268 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9595 - val_loss: 0.1937 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9648 - val_loss: 0.1953 - val_accuracy: 0.9241 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9611 - val_loss: 0.1948 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9612 - val_loss: 0.1938 - val_accuracy: 0.9288 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9625 - val_loss: 0.1941 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0967 - accuracy: 0.9656 - val_loss: 0.1949 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.1938 - val_accuracy: 0.9276 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0928 - accuracy: 0.9635 - val_loss: 0.1942 - val_accuracy: 0.9272 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9660 - val_loss: 0.1942 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0946 - accuracy: 0.9664 - val_loss: 0.1937 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0937 - accuracy: 0.9641 - val_loss: 0.1945 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9644 - val_loss: 0.1943 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9661 - val_loss: 0.1941 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0916 - accuracy: 0.9683 - val_loss: 0.1944 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0927 - accuracy: 0.9651 - val_loss: 0.1944 - val_accuracy: 0.9268 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9654 - val_loss: 0.1945 - val_accuracy: 0.9264 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9665 - val_loss: 0.1944 - val_accuracy: 0.9264 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9656 - val_loss: 0.1945 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9646 - val_loss: 0.1944 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9667 - val_loss: 0.1944 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9661 - val_loss: 0.1944 - val_accuracy: 0.9272 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9673 - val_loss: 0.1943 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9678 - val_loss: 0.1944 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0909 - accuracy: 0.9667 - val_loss: 0.1944 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9237354085603113 0.9287031346035648 0.9151643690349947 0.8375243647829459 0.9219337518192797 0.9771362238888949\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7526 - accuracy: 0.8067 - val_loss: 0.3484 - val_accuracy: 0.8681 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.3114 - accuracy: 0.8565"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2840 - accuracy: 0.8727 - val_loss: 0.2950 - val_accuracy: 0.8638 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2461 - accuracy: 0.8998 - val_loss: 0.2270 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9032 - val_loss: 0.2200 - val_accuracy: 0.9070 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2157 - accuracy: 0.9107 - val_loss: 0.2426 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.9171 - val_loss: 0.2114 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1908 - accuracy: 0.9209 - val_loss: 0.2105 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1858 - accuracy: 0.9228 - val_loss: 0.2074 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1720 - accuracy: 0.9294 - val_loss: 0.2003 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1647 - accuracy: 0.9323 - val_loss: 0.2038 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1649 - accuracy: 0.9364 - val_loss: 0.1973 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.9375 - val_loss: 0.1976 - val_accuracy: 0.9179 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1487 - accuracy: 0.9411 - val_loss: 0.1971 - val_accuracy: 0.9206 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1489 - accuracy: 0.9389 - val_loss: 0.1930 - val_accuracy: 0.9202 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1426 - accuracy: 0.9437 - val_loss: 0.1943 - val_accuracy: 0.9187 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1369 - accuracy: 0.9439 - val_loss: 0.1942 - val_accuracy: 0.9183 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1370 - accuracy: 0.9476 - val_loss: 0.1936 - val_accuracy: 0.9210 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1327 - accuracy: 0.9503 - val_loss: 0.1933 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9473 - val_loss: 0.1917 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1319 - accuracy: 0.9460 - val_loss: 0.1940 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1334 - accuracy: 0.9471 - val_loss: 0.1937 - val_accuracy: 0.9198 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1268 - accuracy: 0.9491 - val_loss: 0.1936 - val_accuracy: 0.9198 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9491 - val_loss: 0.1917 - val_accuracy: 0.9191 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9493 - val_loss: 0.1920 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9500 - val_loss: 0.1923 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1268 - accuracy: 0.9480 - val_loss: 0.1932 - val_accuracy: 0.9206 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1263 - accuracy: 0.9487 - val_loss: 0.1925 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9535 - val_loss: 0.1913 - val_accuracy: 0.9218 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9490 - val_loss: 0.1916 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9524 - val_loss: 0.1924 - val_accuracy: 0.9210 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9526 - val_loss: 0.1922 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.9490 - val_loss: 0.1918 - val_accuracy: 0.9202 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9500 - val_loss: 0.1918 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9525 - val_loss: 0.1916 - val_accuracy: 0.9198 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9521 - val_loss: 0.1918 - val_accuracy: 0.9202 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1255 - accuracy: 0.9511 - val_loss: 0.1917 - val_accuracy: 0.9202 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9521 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1236 - accuracy: 0.9508 - val_loss: 0.1917 - val_accuracy: 0.9198 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9523 - val_loss: 0.1918 - val_accuracy: 0.9198 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1272 - accuracy: 0.9498 - val_loss: 0.1916 - val_accuracy: 0.9198 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9526 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9520 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.9508 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9489 - val_loss: 0.1916 - val_accuracy: 0.9198 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9510 - val_loss: 0.1915 - val_accuracy: 0.9195 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9521 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1236 - accuracy: 0.9525 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9502 - val_loss: 0.1916 - val_accuracy: 0.9195 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9237057220708447 0.9422473320778405 0.8934426229508197 0.8377259012637535 0.91784497751433 0.9725402761055025\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 1.8016 - accuracy: 0.6691 - val_loss: 0.4196 - val_accuracy: 0.7981 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.4150 - accuracy: 0.8259"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8407 - val_loss: 0.3111 - val_accuracy: 0.8856 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2864 - accuracy: 0.8756 - val_loss: 0.2493 - val_accuracy: 0.8977 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2666 - accuracy: 0.8827 - val_loss: 0.2400 - val_accuracy: 0.8969 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2463 - accuracy: 0.8967 - val_loss: 0.2497 - val_accuracy: 0.8887 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2335 - accuracy: 0.9009 - val_loss: 0.2208 - val_accuracy: 0.9086 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2208 - accuracy: 0.9066 - val_loss: 0.2245 - val_accuracy: 0.9023 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2149 - accuracy: 0.9092 - val_loss: 0.2263 - val_accuracy: 0.9019 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9132 - val_loss: 0.2178 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2011 - accuracy: 0.9131 - val_loss: 0.2136 - val_accuracy: 0.9051 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1967 - accuracy: 0.9173 - val_loss: 0.2152 - val_accuracy: 0.9062 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1856 - accuracy: 0.9214 - val_loss: 0.2100 - val_accuracy: 0.9113 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1837 - accuracy: 0.9216 - val_loss: 0.2105 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1820 - accuracy: 0.9242 - val_loss: 0.2125 - val_accuracy: 0.9086 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.9253 - val_loss: 0.2087 - val_accuracy: 0.9140 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9258 - val_loss: 0.2085 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1698 - accuracy: 0.9292 - val_loss: 0.2062 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1651 - accuracy: 0.9337 - val_loss: 0.2034 - val_accuracy: 0.9109 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9319 - val_loss: 0.2049 - val_accuracy: 0.9121 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9333 - val_loss: 0.2055 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9334 - val_loss: 0.2053 - val_accuracy: 0.9109 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1640 - accuracy: 0.9337 - val_loss: 0.2035 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1612 - accuracy: 0.9366 - val_loss: 0.2036 - val_accuracy: 0.9144 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1588 - accuracy: 0.9346 - val_loss: 0.2024 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1582 - accuracy: 0.9349 - val_loss: 0.2031 - val_accuracy: 0.9152 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1548 - accuracy: 0.9353 - val_loss: 0.2046 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1605 - accuracy: 0.9325 - val_loss: 0.2022 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1535 - accuracy: 0.9385 - val_loss: 0.2026 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9355 - val_loss: 0.2019 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9356 - val_loss: 0.2025 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1549 - accuracy: 0.9369 - val_loss: 0.2024 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1549 - accuracy: 0.9362 - val_loss: 0.2026 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9375 - val_loss: 0.2020 - val_accuracy: 0.9121 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1524 - accuracy: 0.9355 - val_loss: 0.2023 - val_accuracy: 0.9136 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1560 - accuracy: 0.9367 - val_loss: 0.2022 - val_accuracy: 0.9148 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1543 - accuracy: 0.9342 - val_loss: 0.2019 - val_accuracy: 0.9136 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9343 - val_loss: 0.2021 - val_accuracy: 0.9136 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9398 - val_loss: 0.2021 - val_accuracy: 0.9144 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1549 - accuracy: 0.9380 - val_loss: 0.2019 - val_accuracy: 0.9136 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1572 - accuracy: 0.9376 - val_loss: 0.2018 - val_accuracy: 0.9140 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9382 - val_loss: 0.2019 - val_accuracy: 0.9140 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1551 - accuracy: 0.9359 - val_loss: 0.2019 - val_accuracy: 0.9136 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1538 - accuracy: 0.9376 - val_loss: 0.2019 - val_accuracy: 0.9140 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1545 - accuracy: 0.9349 - val_loss: 0.2020 - val_accuracy: 0.9140 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1542 - accuracy: 0.9376 - val_loss: 0.2020 - val_accuracy: 0.9140 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1553 - accuracy: 0.9358 - val_loss: 0.2018 - val_accuracy: 0.9140 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9104710003892565 0.9294117647058824 0.8784067085953878 0.8081663191680033 0.9039092366506352 0.9672988427413335\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5230 - accuracy: 0.8407 - val_loss: 0.3264 - val_accuracy: 0.8926 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.2830 - accuracy: 0.8850"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2596 - accuracy: 0.8895 - val_loss: 0.2509 - val_accuracy: 0.8953 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2268 - accuracy: 0.9028 - val_loss: 0.2323 - val_accuracy: 0.8973 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2102 - accuracy: 0.9116 - val_loss: 0.2162 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1988 - accuracy: 0.9145 - val_loss: 0.2179 - val_accuracy: 0.9086 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9254 - val_loss: 0.2114 - val_accuracy: 0.9066 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1698 - accuracy: 0.9276 - val_loss: 0.2071 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1628 - accuracy: 0.9338 - val_loss: 0.2091 - val_accuracy: 0.9093 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1538 - accuracy: 0.9388 - val_loss: 0.2047 - val_accuracy: 0.9113 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.9408 - val_loss: 0.2162 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1412 - accuracy: 0.9414 - val_loss: 0.2065 - val_accuracy: 0.9160 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9494 - val_loss: 0.2028 - val_accuracy: 0.9160 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9477 - val_loss: 0.2047 - val_accuracy: 0.9163 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1290 - accuracy: 0.9495 - val_loss: 0.2085 - val_accuracy: 0.9171 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9554 - val_loss: 0.2062 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9574 - val_loss: 0.2119 - val_accuracy: 0.9191 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9559 - val_loss: 0.2094 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9550 - val_loss: 0.2048 - val_accuracy: 0.9144 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.9583 - val_loss: 0.2071 - val_accuracy: 0.9191 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9571 - val_loss: 0.2069 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9602 - val_loss: 0.2070 - val_accuracy: 0.9214 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9604 - val_loss: 0.2043 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9591 - val_loss: 0.2047 - val_accuracy: 0.9175 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9600 - val_loss: 0.2043 - val_accuracy: 0.9195 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9590 - val_loss: 0.2067 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9600 - val_loss: 0.2068 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9611 - val_loss: 0.2058 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9599 - val_loss: 0.2059 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9596 - val_loss: 0.2061 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9651 - val_loss: 0.2057 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9581 - val_loss: 0.2062 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9630 - val_loss: 0.2060 - val_accuracy: 0.9191 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0997 - accuracy: 0.9619 - val_loss: 0.2062 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0997 - accuracy: 0.9638 - val_loss: 0.2056 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9611 - val_loss: 0.2061 - val_accuracy: 0.9187 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9626 - val_loss: 0.2059 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9633 - val_loss: 0.2059 - val_accuracy: 0.9191 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9630 - val_loss: 0.2061 - val_accuracy: 0.9195 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9622 - val_loss: 0.2059 - val_accuracy: 0.9195 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0998 - accuracy: 0.9630 - val_loss: 0.2058 - val_accuracy: 0.9191 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9606 - val_loss: 0.2060 - val_accuracy: 0.9191 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9326586220319191 0.9386236825790453 0.9225941422594143 0.8568393183577907 0.9306089124192298 0.9790587460149881\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7450 - accuracy: 0.8107 - val_loss: 0.3352 - val_accuracy: 0.8553 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 13/241 [>.............................] - ETA: 0s - loss: 0.2946 - accuracy: 0.8702"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2692 - accuracy: 0.8885 - val_loss: 0.2485 - val_accuracy: 0.8872 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9081 - val_loss: 0.2232 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9116 - val_loss: 0.2189 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1967 - accuracy: 0.9163 - val_loss: 0.2167 - val_accuracy: 0.9144 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9298 - val_loss: 0.2131 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.9332 - val_loss: 0.2011 - val_accuracy: 0.9179 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1559 - accuracy: 0.9358 - val_loss: 0.2027 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9389 - val_loss: 0.2029 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1401 - accuracy: 0.9433 - val_loss: 0.1965 - val_accuracy: 0.9233 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9430 - val_loss: 0.2037 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1316 - accuracy: 0.9438 - val_loss: 0.1980 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1246 - accuracy: 0.9500 - val_loss: 0.1966 - val_accuracy: 0.9222 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1225 - accuracy: 0.9534 - val_loss: 0.1988 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1194 - accuracy: 0.9545 - val_loss: 0.1953 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1183 - accuracy: 0.9533 - val_loss: 0.1965 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9559 - val_loss: 0.1951 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9574 - val_loss: 0.1946 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9589 - val_loss: 0.1945 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9583 - val_loss: 0.1950 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9600 - val_loss: 0.1962 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9598 - val_loss: 0.1969 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1057 - accuracy: 0.9594 - val_loss: 0.1947 - val_accuracy: 0.9272 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9629 - val_loss: 0.1951 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9617 - val_loss: 0.1949 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9607 - val_loss: 0.1954 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1019 - accuracy: 0.9617 - val_loss: 0.1951 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9589 - val_loss: 0.1957 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9641 - val_loss: 0.1954 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9612 - val_loss: 0.1952 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9637 - val_loss: 0.1957 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0997 - accuracy: 0.9620 - val_loss: 0.1959 - val_accuracy: 0.9261 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1007 - accuracy: 0.9611 - val_loss: 0.1955 - val_accuracy: 0.9276 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9625 - val_loss: 0.1953 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9625 - val_loss: 0.1957 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9628 - val_loss: 0.1956 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1000 - accuracy: 0.9630 - val_loss: 0.1956 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1003 - accuracy: 0.9642 - val_loss: 0.1958 - val_accuracy: 0.9276 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9613 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9612 - val_loss: 0.1957 - val_accuracy: 0.9280 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9634 - val_loss: 0.1957 - val_accuracy: 0.9276 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9639 - val_loss: 0.1956 - val_accuracy: 0.9276 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9617 - val_loss: 0.1957 - val_accuracy: 0.9280 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9607 - val_loss: 0.1958 - val_accuracy: 0.9276 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9632 - val_loss: 0.1958 - val_accuracy: 0.9276 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9633 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9633 - val_loss: 0.1959 - val_accuracy: 0.9276 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9624 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1006 - accuracy: 0.9641 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9639 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9620 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9625 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0967 - accuracy: 0.9628 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1000 - accuracy: 0.9619 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9620 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9630 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9609 - val_loss: 0.1958 - val_accuracy: 0.9280 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9625 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0991 - accuracy: 0.9642 - val_loss: 0.1959 - val_accuracy: 0.9280 - lr: 6.0936e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9217594394706111 0.9323213156230234 0.9048582995951417 0.8351663435822256 0.9185898076090826 0.9768787755405153\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5244 - accuracy: 0.8351 - val_loss: 0.3426 - val_accuracy: 0.8863 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 13/241 [>.............................] - ETA: 0s - loss: 0.2517 - accuracy: 0.8870"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2617 - accuracy: 0.8874 - val_loss: 0.2457 - val_accuracy: 0.9039 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9005 - val_loss: 0.2245 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9133 - val_loss: 0.2169 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9153 - val_loss: 0.2118 - val_accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9244 - val_loss: 0.2336 - val_accuracy: 0.9035 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1662 - accuracy: 0.9307 - val_loss: 0.2057 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1605 - accuracy: 0.9330 - val_loss: 0.2151 - val_accuracy: 0.9039 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9401 - val_loss: 0.2030 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1414 - accuracy: 0.9421 - val_loss: 0.1982 - val_accuracy: 0.9221 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1385 - accuracy: 0.9434 - val_loss: 0.2001 - val_accuracy: 0.9260 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.9473 - val_loss: 0.2015 - val_accuracy: 0.9253 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1252 - accuracy: 0.9487 - val_loss: 0.2015 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9508 - val_loss: 0.2009 - val_accuracy: 0.9241 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9530 - val_loss: 0.2001 - val_accuracy: 0.9280 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9563 - val_loss: 0.1988 - val_accuracy: 0.9284 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.9538 - val_loss: 0.2018 - val_accuracy: 0.9299 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9573 - val_loss: 0.1988 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9582 - val_loss: 0.1983 - val_accuracy: 0.9276 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9590 - val_loss: 0.1973 - val_accuracy: 0.9307 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9587 - val_loss: 0.1977 - val_accuracy: 0.9295 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9609 - val_loss: 0.1985 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.1984 - val_accuracy: 0.9268 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9606 - val_loss: 0.1990 - val_accuracy: 0.9260 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9600 - val_loss: 0.1994 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9595 - val_loss: 0.1976 - val_accuracy: 0.9280 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0990 - accuracy: 0.9625 - val_loss: 0.1978 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9629 - val_loss: 0.1979 - val_accuracy: 0.9284 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9619 - val_loss: 0.1981 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9630 - val_loss: 0.1983 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0990 - accuracy: 0.9616 - val_loss: 0.1982 - val_accuracy: 0.9284 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9609 - val_loss: 0.1984 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9612 - val_loss: 0.1982 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0968 - accuracy: 0.9648 - val_loss: 0.1981 - val_accuracy: 0.9284 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9632 - val_loss: 0.1981 - val_accuracy: 0.9288 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9604 - val_loss: 0.1982 - val_accuracy: 0.9292 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9628 - val_loss: 0.1982 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9632 - val_loss: 0.1983 - val_accuracy: 0.9280 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9634 - val_loss: 0.1984 - val_accuracy: 0.9280 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9625 - val_loss: 0.1982 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9249027237354086 0.931161647203442 0.9141039236479321 0.8397439442645493 0.922632785425687 0.977877949058211\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7000 - accuracy: 0.8313 - val_loss: 0.3176 - val_accuracy: 0.8661 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 15/241 [>.............................] - ETA: 0s - loss: 0.2599 - accuracy: 0.8938"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2527 - accuracy: 0.8945 - val_loss: 0.2338 - val_accuracy: 0.9000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9092 - val_loss: 0.2174 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9110 - val_loss: 0.2254 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9218 - val_loss: 0.2076 - val_accuracy: 0.9121 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1745 - accuracy: 0.9275 - val_loss: 0.2031 - val_accuracy: 0.9156 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9306 - val_loss: 0.2035 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9358 - val_loss: 0.1953 - val_accuracy: 0.9156 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9425 - val_loss: 0.1967 - val_accuracy: 0.9226 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9424 - val_loss: 0.1949 - val_accuracy: 0.9230 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1362 - accuracy: 0.9458 - val_loss: 0.1937 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1307 - accuracy: 0.9450 - val_loss: 0.1946 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1244 - accuracy: 0.9502 - val_loss: 0.1935 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1213 - accuracy: 0.9526 - val_loss: 0.1940 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9530 - val_loss: 0.1908 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.9548 - val_loss: 0.1933 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9550 - val_loss: 0.1919 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9578 - val_loss: 0.1927 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1088 - accuracy: 0.9591 - val_loss: 0.1938 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9585 - val_loss: 0.1932 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9643 - val_loss: 0.1946 - val_accuracy: 0.9226 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1076 - accuracy: 0.9586 - val_loss: 0.1930 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9619 - val_loss: 0.1927 - val_accuracy: 0.9249 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9612 - val_loss: 0.1929 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9634 - val_loss: 0.1930 - val_accuracy: 0.9233 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9615 - val_loss: 0.1937 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1007 - accuracy: 0.9629 - val_loss: 0.1933 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9625 - val_loss: 0.1930 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9609 - val_loss: 0.1936 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9621 - val_loss: 0.1938 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9625 - val_loss: 0.1940 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9608 - val_loss: 0.1936 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9638 - val_loss: 0.1939 - val_accuracy: 0.9230 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9633 - val_loss: 0.1940 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9643 - val_loss: 0.1936 - val_accuracy: 0.9237 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9619 - val_loss: 0.1939 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9638 - val_loss: 0.1937 - val_accuracy: 0.9233 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9633 - val_loss: 0.1940 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9621 - val_loss: 0.1939 - val_accuracy: 0.9241 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9616 - val_loss: 0.1938 - val_accuracy: 0.9245 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9244842351109381 0.9397363465160076 0.8995901639344263 0.8396608713226971 0.9196632552252169 0.9715381973387671\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5390 - accuracy: 0.8449 - val_loss: 0.3285 - val_accuracy: 0.8977 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 14/241 [>.............................] - ETA: 0s - loss: 0.2396 - accuracy: 0.8906"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2511 - accuracy: 0.8911 - val_loss: 0.2288 - val_accuracy: 0.9101 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9087 - val_loss: 0.2211 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1986 - accuracy: 0.9159 - val_loss: 0.2275 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1885 - accuracy: 0.9194 - val_loss: 0.2114 - val_accuracy: 0.9136 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1673 - accuracy: 0.9285 - val_loss: 0.2100 - val_accuracy: 0.9136 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1580 - accuracy: 0.9360 - val_loss: 0.2130 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1542 - accuracy: 0.9349 - val_loss: 0.2042 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1405 - accuracy: 0.9398 - val_loss: 0.2027 - val_accuracy: 0.9160 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1332 - accuracy: 0.9443 - val_loss: 0.1976 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9485 - val_loss: 0.2061 - val_accuracy: 0.9222 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1204 - accuracy: 0.9510 - val_loss: 0.1949 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9556 - val_loss: 0.1998 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9554 - val_loss: 0.2054 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1078 - accuracy: 0.9586 - val_loss: 0.1949 - val_accuracy: 0.9257 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1081 - accuracy: 0.9573 - val_loss: 0.1942 - val_accuracy: 0.9230 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9598 - val_loss: 0.1999 - val_accuracy: 0.9237 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9598 - val_loss: 0.1984 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9617 - val_loss: 0.1988 - val_accuracy: 0.9257 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9607 - val_loss: 0.1961 - val_accuracy: 0.9218 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9638 - val_loss: 0.1956 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9629 - val_loss: 0.1971 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0927 - accuracy: 0.9650 - val_loss: 0.1970 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9659 - val_loss: 0.1977 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9637 - val_loss: 0.1968 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9633 - val_loss: 0.1963 - val_accuracy: 0.9226 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0903 - accuracy: 0.9682 - val_loss: 0.1965 - val_accuracy: 0.9261 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9661 - val_loss: 0.1963 - val_accuracy: 0.9253 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9646 - val_loss: 0.1970 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9668 - val_loss: 0.1973 - val_accuracy: 0.9249 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9677 - val_loss: 0.1969 - val_accuracy: 0.9257 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9669 - val_loss: 0.1966 - val_accuracy: 0.9249 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9677 - val_loss: 0.1967 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9691 - val_loss: 0.1966 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9655 - val_loss: 0.1967 - val_accuracy: 0.9245 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9672 - val_loss: 0.1968 - val_accuracy: 0.9253 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9676 - val_loss: 0.1968 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9672 - val_loss: 0.1970 - val_accuracy: 0.9257 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 0.1970 - val_accuracy: 0.9257 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.9690 - val_loss: 0.1969 - val_accuracy: 0.9257 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9667 - val_loss: 0.1968 - val_accuracy: 0.9261 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9670 - val_loss: 0.1969 - val_accuracy: 0.9261 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9664 - val_loss: 0.1968 - val_accuracy: 0.9257 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9651 - val_loss: 0.1968 - val_accuracy: 0.9253 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9659 - val_loss: 0.1968 - val_accuracy: 0.9253 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9128065395095368 0.9380804953560371 0.870020964360587 0.8124476575900789 0.904050729858312 0.9712525394136469\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5332 - accuracy: 0.8427 - val_loss: 0.2951 - val_accuracy: 0.8887 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.2670 - accuracy: 0.8962"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2497 - accuracy: 0.8922 - val_loss: 0.2648 - val_accuracy: 0.8837 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9096 - val_loss: 0.2186 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9149 - val_loss: 0.2286 - val_accuracy: 0.9023 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1915 - accuracy: 0.9209 - val_loss: 0.2183 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1696 - accuracy: 0.9299 - val_loss: 0.2119 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1615 - accuracy: 0.9324 - val_loss: 0.2071 - val_accuracy: 0.9074 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1561 - accuracy: 0.9367 - val_loss: 0.2132 - val_accuracy: 0.9086 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9455 - val_loss: 0.2129 - val_accuracy: 0.9070 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1362 - accuracy: 0.9463 - val_loss: 0.2083 - val_accuracy: 0.9093 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9498 - val_loss: 0.2090 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1186 - accuracy: 0.9546 - val_loss: 0.2128 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1174 - accuracy: 0.9515 - val_loss: 0.2073 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9537 - val_loss: 0.2214 - val_accuracy: 0.9078 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9590 - val_loss: 0.2130 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9596 - val_loss: 0.2120 - val_accuracy: 0.9132 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1028 - accuracy: 0.9603 - val_loss: 0.2103 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9630 - val_loss: 0.2114 - val_accuracy: 0.9148 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0982 - accuracy: 0.9621 - val_loss: 0.2099 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9650 - val_loss: 0.2104 - val_accuracy: 0.9160 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9617 - val_loss: 0.2097 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9650 - val_loss: 0.2109 - val_accuracy: 0.9144 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9668 - val_loss: 0.2116 - val_accuracy: 0.9156 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9665 - val_loss: 0.2100 - val_accuracy: 0.9144 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0933 - accuracy: 0.9650 - val_loss: 0.2103 - val_accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9660 - val_loss: 0.2105 - val_accuracy: 0.9167 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9664 - val_loss: 0.2114 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9690 - val_loss: 0.2113 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9664 - val_loss: 0.2113 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9680 - val_loss: 0.2113 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9670 - val_loss: 0.2110 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9680 - val_loss: 0.2112 - val_accuracy: 0.9144 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9668 - val_loss: 0.2109 - val_accuracy: 0.9144 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9691 - val_loss: 0.2110 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9677 - val_loss: 0.2114 - val_accuracy: 0.9144 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9677 - val_loss: 0.2116 - val_accuracy: 0.9144 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9659 - val_loss: 0.2113 - val_accuracy: 0.9148 - lr: 2.1768e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9314908524717789 0.9485430874147551 0.9027196652719666 0.8531098037720817 0.9256313763433608 0.9798181355980566\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6703 - accuracy: 0.8411 - val_loss: 0.2904 - val_accuracy: 0.8872 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2711 - accuracy: 0.8831"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2540 - accuracy: 0.8957 - val_loss: 0.2423 - val_accuracy: 0.8934 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9071 - val_loss: 0.2227 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9115 - val_loss: 0.2424 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1916 - accuracy: 0.9181 - val_loss: 0.2222 - val_accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1782 - accuracy: 0.9233 - val_loss: 0.2051 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1657 - accuracy: 0.9301 - val_loss: 0.2020 - val_accuracy: 0.9195 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1641 - accuracy: 0.9329 - val_loss: 0.2063 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.9366 - val_loss: 0.2019 - val_accuracy: 0.9187 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9399 - val_loss: 0.2063 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1367 - accuracy: 0.9433 - val_loss: 0.2112 - val_accuracy: 0.9183 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1280 - accuracy: 0.9487 - val_loss: 0.2014 - val_accuracy: 0.9230 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1289 - accuracy: 0.9485 - val_loss: 0.1968 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9472 - val_loss: 0.2029 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9542 - val_loss: 0.1971 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1156 - accuracy: 0.9517 - val_loss: 0.1993 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9563 - val_loss: 0.1949 - val_accuracy: 0.9276 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9565 - val_loss: 0.1974 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9580 - val_loss: 0.1970 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9612 - val_loss: 0.1978 - val_accuracy: 0.9276 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9578 - val_loss: 0.1961 - val_accuracy: 0.9272 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1026 - accuracy: 0.9608 - val_loss: 0.1969 - val_accuracy: 0.9296 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9594 - val_loss: 0.1976 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1028 - accuracy: 0.9599 - val_loss: 0.1962 - val_accuracy: 0.9304 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9611 - val_loss: 0.1968 - val_accuracy: 0.9288 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.1973 - val_accuracy: 0.9280 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9615 - val_loss: 0.1963 - val_accuracy: 0.9288 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9606 - val_loss: 0.1969 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9599 - val_loss: 0.1972 - val_accuracy: 0.9284 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9602 - val_loss: 0.1970 - val_accuracy: 0.9284 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9628 - val_loss: 0.1967 - val_accuracy: 0.9288 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.9599 - val_loss: 0.1971 - val_accuracy: 0.9288 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9609 - val_loss: 0.1972 - val_accuracy: 0.9284 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9617 - val_loss: 0.1970 - val_accuracy: 0.9292 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1003 - accuracy: 0.9617 - val_loss: 0.1969 - val_accuracy: 0.9292 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9642 - val_loss: 0.1969 - val_accuracy: 0.9296 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9632 - val_loss: 0.1970 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9635 - val_loss: 0.1970 - val_accuracy: 0.9284 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9632 - val_loss: 0.1970 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9629 - val_loss: 0.1972 - val_accuracy: 0.9292 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9609 - val_loss: 0.1970 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0993 - accuracy: 0.9638 - val_loss: 0.1969 - val_accuracy: 0.9284 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9635 - val_loss: 0.1969 - val_accuracy: 0.9284 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9625 - val_loss: 0.1970 - val_accuracy: 0.9284 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9147528221097704 0.9304237824161923 0.8896761133603239 0.8199445332667701 0.9100499478882581 0.9757430724673308\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 3s 10ms/step - loss: 0.8467 - accuracy: 0.8047 - val_loss: 0.4046 - val_accuracy: 0.8097 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 22/241 [=>............................] - ETA: 1s - loss: 0.2967 - accuracy: 0.8878"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2839 - accuracy: 0.8802 - val_loss: 0.2458 - val_accuracy: 0.8898 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.8959 - val_loss: 0.2305 - val_accuracy: 0.9011 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2226 - accuracy: 0.9045 - val_loss: 0.2468 - val_accuracy: 0.8996 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2165 - accuracy: 0.9084 - val_loss: 0.2160 - val_accuracy: 0.9077 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1974 - accuracy: 0.9154 - val_loss: 0.2147 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1921 - accuracy: 0.9198 - val_loss: 0.2125 - val_accuracy: 0.9120 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1819 - accuracy: 0.9238 - val_loss: 0.2185 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1723 - accuracy: 0.9264 - val_loss: 0.2118 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1667 - accuracy: 0.9294 - val_loss: 0.2040 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1655 - accuracy: 0.9323 - val_loss: 0.2061 - val_accuracy: 0.9136 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1570 - accuracy: 0.9347 - val_loss: 0.2026 - val_accuracy: 0.9190 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1540 - accuracy: 0.9386 - val_loss: 0.2006 - val_accuracy: 0.9155 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.9373 - val_loss: 0.2041 - val_accuracy: 0.9159 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.9397 - val_loss: 0.2014 - val_accuracy: 0.9155 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1431 - accuracy: 0.9403 - val_loss: 0.2007 - val_accuracy: 0.9194 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9408 - val_loss: 0.2003 - val_accuracy: 0.9167 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1380 - accuracy: 0.9428 - val_loss: 0.2014 - val_accuracy: 0.9186 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9441 - val_loss: 0.2000 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9436 - val_loss: 0.1998 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9464 - val_loss: 0.2010 - val_accuracy: 0.9194 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9471 - val_loss: 0.2006 - val_accuracy: 0.9194 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9489 - val_loss: 0.2008 - val_accuracy: 0.9194 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1342 - accuracy: 0.9463 - val_loss: 0.1999 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9476 - val_loss: 0.1998 - val_accuracy: 0.9194 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9504 - val_loss: 0.1995 - val_accuracy: 0.9190 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1312 - accuracy: 0.9493 - val_loss: 0.1993 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9502 - val_loss: 0.1997 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1286 - accuracy: 0.9511 - val_loss: 0.1997 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1275 - accuracy: 0.9508 - val_loss: 0.1997 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1295 - accuracy: 0.9475 - val_loss: 0.1997 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1312 - accuracy: 0.9471 - val_loss: 0.1997 - val_accuracy: 0.9190 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1291 - accuracy: 0.9486 - val_loss: 0.1996 - val_accuracy: 0.9190 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1366 - accuracy: 0.9449 - val_loss: 0.1994 - val_accuracy: 0.9194 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1292 - accuracy: 0.9497 - val_loss: 0.1995 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9502 - val_loss: 0.1996 - val_accuracy: 0.9186 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9504 - val_loss: 0.1995 - val_accuracy: 0.9186 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9502 - val_loss: 0.1995 - val_accuracy: 0.9190 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1305 - accuracy: 0.9472 - val_loss: 0.1995 - val_accuracy: 0.9190 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1266 - accuracy: 0.9491 - val_loss: 0.1995 - val_accuracy: 0.9194 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1292 - accuracy: 0.9468 - val_loss: 0.1994 - val_accuracy: 0.9190 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9484 - val_loss: 0.1994 - val_accuracy: 0.9190 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1274 - accuracy: 0.9484 - val_loss: 0.1994 - val_accuracy: 0.9190 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9485 - val_loss: 0.1994 - val_accuracy: 0.9190 - lr: 7.8364e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9237354085603113 0.9323909035033805 0.9088016967126193 0.836883621145097 0.920596300108 0.9755892250405896\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.6466 - accuracy: 0.8316 - val_loss: 0.3175 - val_accuracy: 0.8677 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2752 - accuracy: 0.8785"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2641 - accuracy: 0.8910 - val_loss: 0.2391 - val_accuracy: 0.9043 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2235 - accuracy: 0.9052 - val_loss: 0.2255 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9090 - val_loss: 0.2145 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9167 - val_loss: 0.2409 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1851 - accuracy: 0.9254 - val_loss: 0.2049 - val_accuracy: 0.9140 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9259 - val_loss: 0.2072 - val_accuracy: 0.9132 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1717 - accuracy: 0.9280 - val_loss: 0.2055 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1573 - accuracy: 0.9366 - val_loss: 0.2001 - val_accuracy: 0.9156 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1505 - accuracy: 0.9380 - val_loss: 0.1996 - val_accuracy: 0.9121 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9420 - val_loss: 0.2048 - val_accuracy: 0.9152 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9432 - val_loss: 0.1991 - val_accuracy: 0.9191 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1381 - accuracy: 0.9432 - val_loss: 0.1956 - val_accuracy: 0.9179 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9454 - val_loss: 0.1983 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1260 - accuracy: 0.9502 - val_loss: 0.1991 - val_accuracy: 0.9245 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1288 - accuracy: 0.9480 - val_loss: 0.1939 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1236 - accuracy: 0.9498 - val_loss: 0.1946 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.9513 - val_loss: 0.1929 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9538 - val_loss: 0.1937 - val_accuracy: 0.9233 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9555 - val_loss: 0.1947 - val_accuracy: 0.9249 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9561 - val_loss: 0.1947 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9560 - val_loss: 0.1941 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9547 - val_loss: 0.1928 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9569 - val_loss: 0.1937 - val_accuracy: 0.9245 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1120 - accuracy: 0.9590 - val_loss: 0.1930 - val_accuracy: 0.9249 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9572 - val_loss: 0.1940 - val_accuracy: 0.9218 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9591 - val_loss: 0.1936 - val_accuracy: 0.9253 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9598 - val_loss: 0.1933 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9606 - val_loss: 0.1934 - val_accuracy: 0.9257 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1075 - accuracy: 0.9587 - val_loss: 0.1942 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9571 - val_loss: 0.1937 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9587 - val_loss: 0.1939 - val_accuracy: 0.9253 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9585 - val_loss: 0.1937 - val_accuracy: 0.9261 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9586 - val_loss: 0.1941 - val_accuracy: 0.9253 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9166991047100039 0.9529190207156308 0.8575819672131147 0.8221057237602365 0.9052504939643728 0.9707149233840676\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7264 - accuracy: 0.8047 - val_loss: 0.3551 - val_accuracy: 0.8860 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2795 - accuracy: 0.8796"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2771 - accuracy: 0.8806 - val_loss: 0.2614 - val_accuracy: 0.8837 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2384 - accuracy: 0.9000 - val_loss: 0.2237 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2209 - accuracy: 0.9064 - val_loss: 0.2225 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2118 - accuracy: 0.9098 - val_loss: 0.2173 - val_accuracy: 0.9023 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1882 - accuracy: 0.9201 - val_loss: 0.2162 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1834 - accuracy: 0.9247 - val_loss: 0.2133 - val_accuracy: 0.9047 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1761 - accuracy: 0.9254 - val_loss: 0.2141 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1634 - accuracy: 0.9312 - val_loss: 0.2071 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9360 - val_loss: 0.2053 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1545 - accuracy: 0.9382 - val_loss: 0.2087 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1477 - accuracy: 0.9395 - val_loss: 0.2054 - val_accuracy: 0.9128 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1434 - accuracy: 0.9399 - val_loss: 0.2030 - val_accuracy: 0.9152 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1401 - accuracy: 0.9437 - val_loss: 0.2069 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1338 - accuracy: 0.9460 - val_loss: 0.2021 - val_accuracy: 0.9171 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1317 - accuracy: 0.9489 - val_loss: 0.2063 - val_accuracy: 0.9125 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1297 - accuracy: 0.9487 - val_loss: 0.2045 - val_accuracy: 0.9160 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9486 - val_loss: 0.2031 - val_accuracy: 0.9140 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1255 - accuracy: 0.9519 - val_loss: 0.2032 - val_accuracy: 0.9140 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1266 - accuracy: 0.9510 - val_loss: 0.2065 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9511 - val_loss: 0.2034 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1210 - accuracy: 0.9533 - val_loss: 0.2044 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9526 - val_loss: 0.2037 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9528 - val_loss: 0.2037 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9534 - val_loss: 0.2060 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1201 - accuracy: 0.9532 - val_loss: 0.2032 - val_accuracy: 0.9163 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1193 - accuracy: 0.9523 - val_loss: 0.2036 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9530 - val_loss: 0.2036 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1178 - accuracy: 0.9529 - val_loss: 0.2033 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9561 - val_loss: 0.2034 - val_accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9564 - val_loss: 0.2033 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9555 - val_loss: 0.2033 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1143 - accuracy: 0.9533 - val_loss: 0.2038 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.9542 - val_loss: 0.2034 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9543 - val_loss: 0.2035 - val_accuracy: 0.9171 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1130 - accuracy: 0.9555 - val_loss: 0.2036 - val_accuracy: 0.9183 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9537 - val_loss: 0.2036 - val_accuracy: 0.9179 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9538 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9538 - val_loss: 0.2038 - val_accuracy: 0.9179 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9558 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.9542 - val_loss: 0.2036 - val_accuracy: 0.9175 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9565 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.9555 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1142 - accuracy: 0.9554 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9567 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9551 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9529 - val_loss: 0.2037 - val_accuracy: 0.9175 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9108602569093033 0.9411764705882353 0.859538784067086 0.8079049210820132 0.9003576273276606 0.9680812742177307\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5636 - accuracy: 0.8215 - val_loss: 0.3486 - val_accuracy: 0.8794 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2638 - accuracy: 0.8808"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2792 - accuracy: 0.8813 - val_loss: 0.2680 - val_accuracy: 0.8926 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2342 - accuracy: 0.8974 - val_loss: 0.2320 - val_accuracy: 0.9004 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2218 - accuracy: 0.9061 - val_loss: 0.2252 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2063 - accuracy: 0.9127 - val_loss: 0.2436 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1917 - accuracy: 0.9202 - val_loss: 0.2140 - val_accuracy: 0.9082 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1826 - accuracy: 0.9237 - val_loss: 0.2226 - val_accuracy: 0.9008 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9281 - val_loss: 0.2166 - val_accuracy: 0.9066 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9333 - val_loss: 0.2109 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1575 - accuracy: 0.9338 - val_loss: 0.2105 - val_accuracy: 0.9121 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9423 - val_loss: 0.2108 - val_accuracy: 0.9089 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1441 - accuracy: 0.9406 - val_loss: 0.2131 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9452 - val_loss: 0.2111 - val_accuracy: 0.9140 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1353 - accuracy: 0.9455 - val_loss: 0.2074 - val_accuracy: 0.9136 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9472 - val_loss: 0.2060 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9511 - val_loss: 0.2117 - val_accuracy: 0.9121 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9486 - val_loss: 0.2110 - val_accuracy: 0.9148 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.9530 - val_loss: 0.2099 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9532 - val_loss: 0.2104 - val_accuracy: 0.9171 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1213 - accuracy: 0.9526 - val_loss: 0.2089 - val_accuracy: 0.9167 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1178 - accuracy: 0.9543 - val_loss: 0.2106 - val_accuracy: 0.9160 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1171 - accuracy: 0.9537 - val_loss: 0.2102 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9545 - val_loss: 0.2121 - val_accuracy: 0.9140 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.9551 - val_loss: 0.2100 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.9561 - val_loss: 0.2105 - val_accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1122 - accuracy: 0.9551 - val_loss: 0.2119 - val_accuracy: 0.9152 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9560 - val_loss: 0.2103 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9563 - val_loss: 0.2101 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9578 - val_loss: 0.2103 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9574 - val_loss: 0.2095 - val_accuracy: 0.9156 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9599 - val_loss: 0.2107 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9569 - val_loss: 0.2099 - val_accuracy: 0.9167 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9567 - val_loss: 0.2099 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9551 - val_loss: 0.2098 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9589 - val_loss: 0.2103 - val_accuracy: 0.9167 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9583 - val_loss: 0.2104 - val_accuracy: 0.9167 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9583 - val_loss: 0.2104 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9590 - val_loss: 0.2105 - val_accuracy: 0.9167 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9581 - val_loss: 0.2103 - val_accuracy: 0.9171 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9585 - val_loss: 0.2104 - val_accuracy: 0.9179 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9586 - val_loss: 0.2104 - val_accuracy: 0.9183 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9593 - val_loss: 0.2104 - val_accuracy: 0.9183 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9578 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9595 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9609 - val_loss: 0.2104 - val_accuracy: 0.9179 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9589 - val_loss: 0.2105 - val_accuracy: 0.9183 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9558 - val_loss: 0.2106 - val_accuracy: 0.9179 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9547 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9581 - val_loss: 0.2104 - val_accuracy: 0.9179 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9594 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9552 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9568 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9598 - val_loss: 0.2106 - val_accuracy: 0.9179 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9596 - val_loss: 0.2106 - val_accuracy: 0.9179 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1097 - accuracy: 0.9576 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9590 - val_loss: 0.2104 - val_accuracy: 0.9179 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9578 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9569 - val_loss: 0.2106 - val_accuracy: 0.9179 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9551 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9565 - val_loss: 0.2105 - val_accuracy: 0.9179 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9589 - val_loss: 0.2106 - val_accuracy: 0.9179 - lr: 3.6562e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9252627481510315 0.9373837569745815 0.9048117154811716 0.8404341823396372 0.9210977362278765 0.9783849579903867\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5440 - accuracy: 0.8400 - val_loss: 0.3859 - val_accuracy: 0.8712 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 27/241 [==>...........................] - ETA: 0s - loss: 0.2502 - accuracy: 0.8958"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2608 - accuracy: 0.8906 - val_loss: 0.2462 - val_accuracy: 0.9051 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9092 - val_loss: 0.2254 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9131 - val_loss: 0.2305 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1971 - accuracy: 0.9183 - val_loss: 0.2130 - val_accuracy: 0.9113 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1801 - accuracy: 0.9219 - val_loss: 0.2083 - val_accuracy: 0.9113 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9258 - val_loss: 0.2098 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1676 - accuracy: 0.9310 - val_loss: 0.2075 - val_accuracy: 0.9128 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1573 - accuracy: 0.9366 - val_loss: 0.2013 - val_accuracy: 0.9206 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1543 - accuracy: 0.9372 - val_loss: 0.2004 - val_accuracy: 0.9198 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1448 - accuracy: 0.9391 - val_loss: 0.2015 - val_accuracy: 0.9191 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1356 - accuracy: 0.9458 - val_loss: 0.2009 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9430 - val_loss: 0.1983 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9452 - val_loss: 0.2002 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9463 - val_loss: 0.2049 - val_accuracy: 0.9206 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9493 - val_loss: 0.1978 - val_accuracy: 0.9253 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1230 - accuracy: 0.9515 - val_loss: 0.2006 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9520 - val_loss: 0.1979 - val_accuracy: 0.9265 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1184 - accuracy: 0.9528 - val_loss: 0.2010 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1165 - accuracy: 0.9539 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1122 - accuracy: 0.9567 - val_loss: 0.1976 - val_accuracy: 0.9257 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1143 - accuracy: 0.9563 - val_loss: 0.1980 - val_accuracy: 0.9253 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9585 - val_loss: 0.1972 - val_accuracy: 0.9261 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1121 - accuracy: 0.9552 - val_loss: 0.1970 - val_accuracy: 0.9261 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9573 - val_loss: 0.1969 - val_accuracy: 0.9280 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1096 - accuracy: 0.9565 - val_loss: 0.1972 - val_accuracy: 0.9276 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9561 - val_loss: 0.1972 - val_accuracy: 0.9284 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9580 - val_loss: 0.1970 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9555 - val_loss: 0.1968 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9573 - val_loss: 0.1968 - val_accuracy: 0.9265 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9576 - val_loss: 0.1967 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.9573 - val_loss: 0.1962 - val_accuracy: 0.9268 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9576 - val_loss: 0.1964 - val_accuracy: 0.9272 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9569 - val_loss: 0.1965 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9578 - val_loss: 0.1971 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9581 - val_loss: 0.1970 - val_accuracy: 0.9265 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9567 - val_loss: 0.1969 - val_accuracy: 0.9268 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9546 - val_loss: 0.1968 - val_accuracy: 0.9272 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9554 - val_loss: 0.1967 - val_accuracy: 0.9272 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1074 - accuracy: 0.9598 - val_loss: 0.1968 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9589 - val_loss: 0.1967 - val_accuracy: 0.9268 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1074 - accuracy: 0.9586 - val_loss: 0.1968 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1034 - accuracy: 0.9616 - val_loss: 0.1968 - val_accuracy: 0.9268 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9580 - val_loss: 0.1967 - val_accuracy: 0.9265 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9598 - val_loss: 0.1968 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9589 - val_loss: 0.1968 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9574 - val_loss: 0.1967 - val_accuracy: 0.9265 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9603 - val_loss: 0.1968 - val_accuracy: 0.9265 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9186453873102375 0.9361163820366857 0.8906882591093117 0.8279184489831761 0.9134023205729986 0.9751112015917769\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4553 - accuracy: 0.8321 - val_loss: 0.3517 - val_accuracy: 0.8867 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 38/241 [===>..........................] - ETA: 0s - loss: 0.2902 - accuracy: 0.8758"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2657 - accuracy: 0.8875 - val_loss: 0.2373 - val_accuracy: 0.8972 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.9040 - val_loss: 0.2390 - val_accuracy: 0.8968 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.9052 - val_loss: 0.2232 - val_accuracy: 0.9058 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1985 - accuracy: 0.9127 - val_loss: 0.2143 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9257 - val_loss: 0.2193 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1742 - accuracy: 0.9241 - val_loss: 0.2142 - val_accuracy: 0.9089 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1636 - accuracy: 0.9307 - val_loss: 0.2027 - val_accuracy: 0.9159 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1551 - accuracy: 0.9353 - val_loss: 0.2033 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1444 - accuracy: 0.9411 - val_loss: 0.2034 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9399 - val_loss: 0.1957 - val_accuracy: 0.9194 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1355 - accuracy: 0.9446 - val_loss: 0.2000 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9472 - val_loss: 0.1964 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1294 - accuracy: 0.9445 - val_loss: 0.1974 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1262 - accuracy: 0.9489 - val_loss: 0.1956 - val_accuracy: 0.9225 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1240 - accuracy: 0.9491 - val_loss: 0.1952 - val_accuracy: 0.9225 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1251 - accuracy: 0.9500 - val_loss: 0.1965 - val_accuracy: 0.9221 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9510 - val_loss: 0.1961 - val_accuracy: 0.9221 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9524 - val_loss: 0.1986 - val_accuracy: 0.9260 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9535 - val_loss: 0.1963 - val_accuracy: 0.9210 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1156 - accuracy: 0.9550 - val_loss: 0.1964 - val_accuracy: 0.9233 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1170 - accuracy: 0.9535 - val_loss: 0.1956 - val_accuracy: 0.9241 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9561 - val_loss: 0.1964 - val_accuracy: 0.9221 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9563 - val_loss: 0.1990 - val_accuracy: 0.9241 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9587 - val_loss: 0.1961 - val_accuracy: 0.9225 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9561 - val_loss: 0.1958 - val_accuracy: 0.9257 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9571 - val_loss: 0.1953 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9581 - val_loss: 0.1954 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9538 - val_loss: 0.1953 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9587 - val_loss: 0.1952 - val_accuracy: 0.9245 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9580 - val_loss: 0.1955 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9548 - val_loss: 0.1954 - val_accuracy: 0.9241 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1057 - accuracy: 0.9608 - val_loss: 0.1955 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9572 - val_loss: 0.1955 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9567 - val_loss: 0.1956 - val_accuracy: 0.9241 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9564 - val_loss: 0.1956 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1076 - accuracy: 0.9573 - val_loss: 0.1957 - val_accuracy: 0.9245 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9583 - val_loss: 0.1955 - val_accuracy: 0.9237 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9581 - val_loss: 0.1954 - val_accuracy: 0.9237 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9272373540856031 0.9391518131530424 0.9066808059384942 0.8437993504675841 0.9229163095457683 0.9781008576767579\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4841 - accuracy: 0.8370 - val_loss: 0.3173 - val_accuracy: 0.8455 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 28/241 [==>...........................] - ETA: 0s - loss: 0.2632 - accuracy: 0.8929"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2619 - accuracy: 0.8869 - val_loss: 0.2367 - val_accuracy: 0.9019 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9027 - val_loss: 0.2249 - val_accuracy: 0.9039 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9074 - val_loss: 0.2407 - val_accuracy: 0.8918 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2018 - accuracy: 0.9166 - val_loss: 0.2139 - val_accuracy: 0.9043 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1848 - accuracy: 0.9251 - val_loss: 0.2060 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1776 - accuracy: 0.9279 - val_loss: 0.2037 - val_accuracy: 0.9179 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1742 - accuracy: 0.9264 - val_loss: 0.2124 - val_accuracy: 0.9086 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9368 - val_loss: 0.2037 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1564 - accuracy: 0.9368 - val_loss: 0.2018 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1538 - accuracy: 0.9355 - val_loss: 0.2098 - val_accuracy: 0.9082 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9395 - val_loss: 0.2017 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.9391 - val_loss: 0.1992 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1410 - accuracy: 0.9442 - val_loss: 0.2006 - val_accuracy: 0.9156 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1364 - accuracy: 0.9463 - val_loss: 0.1971 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1341 - accuracy: 0.9445 - val_loss: 0.2008 - val_accuracy: 0.9160 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9468 - val_loss: 0.1948 - val_accuracy: 0.9179 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.9485 - val_loss: 0.1950 - val_accuracy: 0.9191 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1275 - accuracy: 0.9480 - val_loss: 0.1962 - val_accuracy: 0.9198 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1268 - accuracy: 0.9497 - val_loss: 0.1959 - val_accuracy: 0.9179 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9503 - val_loss: 0.1969 - val_accuracy: 0.9163 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1220 - accuracy: 0.9524 - val_loss: 0.1954 - val_accuracy: 0.9171 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1223 - accuracy: 0.9515 - val_loss: 0.1965 - val_accuracy: 0.9179 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9491 - val_loss: 0.1962 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9533 - val_loss: 0.1958 - val_accuracy: 0.9187 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9502 - val_loss: 0.1972 - val_accuracy: 0.9175 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9508 - val_loss: 0.1966 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1211 - accuracy: 0.9508 - val_loss: 0.1964 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9545 - val_loss: 0.1964 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9517 - val_loss: 0.1961 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9550 - val_loss: 0.1958 - val_accuracy: 0.9187 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9504 - val_loss: 0.1962 - val_accuracy: 0.9183 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1190 - accuracy: 0.9537 - val_loss: 0.1965 - val_accuracy: 0.9175 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1205 - accuracy: 0.9523 - val_loss: 0.1963 - val_accuracy: 0.9183 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9541 - val_loss: 0.1964 - val_accuracy: 0.9179 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1221 - accuracy: 0.9516 - val_loss: 0.1965 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1203 - accuracy: 0.9511 - val_loss: 0.1965 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1190 - accuracy: 0.9532 - val_loss: 0.1965 - val_accuracy: 0.9175 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1175 - accuracy: 0.9537 - val_loss: 0.1964 - val_accuracy: 0.9175 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9202024133904243 0.9416195856873822 0.8852459016393442 0.8300976307959538 0.9134327436633632 0.9726409342101201\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4982 - accuracy: 0.8187 - val_loss: 0.3035 - val_accuracy: 0.8794 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 29/241 [==>...........................] - ETA: 0s - loss: 0.2548 - accuracy: 0.8879"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2626 - accuracy: 0.8882 - val_loss: 0.2459 - val_accuracy: 0.8914 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2223 - accuracy: 0.9040 - val_loss: 0.2345 - val_accuracy: 0.8965 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9114 - val_loss: 0.2253 - val_accuracy: 0.9047 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2029 - accuracy: 0.9131 - val_loss: 0.2187 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1823 - accuracy: 0.9210 - val_loss: 0.2210 - val_accuracy: 0.9078 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1744 - accuracy: 0.9263 - val_loss: 0.2167 - val_accuracy: 0.9047 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1680 - accuracy: 0.9305 - val_loss: 0.2248 - val_accuracy: 0.9051 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9371 - val_loss: 0.2135 - val_accuracy: 0.9109 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1515 - accuracy: 0.9393 - val_loss: 0.2093 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1432 - accuracy: 0.9430 - val_loss: 0.2080 - val_accuracy: 0.9156 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1381 - accuracy: 0.9429 - val_loss: 0.2057 - val_accuracy: 0.9148 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1352 - accuracy: 0.9459 - val_loss: 0.2067 - val_accuracy: 0.9132 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 0.9446 - val_loss: 0.2058 - val_accuracy: 0.9167 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9468 - val_loss: 0.2056 - val_accuracy: 0.9171 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1276 - accuracy: 0.9471 - val_loss: 0.2073 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9507 - val_loss: 0.2049 - val_accuracy: 0.9187 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1221 - accuracy: 0.9508 - val_loss: 0.2053 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1231 - accuracy: 0.9477 - val_loss: 0.2034 - val_accuracy: 0.9214 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1188 - accuracy: 0.9521 - val_loss: 0.2045 - val_accuracy: 0.9187 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1204 - accuracy: 0.9512 - val_loss: 0.2038 - val_accuracy: 0.9214 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9539 - val_loss: 0.2033 - val_accuracy: 0.9226 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9547 - val_loss: 0.2048 - val_accuracy: 0.9202 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1154 - accuracy: 0.9554 - val_loss: 0.2038 - val_accuracy: 0.9237 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9532 - val_loss: 0.2039 - val_accuracy: 0.9218 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1137 - accuracy: 0.9558 - val_loss: 0.2037 - val_accuracy: 0.9222 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9524 - val_loss: 0.2033 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9572 - val_loss: 0.2035 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.2032 - val_accuracy: 0.9226 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9576 - val_loss: 0.2029 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1124 - accuracy: 0.9561 - val_loss: 0.2030 - val_accuracy: 0.9230 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9591 - val_loss: 0.2032 - val_accuracy: 0.9226 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1125 - accuracy: 0.9555 - val_loss: 0.2030 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1109 - accuracy: 0.9564 - val_loss: 0.2030 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9541 - val_loss: 0.2030 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9569 - val_loss: 0.2031 - val_accuracy: 0.9230 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9576 - val_loss: 0.2031 - val_accuracy: 0.9230 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9587 - val_loss: 0.2030 - val_accuracy: 0.9230 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9567 - val_loss: 0.2031 - val_accuracy: 0.9230 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1109 - accuracy: 0.9567 - val_loss: 0.2031 - val_accuracy: 0.9230 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1106 - accuracy: 0.9577 - val_loss: 0.2030 - val_accuracy: 0.9226 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9587 - val_loss: 0.2030 - val_accuracy: 0.9226 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9548 - val_loss: 0.2031 - val_accuracy: 0.9226 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9580 - val_loss: 0.2030 - val_accuracy: 0.9230 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9089139743090697 0.9337461300309597 0.8668763102725366 0.8041848601384172 0.9003112201517482 0.9700138247950619\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5080 - accuracy: 0.8264 - val_loss: 0.3646 - val_accuracy: 0.8440 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 40/241 [===>..........................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8766"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2641 - accuracy: 0.8849 - val_loss: 0.2678 - val_accuracy: 0.8868 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2340 - accuracy: 0.8968 - val_loss: 0.2288 - val_accuracy: 0.9031 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9076 - val_loss: 0.2347 - val_accuracy: 0.8957 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9127 - val_loss: 0.2221 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1882 - accuracy: 0.9219 - val_loss: 0.2183 - val_accuracy: 0.9070 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1811 - accuracy: 0.9218 - val_loss: 0.2120 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1736 - accuracy: 0.9288 - val_loss: 0.2206 - val_accuracy: 0.9019 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9311 - val_loss: 0.2102 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1604 - accuracy: 0.9343 - val_loss: 0.2170 - val_accuracy: 0.9086 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1543 - accuracy: 0.9362 - val_loss: 0.2096 - val_accuracy: 0.9140 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1470 - accuracy: 0.9385 - val_loss: 0.2130 - val_accuracy: 0.9089 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1458 - accuracy: 0.9394 - val_loss: 0.2119 - val_accuracy: 0.9105 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1394 - accuracy: 0.9417 - val_loss: 0.2150 - val_accuracy: 0.9171 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1342 - accuracy: 0.9469 - val_loss: 0.2129 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1369 - accuracy: 0.9446 - val_loss: 0.2127 - val_accuracy: 0.9117 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1363 - accuracy: 0.9467 - val_loss: 0.2089 - val_accuracy: 0.9121 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.9478 - val_loss: 0.2112 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9480 - val_loss: 0.2117 - val_accuracy: 0.9128 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9515 - val_loss: 0.2114 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9493 - val_loss: 0.2106 - val_accuracy: 0.9121 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1241 - accuracy: 0.9506 - val_loss: 0.2097 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9504 - val_loss: 0.2101 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1214 - accuracy: 0.9499 - val_loss: 0.2106 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9516 - val_loss: 0.2106 - val_accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1215 - accuracy: 0.9530 - val_loss: 0.2115 - val_accuracy: 0.9117 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1225 - accuracy: 0.9532 - val_loss: 0.2109 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9494 - val_loss: 0.2111 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9512 - val_loss: 0.2104 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1204 - accuracy: 0.9538 - val_loss: 0.2102 - val_accuracy: 0.9148 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.9537 - val_loss: 0.2105 - val_accuracy: 0.9136 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1193 - accuracy: 0.9547 - val_loss: 0.2106 - val_accuracy: 0.9140 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1220 - accuracy: 0.9515 - val_loss: 0.2106 - val_accuracy: 0.9152 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9528 - val_loss: 0.2106 - val_accuracy: 0.9144 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9283768003114052 0.9497830130192189 0.8922594142259415 0.8461508356405381 0.9210212136225802 0.9800204665544335\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.5061 - accuracy: 0.8309 - val_loss: 0.3564 - val_accuracy: 0.8829 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 41/241 [====>.........................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8758"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2640 - accuracy: 0.8883 - val_loss: 0.2507 - val_accuracy: 0.8899 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2269 - accuracy: 0.9013 - val_loss: 0.2279 - val_accuracy: 0.9016 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9090 - val_loss: 0.2206 - val_accuracy: 0.9035 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9144 - val_loss: 0.2181 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.9233 - val_loss: 0.2064 - val_accuracy: 0.9086 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9244 - val_loss: 0.2054 - val_accuracy: 0.9117 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9247 - val_loss: 0.2070 - val_accuracy: 0.9089 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9292 - val_loss: 0.2048 - val_accuracy: 0.9132 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1554 - accuracy: 0.9315 - val_loss: 0.2053 - val_accuracy: 0.9121 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1524 - accuracy: 0.9382 - val_loss: 0.1987 - val_accuracy: 0.9175 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1446 - accuracy: 0.9385 - val_loss: 0.2024 - val_accuracy: 0.9144 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1452 - accuracy: 0.9386 - val_loss: 0.2004 - val_accuracy: 0.9175 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1413 - accuracy: 0.9425 - val_loss: 0.1956 - val_accuracy: 0.9237 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1367 - accuracy: 0.9467 - val_loss: 0.1980 - val_accuracy: 0.9175 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1338 - accuracy: 0.9462 - val_loss: 0.1982 - val_accuracy: 0.9179 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9469 - val_loss: 0.1991 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9491 - val_loss: 0.1991 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9468 - val_loss: 0.1973 - val_accuracy: 0.9206 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1269 - accuracy: 0.9491 - val_loss: 0.1971 - val_accuracy: 0.9195 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9476 - val_loss: 0.1976 - val_accuracy: 0.9187 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9503 - val_loss: 0.1972 - val_accuracy: 0.9218 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1244 - accuracy: 0.9506 - val_loss: 0.1977 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1228 - accuracy: 0.9526 - val_loss: 0.1985 - val_accuracy: 0.9210 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1207 - accuracy: 0.9513 - val_loss: 0.1973 - val_accuracy: 0.9214 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9508 - val_loss: 0.1971 - val_accuracy: 0.9214 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1219 - accuracy: 0.9513 - val_loss: 0.1976 - val_accuracy: 0.9237 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9519 - val_loss: 0.1975 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9533 - val_loss: 0.1972 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1183 - accuracy: 0.9558 - val_loss: 0.1971 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.9511 - val_loss: 0.1969 - val_accuracy: 0.9237 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9507 - val_loss: 0.1969 - val_accuracy: 0.9233 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9545 - val_loss: 0.1970 - val_accuracy: 0.9222 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.9517 - val_loss: 0.1969 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9182561307901907 0.9329538266919671 0.8947368421052632 0.8273776860955222 0.9138453343986152 0.9730299328821249\n"
          ]
        }
      ],
      "source": [
        "# 5-Fold CV\n",
        "final_ACC_collection_cv = []\n",
        "final_BACC_collection_cv = []\n",
        "final_Sn_collection_cv = []\n",
        "final_Sp_collection_cv = []\n",
        "final_MCC_collection_cv = []\n",
        "final_AUC_collection_cv = []\n",
        "\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "\n",
        "# split dataset\n",
        "for i in range(len(CNN_channel)):\n",
        "  # collect the value in cross validation\n",
        "  ACC_collection_cv = []\n",
        "  BACC_collection_cv = []\n",
        "  Sn_collection_cv = []\n",
        "  Sp_collection_cv = []\n",
        "  MCC_collection_cv = []\n",
        "  AUC_collection_cv = []\n",
        "\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(X_train_whole, y_train_whole):\n",
        "      X_train, X_valid = X[train_ix], X[test_ix]\n",
        "      y_train, y_valid = y[train_ix], y[test_ix]\n",
        "      X_train_only, X_train_indicator, y_train_only, y_train_indicator = train_test_split( X_train, y_train, test_size=0.25, random_state=random_num,shuffle=True, stratify = y_train)\n",
        "\n",
        "      # train the model\n",
        "      saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i])\n",
        "\n",
        "      # ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_valid, y_valid)\n",
        "\n",
        "      # ACC_collection_cv.append(ACC)\n",
        "      # BACC_collection_cv.append(BACC)\n",
        "      # Sn_collection_cv.append(Sn)\n",
        "      # Sp_collection_cv.append(Sp)\n",
        "      # MCC_collection_cv.append(MCC)\n",
        "      # AUC_collection_cv.append(AUC)\n",
        "\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_valid, y_valid)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  # final_ACC_collection_cv.append(str(round(statistics.mean(ACC_collection_cv),3))+'±'+ str(round(statistics.stdev(ACC_collection_cv),3)))\n",
        "  # final_BACC_collection_cv.append(str(round(statistics.mean(BACC_collection_cv),3))+'±'+str(round(statistics.stdev(BACC_collection_cv),3)))\n",
        "  # final_Sn_collection_cv.append(str(round(statistics.mean(Sn_collection_cv),3))+'±'+str(round(statistics.stdev(Sn_collection_cv),3)))\n",
        "  # final_Sp_collection_cv.append(str(round(statistics.mean(Sp_collection_cv),3))+'±'+str(round(statistics.stdev(Sp_collection_cv),3)))\n",
        "  # final_MCC_collection_cv.append(str(round(statistics.mean(MCC_collection_cv),3))+'±'+str(round(statistics.stdev(MCC_collection_cv),3)))\n",
        "  # final_AUC_collection_cv.append(str(round(statistics.mean(AUC_collection_cv),3))+'±'+str(round(statistics.stdev(AUC_collection_cv),3)))\n",
        "\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "  final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "  final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "  final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "  final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkdvfb9HpEhS",
        "outputId": "2b65fb53-dafd-45df-b5ea-770b8f814e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.91±0.008', '0.909±0.006', '0.902±0.004', '0.912±0.01', '0.918±0.006', '0.918±0.005', '0.917±0.008', '0.914±0.015', '0.923±0.005', '0.92±0.005', '0.919±0.01', '0.921±0.007', '0.922±0.007', '0.924±0.009', '0.922±0.006', '0.923±0.008', '0.923±0.007', '0.923±0.007', '0.921±0.008', '0.917±0.008', '0.923±0.006', '0.92±0.004', '0.922±0.008', '0.922±0.008', '0.919±0.006', '0.921±0.008'] \n",
            " ['0.903±0.013', '0.902±0.005', '0.893±0.006', '0.903±0.013', '0.912±0.008', '0.913±0.007', '0.911±0.01', '0.906±0.02', '0.918±0.007', '0.913±0.01', '0.913±0.012', '0.916±0.009', '0.915±0.008', '0.919±0.011', '0.916±0.007', '0.918±0.011', '0.918±0.009', '0.919±0.008', '0.917±0.009', '0.912±0.01', '0.918±0.008', '0.913±0.007', '0.919±0.01', '0.916±0.009', '0.912±0.009', '0.914±0.009'] \n",
            " ['0.934±0.021', '0.93±0.014', '0.927±0.006', '0.938±0.008', '0.937±0.009', '0.933±0.006', '0.936±0.006', '0.939±0.005', '0.938±0.005', '0.94±0.01', '0.936±0.006', '0.937±0.008', '0.946±0.014', '0.941±0.008', '0.939±0.011', '0.938±0.007', '0.939±0.008', '0.935±0.009', '0.934±0.006', '0.932±0.003', '0.939±0.008', '0.938±0.011', '0.934±0.006', '0.938±0.007', '0.94±0.008', '0.939±0.007'] \n",
            " ['0.871±0.04', '0.874±0.013', '0.859±0.015', '0.869±0.03', '0.888±0.022', '0.893±0.016', '0.887±0.019', '0.873±0.041', '0.897±0.016', '0.886±0.028', '0.89±0.022', '0.894±0.019', '0.883±0.018', '0.897±0.022', '0.893±0.016', '0.897±0.023', '0.896±0.02', '0.902±0.019', '0.899±0.017', '0.893±0.019', '0.896±0.02', '0.888±0.021', '0.903±0.018', '0.895±0.017', '0.884±0.024', '0.889±0.015'] \n",
            " ['0.809±0.018', '0.806±0.011', '0.789±0.01', '0.812±0.021', '0.826±0.013', '0.825±0.01', '0.824±0.017', '0.816±0.033', '0.835±0.011', '0.829±0.012', '0.827±0.021', '0.832±0.016', '0.834±0.015', '0.838±0.02', '0.833±0.013', '0.835±0.018', '0.836±0.015', '0.835±0.014', '0.831±0.016', '0.824±0.018', '0.835±0.013', '0.828±0.01', '0.835±0.017', '0.833±0.016', '0.827±0.013', '0.83±0.017'] \n",
            " ['0.968±0.006', '0.971±0.005', '0.964±0.004', '0.969±0.006', '0.975±0.004', '0.974±0.003', '0.974±0.005', '0.971±0.008', '0.975±0.004', '0.974±0.003', '0.973±0.005', '0.975±0.004', '0.976±0.005', '0.975±0.004', '0.975±0.004', '0.976±0.005', '0.976±0.005', '0.976±0.003', '0.976±0.004', '0.973±0.005', '0.977±0.004', '0.974±0.003', '0.975±0.005', '0.975±0.004', '0.974±0.004', '0.975±0.004']\n"
          ]
        }
      ],
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VJ-G_3GpEhS",
        "outputId": "db8e79f6-5103-458b-f6ae-4707edb67efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.906±0.014', '0.907±0.005', '0.906±0.005', '0.911±0.009', '0.917±0.01', '0.915±0.007', '0.918±0.007', '0.913±0.012', '0.92±0.006', '0.921±0.006', '0.911±0.022', '0.92±0.007', '0.925±0.007', '0.923±0.009', '0.92±0.009', '0.923±0.007', '0.925±0.008', '0.923±0.008', '0.923±0.007', '0.921±0.007', '0.921±0.009', '0.922±0.005', '0.918±0.009', '0.92±0.007', '0.918±0.008', '0.917±0.008'] \n",
            " [0.9215420322878571, 0.9091034803906435, 0.8977857611101375, 0.9221628919838032, 0.9030276665975258] \n",
            " [0.926859250153657, 0.9391086001255493, 0.934984520123839, 0.9342839429634222, 0.9386464263124604] \n",
            " [0.9162248144220573, 0.8790983606557377, 0.860587002096436, 0.9100418410041841, 0.8674089068825911] \n",
            " [0.8360943356038126, 0.8217553034712758, 0.8005996660692932, 0.8408594028885847, 0.8116126592175859] \n",
            " [0.9774125784335259, 0.9713066515390079, 0.9686027870267603, 0.9795438215129688, 0.9735638541690672]\n"
          ]
        }
      ],
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myos98aO_YO2"
      },
      "source": [
        "### final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU-AvOnilDxo",
        "outputId": "0ffef1dd-b805-44c1-cf44-7f743f1b0a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5 5 5\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [32,32,32,128,128]\n",
        "dense_node = [512,8192,4096,4096,2048]\n",
        "kernel_size = [3,9,6,12,12]\n",
        "stride_size = [1,2,1,4,8]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqrQ7-cY_dOf"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(320,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "kNwRgQFaXAuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhjAC1Mp_glC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "RJTUvbfnXDF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJJrzyhG_kzx",
        "outputId": "8acc1529-da9d-4ad0-e11b-3ceb3472a74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "402/402 [==============================] - 6s 4ms/step - loss: 0.6932 - accuracy: 0.8106 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2737 - accuracy: 0.8842 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2359 - accuracy: 0.8999 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2206 - accuracy: 0.9081 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2108 - accuracy: 0.9126 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1892 - accuracy: 0.9222 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1859 - accuracy: 0.9232 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1786 - accuracy: 0.9269 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9334 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9357 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9383 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9407 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9420 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9431 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1386 - accuracy: 0.9462 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1335 - accuracy: 0.9471 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1334 - accuracy: 0.9492 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1287 - accuracy: 0.9502 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9516 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1245 - accuracy: 0.9530 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1253 - accuracy: 0.9517 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.9534 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9536 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9552 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1189 - accuracy: 0.9545 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1180 - accuracy: 0.9549 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9559 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1197 - accuracy: 0.9563 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1190 - accuracy: 0.9533 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1199 - accuracy: 0.9564 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1176 - accuracy: 0.9546 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9571 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9545 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9552 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1175 - accuracy: 0.9571 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9560 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9554 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1167 - accuracy: 0.9552 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1125 - accuracy: 0.9576 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9557 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9566 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9549 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9557 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9536 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9565 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9352428393524284 0.9283935242839353 0.9420921544209215 0.8705673645942783 0.9352428393524284 0.9817794881895259\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7106 - accuracy: 0.8074 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.8904 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9044 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9144 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2004 - accuracy: 0.9157 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1818 - accuracy: 0.9260 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1754 - accuracy: 0.9305 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9326 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1571 - accuracy: 0.9345 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1522 - accuracy: 0.9379 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1480 - accuracy: 0.9428 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1398 - accuracy: 0.9442 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9471 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9458 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1267 - accuracy: 0.9508 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1246 - accuracy: 0.9522 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9541 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1172 - accuracy: 0.9540 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1170 - accuracy: 0.9571 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1149 - accuracy: 0.9533 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1128 - accuracy: 0.9554 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9565 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9578 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9578 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1096 - accuracy: 0.9577 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1120 - accuracy: 0.9586 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9585 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9591 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9580 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9570 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1075 - accuracy: 0.9601 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1064 - accuracy: 0.9611 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9607 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1059 - accuracy: 0.9600 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9598 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9607 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9587 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1056 - accuracy: 0.9604 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1069 - accuracy: 0.9584 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9593 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9591 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9592 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9593 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9615 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9598 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9293275217932753 0.9202988792029888 0.9383561643835616 0.8587950667437313 0.9293275217932753 0.9775846413434055\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6939 - accuracy: 0.8001 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2669 - accuracy: 0.8888 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2258 - accuracy: 0.9025 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9098 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9180 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9266 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1732 - accuracy: 0.9278 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9352 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1517 - accuracy: 0.9383 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9399 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1420 - accuracy: 0.9422 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1335 - accuracy: 0.9477 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9468 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1262 - accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1205 - accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.9520 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9545 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1142 - accuracy: 0.9566 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1106 - accuracy: 0.9580 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9552 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9593 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9572 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9598 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1064 - accuracy: 0.9589 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9598 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9606 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9612 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1018 - accuracy: 0.9615 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1033 - accuracy: 0.9624 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1032 - accuracy: 0.9612 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9606 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9627 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1019 - accuracy: 0.9633 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9603 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9619 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9619 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9611 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9621 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1009 - accuracy: 0.9617 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9609 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9626 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9605 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9606 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9611 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9234122042341221 0.9084682440846824 0.9383561643835616 0.8472028910053546 0.923412204234122 0.9783350573580706\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.4584 - accuracy: 0.8395 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2620 - accuracy: 0.8867 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2209 - accuracy: 0.9084 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9158 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9201 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9299 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9341 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9334 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9399 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1418 - accuracy: 0.9443 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9442 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9499 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1238 - accuracy: 0.9514 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9549 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1159 - accuracy: 0.9568 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1125 - accuracy: 0.9579 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1106 - accuracy: 0.9591 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1059 - accuracy: 0.9592 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9587 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1059 - accuracy: 0.9598 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9633 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1005 - accuracy: 0.9625 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9623 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9606 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9639 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0972 - accuracy: 0.9648 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9636 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9635 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9640 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9640 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9647 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9638 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9646 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9637 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9629 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0944 - accuracy: 0.9658 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9670 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9627 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9640 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9636 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9647 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9649 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9642 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9651 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9636 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9234122042341221 0.9097135740971357 0.9371108343711083 0.8471424048776754 0.923412204234122 0.9776614082619817\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6024 - accuracy: 0.8256 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.8846 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2340 - accuracy: 0.9017 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2192 - accuracy: 0.9084 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9125 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9199 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1798 - accuracy: 0.9240 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.9293 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1601 - accuracy: 0.9363 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1534 - accuracy: 0.9397 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9394 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1410 - accuracy: 0.9436 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1375 - accuracy: 0.9457 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9447 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9498 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1296 - accuracy: 0.9494 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9481 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1231 - accuracy: 0.9513 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9521 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9542 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1170 - accuracy: 0.9564 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1133 - accuracy: 0.9566 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9566 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9572 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9560 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9584 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9578 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9577 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9587 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9566 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9564 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1093 - accuracy: 0.9580 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1086 - accuracy: 0.9577 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9580 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9580 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9575 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9563 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9594 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1096 - accuracy: 0.9565 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9574 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9590 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9591 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9573 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9308841843088418 0.9215442092154421 0.9402241594022416 0.8619187609368223 0.9308841843088418 0.9806283721225975\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4413 - accuracy: 0.8412 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2628 - accuracy: 0.8890 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9099 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9157 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9211 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9279 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9331 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9336 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1475 - accuracy: 0.9403 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9410 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1374 - accuracy: 0.9444 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1319 - accuracy: 0.9489 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1266 - accuracy: 0.9517 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1241 - accuracy: 0.9520 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9532 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9561 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1118 - accuracy: 0.9573 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9571 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1087 - accuracy: 0.9584 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1086 - accuracy: 0.9580 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9618 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9607 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9617 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9618 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9619 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9607 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0998 - accuracy: 0.9629 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1009 - accuracy: 0.9621 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9615 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9634 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9627 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9640 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9619 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9629 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9643 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9638 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9626 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9640 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9639 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9627 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9636 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9636 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9643 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0982 - accuracy: 0.9633 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9635 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9315068493150684 0.927148194271482 0.935865504358655 0.8630464913497742 0.9315068493150684 0.981032367724396\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4942 - accuracy: 0.8347 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2710 - accuracy: 0.8884 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2263 - accuracy: 0.9065 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9110 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9175 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1791 - accuracy: 0.9260 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1748 - accuracy: 0.9280 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9320 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9369 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1472 - accuracy: 0.9411 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9436 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9465 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9489 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9483 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1232 - accuracy: 0.9520 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9517 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1193 - accuracy: 0.9524 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9549 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9547 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9570 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9580 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9574 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9587 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9605 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1086 - accuracy: 0.9604 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9576 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9588 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9586 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9603 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9647 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9616 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9582 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9592 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1076 - accuracy: 0.9590 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9602 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1043 - accuracy: 0.9613 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9589 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9607 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9629 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9601 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1023 - accuracy: 0.9608 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1046 - accuracy: 0.9600 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9594 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9594 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9619 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9318181818181818 0.9333748443337484 0.9302615193026152 0.8636405491909328 0.9318181818181819 0.9804492493125873\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4530 - accuracy: 0.8400 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2619 - accuracy: 0.8890 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9140 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1946 - accuracy: 0.9185 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9282 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9324 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9369 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9394 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9425 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9447 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1284 - accuracy: 0.9486 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9489 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9507 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1148 - accuracy: 0.9556 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9551 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9547 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1054 - accuracy: 0.9582 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9579 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9622 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1018 - accuracy: 0.9608 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1004 - accuracy: 0.9606 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0998 - accuracy: 0.9619 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9629 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9629 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9635 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9642 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9645 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9636 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9643 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9651 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9644 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9676 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9636 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9641 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9636 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0952 - accuracy: 0.9646 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9639 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9635 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9648 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9636 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9644 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9622 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9651 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.934931506849315 0.9259028642590287 0.9439601494396015 0.8700048645692477 0.9349315068493151 0.9809391230581459\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4472 - accuracy: 0.8473 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2617 - accuracy: 0.8909 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2219 - accuracy: 0.9057 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2071 - accuracy: 0.9139 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9183 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9284 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1673 - accuracy: 0.9314 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1607 - accuracy: 0.9343 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9401 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9418 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9470 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1286 - accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9532 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9532 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1160 - accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.9577 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9583 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9618 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9606 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9606 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9603 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9636 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9620 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9616 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9645 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9645 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9635 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9654 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9653 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9633 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9649 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9647 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9644 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9668 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9654 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0952 - accuracy: 0.9640 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9647 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9649 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9661 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9660 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9631 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9651 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9645 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9299501867995019 0.9184308841843088 0.9414694894146949 0.8601286722974508 0.9299501867995019 0.9805128340330237\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4634 - accuracy: 0.8437 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2608 - accuracy: 0.8906 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2186 - accuracy: 0.9088 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9150 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9192 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1759 - accuracy: 0.9277 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9299 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9307 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1475 - accuracy: 0.9400 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9418 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1382 - accuracy: 0.9433 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1281 - accuracy: 0.9495 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9504 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9513 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9525 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1147 - accuracy: 0.9562 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9561 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9572 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9594 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9592 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9604 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9579 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1003 - accuracy: 0.9608 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9604 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1017 - accuracy: 0.9601 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9613 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9622 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9622 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9637 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9615 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9627 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9626 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0979 - accuracy: 0.9650 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9625 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9633 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0972 - accuracy: 0.9622 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9635 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9627 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9607 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9633 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9636 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9639 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9626 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9608 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9274595267745953 0.912826899128269 0.9420921544209215 0.855285388798817 0.9274595267745953 0.977820563918928\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.7903 - accuracy: 0.8149 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2691 - accuracy: 0.8870 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2211 - accuracy: 0.9108 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2058 - accuracy: 0.9145 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1880 - accuracy: 0.9230 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1656 - accuracy: 0.9338 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9351 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1500 - accuracy: 0.9397 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1322 - accuracy: 0.9467 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1278 - accuracy: 0.9490 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1236 - accuracy: 0.9510 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1156 - accuracy: 0.9555 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1090 - accuracy: 0.9577 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1057 - accuracy: 0.9580 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0974 - accuracy: 0.9657 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0981 - accuracy: 0.9629 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0941 - accuracy: 0.9657 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0884 - accuracy: 0.9681 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9664 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0884 - accuracy: 0.9667 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0851 - accuracy: 0.9690 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0878 - accuracy: 0.9673 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0837 - accuracy: 0.9709 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0822 - accuracy: 0.9715 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0841 - accuracy: 0.9696 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9700 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9705 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9720 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9705 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9731 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0784 - accuracy: 0.9735 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0793 - accuracy: 0.9731 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0777 - accuracy: 0.9721 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9706 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0794 - accuracy: 0.9731 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0793 - accuracy: 0.9710 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0802 - accuracy: 0.9725 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0797 - accuracy: 0.9729 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0778 - accuracy: 0.9721 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.9738 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9728 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9716 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.9738 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0785 - accuracy: 0.9737 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9748 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9389788293897883 0.925280199252802 0.9526774595267746 0.8782873462334724 0.9389788293897883 0.9821367645302719\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5449 - accuracy: 0.8538 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2539 - accuracy: 0.8948 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2127 - accuracy: 0.9134 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1958 - accuracy: 0.9208 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1820 - accuracy: 0.9265 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1653 - accuracy: 0.9341 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1536 - accuracy: 0.9378 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1459 - accuracy: 0.9411 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1314 - accuracy: 0.9465 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1241 - accuracy: 0.9522 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1203 - accuracy: 0.9545 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1092 - accuracy: 0.9580 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1020 - accuracy: 0.9615 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1009 - accuracy: 0.9601 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9636 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0945 - accuracy: 0.9653 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0933 - accuracy: 0.9668 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.9671 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0881 - accuracy: 0.9688 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0848 - accuracy: 0.9696 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9712 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0822 - accuracy: 0.9715 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0837 - accuracy: 0.9699 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9725 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9712 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9724 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0795 - accuracy: 0.9719 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9713 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0768 - accuracy: 0.9735 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0805 - accuracy: 0.9714 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9718 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0781 - accuracy: 0.9728 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9710 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0756 - accuracy: 0.9745 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0786 - accuracy: 0.9733 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0761 - accuracy: 0.9739 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0781 - accuracy: 0.9738 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9731 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.9739 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0756 - accuracy: 0.9734 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0758 - accuracy: 0.9741 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0759 - accuracy: 0.9730 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9738 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9742 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0766 - accuracy: 0.9738 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9361768368617683 0.912826899128269 0.9595267745952677 0.8733064811032453 0.9361768368617683 0.9809616103373247\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4329 - accuracy: 0.8522 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2439 - accuracy: 0.8962 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2010 - accuracy: 0.9187 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1907 - accuracy: 0.9210 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1743 - accuracy: 0.9276 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1538 - accuracy: 0.9392 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1422 - accuracy: 0.9445 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1347 - accuracy: 0.9468 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1250 - accuracy: 0.9520 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1146 - accuracy: 0.9563 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1112 - accuracy: 0.9575 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1023 - accuracy: 0.9623 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0981 - accuracy: 0.9636 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0972 - accuracy: 0.9620 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0907 - accuracy: 0.9655 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0885 - accuracy: 0.9675 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0852 - accuracy: 0.9687 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0837 - accuracy: 0.9710 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9712 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0786 - accuracy: 0.9726 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0755 - accuracy: 0.9737 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0765 - accuracy: 0.9745 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0744 - accuracy: 0.9730 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9748 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0733 - accuracy: 0.9745 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0748 - accuracy: 0.9743 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9754 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9742 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9757 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9765 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9752 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9773 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0697 - accuracy: 0.9774 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0713 - accuracy: 0.9759 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9759 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9757 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9758 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0708 - accuracy: 0.9766 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0698 - accuracy: 0.9759 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9754 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9768 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9771 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9756 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9769 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9336861768368617 0.9221668742216688 0.9452054794520548 0.8676026361407306 0.9336861768368618 0.981045549922535\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.4275 - accuracy: 0.8522 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2447 - accuracy: 0.8972 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2015 - accuracy: 0.9186 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1883 - accuracy: 0.9227 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1733 - accuracy: 0.9305 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1504 - accuracy: 0.9411 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1408 - accuracy: 0.9434 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1312 - accuracy: 0.9482 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1183 - accuracy: 0.9533 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1137 - accuracy: 0.9551 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1086 - accuracy: 0.9580 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0990 - accuracy: 0.9629 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0958 - accuracy: 0.9654 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9642 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9671 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0845 - accuracy: 0.9699 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0827 - accuracy: 0.9706 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9718 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0783 - accuracy: 0.9738 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0765 - accuracy: 0.9731 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9712 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9748 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0732 - accuracy: 0.9756 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0719 - accuracy: 0.9767 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9752 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9744 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.9766 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0718 - accuracy: 0.9762 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9760 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9748 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0715 - accuracy: 0.9759 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0697 - accuracy: 0.9763 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.9771 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0708 - accuracy: 0.9756 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9767 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0684 - accuracy: 0.9774 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9781 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0688 - accuracy: 0.9766 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0686 - accuracy: 0.9772 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0698 - accuracy: 0.9767 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9766 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0684 - accuracy: 0.9768 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.9768 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0679 - accuracy: 0.9773 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0686 - accuracy: 0.9756 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9277708592777086 0.9072229140722291 0.9483188044831881 0.85626508525583 0.9277708592777085 0.9785227098257003\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4559 - accuracy: 0.8582 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2494 - accuracy: 0.8959 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2093 - accuracy: 0.9137 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1893 - accuracy: 0.9242 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1792 - accuracy: 0.9280 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1544 - accuracy: 0.9377 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1459 - accuracy: 0.9418 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1388 - accuracy: 0.9438 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1262 - accuracy: 0.9523 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9534 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1125 - accuracy: 0.9566 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1043 - accuracy: 0.9607 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0990 - accuracy: 0.9621 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0987 - accuracy: 0.9619 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0900 - accuracy: 0.9661 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.9670 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0888 - accuracy: 0.9689 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0844 - accuracy: 0.9706 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9703 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9722 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9721 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9732 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9745 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9741 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9732 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0732 - accuracy: 0.9754 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9743 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0741 - accuracy: 0.9737 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9735 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9742 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9759 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9747 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9749 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0728 - accuracy: 0.9754 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9745 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9753 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9759 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9751 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.9761 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9774 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9752 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9743 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9759 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0724 - accuracy: 0.9761 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9364881693648817 0.9209215442092155 0.952054794520548 0.8733997254759605 0.9364881693648817 0.9828895068151965\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.5151 - accuracy: 0.8512 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2491 - accuracy: 0.8979 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2127 - accuracy: 0.9109 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1934 - accuracy: 0.9207 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1830 - accuracy: 0.9262 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1594 - accuracy: 0.9381 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1478 - accuracy: 0.9406 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1406 - accuracy: 0.9423 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1272 - accuracy: 0.9515 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1231 - accuracy: 0.9518 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9540 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1095 - accuracy: 0.9580 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1035 - accuracy: 0.9613 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0982 - accuracy: 0.9631 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0948 - accuracy: 0.9661 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0917 - accuracy: 0.9677 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0897 - accuracy: 0.9680 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9703 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0850 - accuracy: 0.9686 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0846 - accuracy: 0.9708 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0828 - accuracy: 0.9710 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9707 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0802 - accuracy: 0.9735 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0788 - accuracy: 0.9716 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9717 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9719 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.9738 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0775 - accuracy: 0.9740 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9735 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0785 - accuracy: 0.9726 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.9740 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0766 - accuracy: 0.9735 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0750 - accuracy: 0.9748 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9737 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9748 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0755 - accuracy: 0.9754 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9743 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9744 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9756 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0764 - accuracy: 0.9740 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9754 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0769 - accuracy: 0.9744 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.9752 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9744 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.9737 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9343088418430884 0.9227895392278954 0.9458281444582815 0.8688482967812773 0.9343088418430885 0.9831391931564231\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.4231 - accuracy: 0.8587 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2461 - accuracy: 0.8984 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2083 - accuracy: 0.9127 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1896 - accuracy: 0.9227 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1791 - accuracy: 0.9263 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1559 - accuracy: 0.9376 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1495 - accuracy: 0.9402 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1407 - accuracy: 0.9429 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1259 - accuracy: 0.9513 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1191 - accuracy: 0.9551 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1136 - accuracy: 0.9569 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1037 - accuracy: 0.9617 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9606 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0947 - accuracy: 0.9647 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0892 - accuracy: 0.9673 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9690 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9678 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.9710 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9714 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0783 - accuracy: 0.9722 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0764 - accuracy: 0.9750 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0756 - accuracy: 0.9746 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9737 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.9745 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9744 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9752 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9766 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.9752 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9752 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0715 - accuracy: 0.9765 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9766 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9749 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.9777 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0703 - accuracy: 0.9770 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9760 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.9779 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9744 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.9752 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0694 - accuracy: 0.9763 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9764 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9765 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9758 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0703 - accuracy: 0.9759 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0719 - accuracy: 0.9754 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0704 - accuracy: 0.9752 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9361768368617683 0.9196762141967622 0.9526774595267746 0.8728290945142074 0.9361768368617684 0.9823785027814439\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7123 - accuracy: 0.8390 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2555 - accuracy: 0.8953 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2144 - accuracy: 0.9123 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1993 - accuracy: 0.9214 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1813 - accuracy: 0.9268 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1611 - accuracy: 0.9360 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1518 - accuracy: 0.9394 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1448 - accuracy: 0.9425 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1276 - accuracy: 0.9513 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1238 - accuracy: 0.9521 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1153 - accuracy: 0.9568 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1056 - accuracy: 0.9596 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1037 - accuracy: 0.9607 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0997 - accuracy: 0.9633 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0937 - accuracy: 0.9657 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0926 - accuracy: 0.9657 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9671 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9668 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0870 - accuracy: 0.9698 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9703 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0807 - accuracy: 0.9742 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0770 - accuracy: 0.9724 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0788 - accuracy: 0.9735 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0764 - accuracy: 0.9742 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0750 - accuracy: 0.9732 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9731 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9745 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9728 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.9753 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9747 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0732 - accuracy: 0.9745 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0748 - accuracy: 0.9730 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0747 - accuracy: 0.9748 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0724 - accuracy: 0.9756 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0723 - accuracy: 0.9754 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9733 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9742 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9747 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9748 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.9763 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9744 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0709 - accuracy: 0.9757 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9756 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0724 - accuracy: 0.9755 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9762 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9324408468244084 0.912826899128269 0.952054794520548 0.8655479146339741 0.9324408468244085 0.9811577924625743\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.5170 - accuracy: 0.8463 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2551 - accuracy: 0.8936 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2179 - accuracy: 0.9112 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2001 - accuracy: 0.9197 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1870 - accuracy: 0.9218 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1652 - accuracy: 0.9331 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1556 - accuracy: 0.9370 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1456 - accuracy: 0.9418 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9476 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1284 - accuracy: 0.9489 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1238 - accuracy: 0.9499 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1149 - accuracy: 0.9560 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1109 - accuracy: 0.9566 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1064 - accuracy: 0.9609 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1031 - accuracy: 0.9611 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9631 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0977 - accuracy: 0.9623 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0938 - accuracy: 0.9673 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0925 - accuracy: 0.9664 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0890 - accuracy: 0.9675 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9686 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9684 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9673 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.9702 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9700 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9696 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9695 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0838 - accuracy: 0.9707 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0833 - accuracy: 0.9708 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0846 - accuracy: 0.9707 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.9710 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0819 - accuracy: 0.9718 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9705 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9716 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9714 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9703 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0829 - accuracy: 0.9709 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9739 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0812 - accuracy: 0.9721 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0837 - accuracy: 0.9687 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9697 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9707 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0835 - accuracy: 0.9700 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9718 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0835 - accuracy: 0.9708 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9311955168119551 0.9265255292652553 0.935865504358655 0.8624286514841383 0.9311955168119552 0.9817440125680628\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.5410 - accuracy: 0.8600 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2435 - accuracy: 0.8971 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2061 - accuracy: 0.9145 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1862 - accuracy: 0.9228 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1741 - accuracy: 0.9302 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1519 - accuracy: 0.9394 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1430 - accuracy: 0.9415 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1372 - accuracy: 0.9442 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1222 - accuracy: 0.9529 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1161 - accuracy: 0.9543 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1100 - accuracy: 0.9573 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1023 - accuracy: 0.9614 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0965 - accuracy: 0.9650 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0932 - accuracy: 0.9646 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0883 - accuracy: 0.9695 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9668 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0849 - accuracy: 0.9686 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9699 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9706 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9711 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0773 - accuracy: 0.9725 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9735 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9724 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9741 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0741 - accuracy: 0.9737 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9752 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0736 - accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0723 - accuracy: 0.9754 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9759 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9745 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9773 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0704 - accuracy: 0.9761 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9765 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0713 - accuracy: 0.9758 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9755 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9755 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0686 - accuracy: 0.9776 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9756 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0723 - accuracy: 0.9737 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9754 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0687 - accuracy: 0.9761 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9743 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9764 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0691 - accuracy: 0.9769 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0703 - accuracy: 0.9762 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9336861768368617 0.9178082191780822 0.9495641344956414 0.8678100304181736 0.9336861768368618 0.9801679644669972\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 1.3837 - accuracy: 0.5247 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6975 - accuracy: 0.5300 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5448 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6551 - accuracy: 0.5774 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6481 - accuracy: 0.5942 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5338 - accuracy: 0.7189 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4466 - accuracy: 0.7792 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3922 - accuracy: 0.8157 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3464 - accuracy: 0.8416 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8515 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3204 - accuracy: 0.8586 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2976 - accuracy: 0.8726 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2929 - accuracy: 0.8748 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2850 - accuracy: 0.8791 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2731 - accuracy: 0.8844 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2685 - accuracy: 0.8872 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2705 - accuracy: 0.8871 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2586 - accuracy: 0.8915 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2562 - accuracy: 0.8924 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2524 - accuracy: 0.8919 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2458 - accuracy: 0.8953 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2468 - accuracy: 0.8972 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2428 - accuracy: 0.8976 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2438 - accuracy: 0.8996 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2390 - accuracy: 0.8965 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2413 - accuracy: 0.8999 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2360 - accuracy: 0.8993 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2388 - accuracy: 0.8987 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2403 - accuracy: 0.8990 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2356 - accuracy: 0.9018 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2338 - accuracy: 0.9046 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2338 - accuracy: 0.9027 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2313 - accuracy: 0.9050 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2333 - accuracy: 0.9070 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2303 - accuracy: 0.9054 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2312 - accuracy: 0.9032 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2332 - accuracy: 0.9021 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2328 - accuracy: 0.9056 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2330 - accuracy: 0.9044 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9036 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2316 - accuracy: 0.9037 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2286 - accuracy: 0.9058 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2309 - accuracy: 0.9026 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9023 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2325 - accuracy: 0.9038 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9131382316313823 0.9078455790784558 0.9184308841843088 0.8263227587485527 0.9131382316313823 0.9708975836255387\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.6675 - accuracy: 0.8374 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2581 - accuracy: 0.8931 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2151 - accuracy: 0.9102 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2006 - accuracy: 0.9167 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1864 - accuracy: 0.9220 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1684 - accuracy: 0.9316 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1590 - accuracy: 0.9376 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9378 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1386 - accuracy: 0.9438 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1278 - accuracy: 0.9499 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1260 - accuracy: 0.9492 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1166 - accuracy: 0.9536 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1131 - accuracy: 0.9564 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1104 - accuracy: 0.9563 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9599 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1004 - accuracy: 0.9622 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0976 - accuracy: 0.9626 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9651 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.9651 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0923 - accuracy: 0.9664 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.9661 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9675 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0855 - accuracy: 0.9692 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9695 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0855 - accuracy: 0.9688 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0851 - accuracy: 0.9682 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0845 - accuracy: 0.9708 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9694 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0812 - accuracy: 0.9701 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9721 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9715 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0817 - accuracy: 0.9704 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9717 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9706 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9706 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9698 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9701 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0814 - accuracy: 0.9731 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9707 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0799 - accuracy: 0.9710 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0792 - accuracy: 0.9717 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9720 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9700 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0801 - accuracy: 0.9703 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0786 - accuracy: 0.9738 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9343088418430884 0.9190535491905355 0.9495641344956414 0.8690222624571889 0.9343088418430885 0.979894627711462\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6192 - accuracy: 0.8446 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2564 - accuracy: 0.8927 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9082 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9164 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1837 - accuracy: 0.9212 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1620 - accuracy: 0.9353 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1539 - accuracy: 0.9369 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9402 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1323 - accuracy: 0.9491 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9508 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9552 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1093 - accuracy: 0.9564 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9591 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1017 - accuracy: 0.9592 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0959 - accuracy: 0.9650 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0944 - accuracy: 0.9643 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9662 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.9661 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9664 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9686 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0803 - accuracy: 0.9714 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9702 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9703 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9696 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0783 - accuracy: 0.9715 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0789 - accuracy: 0.9715 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9724 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9721 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9707 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0769 - accuracy: 0.9731 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9738 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0760 - accuracy: 0.9726 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0732 - accuracy: 0.9745 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9747 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9723 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9742 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0747 - accuracy: 0.9742 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9721 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0736 - accuracy: 0.9729 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9737 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9731 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0738 - accuracy: 0.9728 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9741 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0750 - accuracy: 0.9740 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0759 - accuracy: 0.9721 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9293275217932753 0.912826899128269 0.9458281444582815 0.8591229988116289 0.9293275217932753 0.9796191585415216\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 1.1463 - accuracy: 0.6449 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3117 - accuracy: 0.8635 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2476 - accuracy: 0.8972 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2264 - accuracy: 0.9062 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9151 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1860 - accuracy: 0.9242 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9273 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9300 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9380 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1521 - accuracy: 0.9380 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1421 - accuracy: 0.9450 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1382 - accuracy: 0.9451 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1309 - accuracy: 0.9492 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1254 - accuracy: 0.9509 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1214 - accuracy: 0.9527 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1202 - accuracy: 0.9526 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1150 - accuracy: 0.9558 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9568 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1093 - accuracy: 0.9577 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1068 - accuracy: 0.9604 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1049 - accuracy: 0.9586 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1049 - accuracy: 0.9604 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1037 - accuracy: 0.9598 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9626 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9613 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1025 - accuracy: 0.9616 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9623 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9613 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9617 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0985 - accuracy: 0.9659 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9618 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9639 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9610 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9640 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9633 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9619 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9640 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0991 - accuracy: 0.9625 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0973 - accuracy: 0.9641 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0975 - accuracy: 0.9627 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9643 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9631 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9635 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9623 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9618 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.924346201743462 0.9041095890410958 0.9445828144458281 0.8493883725085629 0.924346201743462 0.9785793157353573\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 1.1753 - accuracy: 0.6342 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3402 - accuracy: 0.8530 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2739 - accuracy: 0.8887 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2487 - accuracy: 0.8960 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2330 - accuracy: 0.9032 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2072 - accuracy: 0.9145 - lr: 0.0360\n"
          ]
        }
      ],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',BACC_collection_test, '\\n',Sn_collection_test, '\\n',Sp_collection_test, '\\n',MCC_collection_test,'\\n', AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVsxPkQe5DsT"
      },
      "source": [
        "### 480 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW4FNivjn0Y7"
      },
      "source": [
        "#### defined function for model development and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3svmF6Xrn0Y8"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, X_valid, y_train, y_valid, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(480,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "  # set checkpoint and save the best model\n",
        "  mc = ModelCheckpoint('best_model_grid_480.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lr , early_stop, mc]\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  saved_model = load_model('best_model_grid_480.h5')\n",
        "  return saved_model\n",
        "\n",
        "  # import gc\n",
        "  # del model\n",
        "  # del saved_model\n",
        "  # import torch\n",
        "  # import gc\n",
        "  # torch.cuda.memory_reserved()\n",
        "  # gc.collect()\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ158sS6YJim"
      },
      "source": [
        "#### 5 Fold CV for optimal hyperparrameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHxXxO2KYJiw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znl9OFOUYJiw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "random_num = 1\n",
        "X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2fI7AmUYJiw",
        "outputId": "9e0b9f63-5286-4569-872a-93d6eaeb3b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30 30 30 30\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [128, 32, 64, 64, 32, 16, 16, 16, 16, 16, 64, 64, 64, 16, 128, 16, 32, 32, 16, 32, 32, 64, 32, 32, 16, 16, 32, 32, 16, 32]\n",
        "dense_node = [8192, 4096, 8192, 8192, 4096, 8192, 8192, 2048, 8192, 2048, 2048, 2048, 1024, 2048, 1024, 2048, 512, 1024, 512, 32, 32, 64, 64, 128, 128, 256, 256, 512, 512, 512]\n",
        "kernel_size = [9, 6, 6, 9, 9, 12, 6, 12, 9, 9, 6, 12, 12, 6, 12, 9, 6, 12, 12, 6, 12, 6, 9, 9, 12, 6, 9, 6, 12, 6]\n",
        "stride_size = [8, 1, 4, 8, 4, 2, 2, 2, 2, 2, 8, 4, 4, 1, 4, 1, 4, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 4, 1, 2]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrM4EE-DYJix"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-7sruhYYJix",
        "outputId": "6147a7d8-1f02-421f-ba1f-d6d627a529d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7116 - accuracy: 0.6238 - val_loss: 0.6630 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 40/241 [===>..........................] - ETA: 0s - loss: 0.6449 - accuracy: 0.6555"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6630 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.6229 - val_loss: 0.6626 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6633 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6629 - accuracy: 0.6229 - val_loss: 0.6632 - val_accuracy: 0.6232 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6631 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6629 - accuracy: 0.6229 - val_loss: 0.6626 - val_accuracy: 0.6232 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6628 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6629 - accuracy: 0.6229 - val_loss: 0.6625 - val_accuracy: 0.6232 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6488 - accuracy: 0.6394 - val_loss: 0.5935 - val_accuracy: 0.7073 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.7867 - val_loss: 0.4150 - val_accuracy: 0.8470 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.8254 - val_loss: 0.3555 - val_accuracy: 0.8610 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3838 - accuracy: 0.8378 - val_loss: 0.2732 - val_accuracy: 0.8957 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8505 - val_loss: 0.2518 - val_accuracy: 0.8968 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8545 - val_loss: 0.2563 - val_accuracy: 0.8926 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.8593 - val_loss: 0.2877 - val_accuracy: 0.8735 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.8639 - val_loss: 0.2234 - val_accuracy: 0.9077 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.8605 - val_loss: 0.2436 - val_accuracy: 0.8980 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2922 - accuracy: 0.8621 - val_loss: 0.2268 - val_accuracy: 0.9054 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.8665 - val_loss: 0.2182 - val_accuracy: 0.9097 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2784 - accuracy: 0.8697 - val_loss: 0.2427 - val_accuracy: 0.8906 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2885 - accuracy: 0.8623 - val_loss: 0.2356 - val_accuracy: 0.8918 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2775 - accuracy: 0.8709 - val_loss: 0.2205 - val_accuracy: 0.9070 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2827 - accuracy: 0.8653 - val_loss: 0.2127 - val_accuracy: 0.9132 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2748 - accuracy: 0.8696 - val_loss: 0.2161 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2799 - accuracy: 0.8661 - val_loss: 0.2172 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2695 - accuracy: 0.8757 - val_loss: 0.2248 - val_accuracy: 0.9004 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.8656 - val_loss: 0.2112 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.8690 - val_loss: 0.2151 - val_accuracy: 0.9109 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2715 - accuracy: 0.8739 - val_loss: 0.2087 - val_accuracy: 0.9163 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.8654 - val_loss: 0.2119 - val_accuracy: 0.9136 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2703 - accuracy: 0.8695 - val_loss: 0.2120 - val_accuracy: 0.9144 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.8693 - val_loss: 0.2131 - val_accuracy: 0.9120 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2706 - accuracy: 0.8710 - val_loss: 0.2146 - val_accuracy: 0.9109 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.8752 - val_loss: 0.2111 - val_accuracy: 0.9144 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.8730 - val_loss: 0.2132 - val_accuracy: 0.9116 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2649 - accuracy: 0.8718 - val_loss: 0.2121 - val_accuracy: 0.9132 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2764 - accuracy: 0.8662 - val_loss: 0.2108 - val_accuracy: 0.9144 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.8690 - val_loss: 0.2119 - val_accuracy: 0.9136 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.8705 - val_loss: 0.2109 - val_accuracy: 0.9136 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2700 - accuracy: 0.8726 - val_loss: 0.2104 - val_accuracy: 0.9140 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.8715 - val_loss: 0.2112 - val_accuracy: 0.9132 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.8767 - val_loss: 0.2109 - val_accuracy: 0.9144 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2645 - accuracy: 0.8761 - val_loss: 0.2114 - val_accuracy: 0.9128 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2646 - accuracy: 0.8765 - val_loss: 0.2107 - val_accuracy: 0.9140 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.8710 - val_loss: 0.2112 - val_accuracy: 0.9136 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.8770 - val_loss: 0.2108 - val_accuracy: 0.9132 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.2680 - accuracy: 0.8727 - val_loss: 0.2110 - val_accuracy: 0.9132 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2673 - accuracy: 0.8709 - val_loss: 0.2111 - val_accuracy: 0.9132 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2687 - accuracy: 0.8691 - val_loss: 0.2105 - val_accuracy: 0.9140 - lr: 1.6927e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9190661478599221 0.931161647203442 0.8981972428419936 0.8264851473683413 0.9146794450227178 0.9754937393311829\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 0.9358 - accuracy: 0.6248 - val_loss: 0.6610 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.6671 - accuracy: 0.6185"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6344 - accuracy: 0.6572 - val_loss: 0.6613 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6615 - accuracy: 0.6263 - val_loss: 0.6618 - val_accuracy: 0.6261 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.6263 - val_loss: 0.6614 - val_accuracy: 0.6261 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.6263 - val_loss: 0.6611 - val_accuracy: 0.6261 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.6263 - val_loss: 0.6699 - val_accuracy: 0.6261 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5168 - accuracy: 0.7070 - val_loss: 0.3806 - val_accuracy: 0.8572 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4388 - accuracy: 0.7834 - val_loss: 0.3252 - val_accuracy: 0.8782 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.4129 - accuracy: 0.7984 - val_loss: 0.3073 - val_accuracy: 0.8953 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8164 - val_loss: 0.2978 - val_accuracy: 0.8930 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3938 - accuracy: 0.8160 - val_loss: 0.3066 - val_accuracy: 0.8938 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3908 - accuracy: 0.8147 - val_loss: 0.3026 - val_accuracy: 0.8875 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3860 - accuracy: 0.8238 - val_loss: 0.2954 - val_accuracy: 0.8992 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3889 - accuracy: 0.8174 - val_loss: 0.2869 - val_accuracy: 0.9012 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3774 - accuracy: 0.8289 - val_loss: 0.2857 - val_accuracy: 0.9027 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8326 - val_loss: 0.2797 - val_accuracy: 0.9027 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3684 - accuracy: 0.8318 - val_loss: 0.2907 - val_accuracy: 0.9000 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3665 - accuracy: 0.8335 - val_loss: 0.2783 - val_accuracy: 0.9051 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3695 - accuracy: 0.8299 - val_loss: 0.2759 - val_accuracy: 0.9035 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3739 - accuracy: 0.8252 - val_loss: 0.2775 - val_accuracy: 0.9058 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8277 - val_loss: 0.2759 - val_accuracy: 0.9066 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3678 - accuracy: 0.8316 - val_loss: 0.2759 - val_accuracy: 0.9054 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8363 - val_loss: 0.2741 - val_accuracy: 0.9051 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3668 - accuracy: 0.8334 - val_loss: 0.2746 - val_accuracy: 0.9058 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3658 - accuracy: 0.8339 - val_loss: 0.2739 - val_accuracy: 0.9058 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3666 - accuracy: 0.8312 - val_loss: 0.2769 - val_accuracy: 0.9051 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3679 - accuracy: 0.8316 - val_loss: 0.2765 - val_accuracy: 0.9062 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3686 - accuracy: 0.8329 - val_loss: 0.2742 - val_accuracy: 0.9058 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8356 - val_loss: 0.2753 - val_accuracy: 0.9070 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8347 - val_loss: 0.2745 - val_accuracy: 0.9062 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8309 - val_loss: 0.2728 - val_accuracy: 0.9062 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3608 - accuracy: 0.8379 - val_loss: 0.2753 - val_accuracy: 0.9066 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3658 - accuracy: 0.8333 - val_loss: 0.2738 - val_accuracy: 0.9062 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8299 - val_loss: 0.2741 - val_accuracy: 0.9058 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3676 - accuracy: 0.8285 - val_loss: 0.2742 - val_accuracy: 0.9066 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3626 - accuracy: 0.8318 - val_loss: 0.2735 - val_accuracy: 0.9066 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8346 - val_loss: 0.2735 - val_accuracy: 0.9070 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8316 - val_loss: 0.2734 - val_accuracy: 0.9066 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3686 - accuracy: 0.8316 - val_loss: 0.2738 - val_accuracy: 0.9054 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3671 - accuracy: 0.8329 - val_loss: 0.2740 - val_accuracy: 0.9062 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3547 - accuracy: 0.8417 - val_loss: 0.2730 - val_accuracy: 0.9062 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8344 - val_loss: 0.2730 - val_accuracy: 0.9074 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8343 - val_loss: 0.2735 - val_accuracy: 0.9062 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3593 - accuracy: 0.8385 - val_loss: 0.2733 - val_accuracy: 0.9062 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3653 - accuracy: 0.8324 - val_loss: 0.2734 - val_accuracy: 0.9066 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3663 - accuracy: 0.8333 - val_loss: 0.2736 - val_accuracy: 0.9058 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8272 - val_loss: 0.2734 - val_accuracy: 0.9062 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3622 - accuracy: 0.8364 - val_loss: 0.2734 - val_accuracy: 0.9066 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3729 - accuracy: 0.8278 - val_loss: 0.2735 - val_accuracy: 0.9058 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3602 - accuracy: 0.8374 - val_loss: 0.2736 - val_accuracy: 0.9058 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3621 - accuracy: 0.8372 - val_loss: 0.2736 - val_accuracy: 0.9058 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3622 - accuracy: 0.8344 - val_loss: 0.2735 - val_accuracy: 0.9062 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3602 - accuracy: 0.8373 - val_loss: 0.2734 - val_accuracy: 0.9066 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3661 - accuracy: 0.8298 - val_loss: 0.2733 - val_accuracy: 0.9062 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3605 - accuracy: 0.8363 - val_loss: 0.2734 - val_accuracy: 0.9066 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3698 - accuracy: 0.8286 - val_loss: 0.2734 - val_accuracy: 0.9062 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3569 - accuracy: 0.8396 - val_loss: 0.2734 - val_accuracy: 0.9062 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.8337 - val_loss: 0.2734 - val_accuracy: 0.9062 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3622 - accuracy: 0.8368 - val_loss: 0.2734 - val_accuracy: 0.9062 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3727 - accuracy: 0.8264 - val_loss: 0.2735 - val_accuracy: 0.9062 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3688 - accuracy: 0.8286 - val_loss: 0.2735 - val_accuracy: 0.9062 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8334 - val_loss: 0.2734 - val_accuracy: 0.9062 - lr: 3.6562e-06\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9015181004281821 0.9234149403640929 0.8657786885245902 0.7906274240187188 0.8945968144443415 0.956157445998374\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 5ms/step - loss: 2.5825 - accuracy: 0.6153 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 42/241 [====>.........................] - ETA: 0s - loss: 0.6691 - accuracy: 0.6109"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6627 - accuracy: 0.6241 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6624 - accuracy: 0.6241 - val_loss: 0.6624 - val_accuracy: 0.6241 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6625 - accuracy: 0.6241 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.6241 - val_loss: 0.6628 - val_accuracy: 0.6241 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.6241 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6623 - accuracy: 0.6241 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6241 - val_loss: 0.6626 - val_accuracy: 0.6241 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.6241 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0028\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.628649279875438 1.0 0.0 nan 0.5 0.5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-412af7b487d6>:67: RuntimeWarning: invalid value encountered in divide\n",
            "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 2s 5ms/step - loss: 1.2988 - accuracy: 0.6216 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.6549 - accuracy: 0.6395"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6624 - accuracy: 0.6244 - val_loss: 0.6625 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6622 - accuracy: 0.6244 - val_loss: 0.6630 - val_accuracy: 0.6241 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6624 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6623 - accuracy: 0.6242 - val_loss: 0.6623 - val_accuracy: 0.6241 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6241 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6242 - val_loss: 0.6625 - val_accuracy: 0.6241 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6623 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6244 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6618 - accuracy: 0.6245 - val_loss: 0.6623 - val_accuracy: 0.6241 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6617 - accuracy: 0.6245 - val_loss: 0.6621 - val_accuracy: 0.6241 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6620 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6244 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6245 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6244 - val_loss: 0.6620 - val_accuracy: 0.6241 - lr: 0.0028\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.6278707668353445 1.0 0.0 nan 0.5 0.5\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-412af7b487d6>:67: RuntimeWarning: invalid value encountered in divide\n",
            "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 2s 5ms/step - loss: 1.1916 - accuracy: 0.6254 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.1000\n",
            "Epoch 2/200\n",
            " 43/241 [====>.........................] - ETA: 0s - loss: 0.6560 - accuracy: 0.6374"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6612 - accuracy: 0.6274 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.6272 - val_loss: 0.6608 - val_accuracy: 0.6272 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6607 - accuracy: 0.6275 - val_loss: 0.6610 - val_accuracy: 0.6272 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6608 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.6275 - val_loss: 0.6608 - val_accuracy: 0.6272 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6607 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6606 - accuracy: 0.6275 - val_loss: 0.6606 - val_accuracy: 0.6272 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.6275 - val_loss: 0.6606 - val_accuracy: 0.6272 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.6275 - val_loss: 0.6605 - val_accuracy: 0.6272 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6606 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6603 - accuracy: 0.6275 - val_loss: 0.6605 - val_accuracy: 0.6272 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6603 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6603 - accuracy: 0.6275 - val_loss: 0.6604 - val_accuracy: 0.6272 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6602 - accuracy: 0.6275 - val_loss: 0.6602 - val_accuracy: 0.6272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.6598 - accuracy: 0.6275 - val_loss: 0.6592 - val_accuracy: 0.6272 - lr: 0.0028\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.6154145581938497 1.0 0.0 nan 0.5 0.5012022831857048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-412af7b487d6>:67: RuntimeWarning: invalid value encountered in divide\n",
            "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-cb85ac7edf1f>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0mfinal_Sn_collection_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSn_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'±'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSn_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0mfinal_Sp_collection_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSp_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'±'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSp_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0mfinal_MCC_collection_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMCC_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'±'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMCC_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0mfinal_AUC_collection_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUC_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'±'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUC_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/statistics.py\u001b[0m in \u001b[0;36mstdev\u001b[0;34m(data, xbar)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;31m# remain because there are two rounding steps.  The first occurs in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;31m# the _convert() step for variance(), the second occurs in math.sqrt().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/statistics.py\u001b[0m in \u001b[0;36mvariance\u001b[0;34m(data, xbar)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variance requires at least two data points'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/statistics.py\u001b[0m in \u001b[0;36m_ss\u001b[0;34m(data, c)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0mmean_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_integer_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m     \u001b[0mpartials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_exact_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot convert NaN to integer ratio"
          ]
        }
      ],
      "source": [
        "# 5-Fold CV\n",
        "final_ACC_collection_cv = []\n",
        "final_BACC_collection_cv = []\n",
        "final_Sn_collection_cv = []\n",
        "final_Sp_collection_cv = []\n",
        "final_MCC_collection_cv = []\n",
        "final_AUC_collection_cv = []\n",
        "\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "\n",
        "# split dataset\n",
        "# for i in range(len(CNN_channel)-15):\n",
        "for a in range(12):\n",
        "  i = a+20\n",
        "  # collect the value in cross validation\n",
        "  ACC_collection_cv = []\n",
        "  BACC_collection_cv = []\n",
        "  Sn_collection_cv = []\n",
        "  Sp_collection_cv = []\n",
        "  MCC_collection_cv = []\n",
        "  AUC_collection_cv = []\n",
        "\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(X_train_whole, y_train_whole):\n",
        "      X_train, X_valid = X[train_ix], X[test_ix]\n",
        "      y_train, y_valid = y[train_ix], y[test_ix]\n",
        "      X_train_only, X_train_indicator, y_train_only, y_train_indicator = train_test_split( X_train, y_train, test_size=0.25, random_state=random_num,shuffle=True, stratify = y_train)\n",
        "\n",
        "      # train the model\n",
        "      saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i])\n",
        "\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_valid, y_valid)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "  final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "  final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "  final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "  final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-5-dTV8YJix",
        "outputId": "60097266-48dd-4d96-fbb7-0c60f6183c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.929±0.006', '0.921±0.006', '0.928±0.006', '0.928±0.005', '0.928±0.008', '0.924±0.008', '0.929±0.007', '0.922±0.012', '0.926±0.006', '0.925±0.006', '0.93±0.005', '0.928±0.007', '0.927±0.008', '0.923±0.004', '0.928±0.008', '0.919±0.013', '0.929±0.008', '0.906±0.033'] \n",
            " ['0.926±0.009', '0.915±0.005', '0.923±0.009', '0.923±0.007', '0.925±0.011', '0.92±0.008', '0.925±0.008', '0.918±0.016', '0.922±0.006', '0.919±0.008', '0.927±0.006', '0.924±0.008', '0.922±0.009', '0.917±0.006', '0.923±0.01', '0.913±0.015', '0.925±0.01', '0.894±0.045'] \n",
            " ['0.938±0.003', '0.94±0.012', '0.942±0.013', '0.945±0.01', '0.938±0.011', '0.938±0.011', '0.94±0.006', '0.937±0.004', '0.939±0.009', '0.942±0.005', '0.94±0.011', '0.941±0.005', '0.943±0.01', '0.943±0.009', '0.943±0.008', '0.937±0.012', '0.942±0.005', '0.942±0.006'] \n",
            " ['0.915±0.017', '0.889±0.012', '0.904±0.026', '0.901±0.018', '0.912±0.025', '0.901±0.013', '0.91±0.011', '0.899±0.028', '0.906±0.01', '0.896±0.017', '0.913±0.016', '0.906±0.012', '0.901±0.019', '0.89±0.017', '0.904±0.018', '0.89±0.022', '0.908±0.018', '0.846±0.091'] \n",
            " ['0.85±0.014', '0.831±0.013', '0.846±0.013', '0.847±0.011', '0.848±0.018', '0.839±0.017', '0.849±0.015', '0.834±0.027', '0.843±0.013', '0.84±0.013', '0.852±0.011', '0.846±0.014', '0.844±0.017', '0.836±0.01', '0.846±0.018', '0.827±0.029', '0.849±0.018', '0.799±0.072'] \n",
            " ['0.981±0.003', '0.976±0.003', '0.981±0.004', '0.981±0.003', '0.98±0.004', '0.978±0.004', '0.98±0.003', '0.977±0.007', '0.979±0.003', '0.978±0.004', '0.98±0.003', '0.981±0.004', '0.98±0.004', '0.977±0.003', '0.98±0.004', '0.973±0.008', '0.98±0.004', '0.964±0.028']\n"
          ]
        }
      ],
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbOjoBbjUg_U",
        "outputId": "781bbcf5-e0cf-4e7d-c810-2c0beaaf8d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.919±0.007', '0.683±0.133'] \n",
            " ['0.912±0.008', '0.582±0.184'] \n",
            " ['0.94±0.006', '0.989±0.024'] \n",
            " ['0.883±0.012', '0.175±0.392'] \n",
            " ['0.826±0.015'] \n",
            " ['0.976±0.003']\n"
          ]
        }
      ],
      "source": [
        "# there is an bad initialization of parameters\n",
        "# since the i = 18; the rest hyperparameters are rerunned\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "xiCuPi33aNTF",
        "outputId": "cc650d0b-ae8e-4ccd-c943-569257012f82"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7d12dff613b2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# since the i = 18; the rest hyperparameters are rerunned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# performance in test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_ACC_collection_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_BACC_collection_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_Sn_collection_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_Sp_collection_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_MCC_collection_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_AUC_collection_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'final_ACC_collection_test' is not defined"
          ]
        }
      ],
      "source": [
        "# there is an bad initialization of parameters\n",
        "# since the i = 18; the rest hyperparameters are rerunned\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4jT6DS3YTTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHLPytdEYTcw"
      },
      "source": [
        "### final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffef1dd-b805-44c1-cf44-7f743f1b0a7c",
        "id": "0t1RfvycYTcx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5 5 5\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [128,64,64,32,16,64,128,32,32]\n",
        "dense_node = [8192,8192,8192,4096,8192,2048,1024,512,512]\n",
        "kernel_size = [9,6,9,9,6,12,12,6,6]\n",
        "stride_size = [8,4,8,4,2,4,4,4,4]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgFeY-vlYTcx"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(480,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "JINgDJqAYTcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVkB0IvMYTcy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t12_35M_UR50D_unified_480_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "ySmVvsWwYTcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVOZmm1MYTcy"
      },
      "outputs": [],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',BACC_collection_test, '\\n',Sn_collection_test, '\\n',Sp_collection_test, '\\n',MCC_collection_test,'\\n', AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Borpedo25DsU"
      },
      "source": [
        "### 640 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjTN9KSDoVxJ"
      },
      "source": [
        "#### defined function for model development and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9H1wmnAoVxJ"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, X_valid, y_train, y_valid, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(640,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "  # set checkpoint and save the best model\n",
        "  mc = ModelCheckpoint('best_model_grid_640.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lr , early_stop, mc]\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  saved_model = load_model('best_model_grid_640.h5')\n",
        "  return saved_model\n",
        "\n",
        "  # import gc\n",
        "  # del model\n",
        "  # del saved_model\n",
        "  # import torch\n",
        "  # import gc\n",
        "  # torch.cuda.memory_reserved()\n",
        "  # gc.collect()\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM9mOI27cXie"
      },
      "source": [
        "#### 5 Fold CV for optimal hyperparrameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkKRTt6DcXif"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQtVSMNncXif"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "random_num = 1\n",
        "X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E_ZbFCbcXif",
        "outputId": "69f07346-06a9-4c00-9ac6-b652c04cef69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34 34 34 34\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [64, 64, 64, 32, 64, 16, 128, 64, 32, 32, 32, 64, 32, 16, 128, 16, 128, 64, 64, 64, 16, 64, 64, 16, 32, 128, 32, 16, 32, 64, 32, 64, 64, 64]\n",
        "dense_node = [8192, 2048, 8192, 8192, 4096, 2048, 4096, 2048, 2048, 4096, 512, 1024, 4096, 2048, 4096, 1024, 512, 512, 1024, 512, 128, 1024, 512, 32, 32, 64, 64, 128, 128, 256, 256, 512, 512, 512]\n",
        "kernel_size = [12, 12, 6, 9, 12, 12, 6, 9, 9, 9, 9, 9, 12, 9, 9, 12, 9, 9, 9, 12, 9, 6, 9, 12, 9, 12, 9, 9, 9, 9, 6, 9, 12, 9]\n",
        "stride_size = [2, 4, 4, 2, 2, 2, 4, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGsZFCROcXig"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lB1nb7LcXig",
        "outputId": "2f8aa763-14f7-4b47-a41e-63c0b1c1dccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.0890 - accuracy: 0.7200"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 16s 14ms/step - loss: 1.0890 - accuracy: 0.7200 - val_loss: 0.3870 - val_accuracy: 0.8400 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.3469 - accuracy: 0.8527 - val_loss: 0.2438 - val_accuracy: 0.8930 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.2388 - accuracy: 0.8994 - val_loss: 0.2236 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2201 - accuracy: 0.9079 - val_loss: 0.2162 - val_accuracy: 0.9089 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2094 - accuracy: 0.9123 - val_loss: 0.2003 - val_accuracy: 0.9081 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 4s 16ms/step - loss: 0.1876 - accuracy: 0.9203 - val_loss: 0.2203 - val_accuracy: 0.9105 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1751 - accuracy: 0.9231 - val_loss: 0.1898 - val_accuracy: 0.9175 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1694 - accuracy: 0.9285 - val_loss: 0.1936 - val_accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1561 - accuracy: 0.9345 - val_loss: 0.1893 - val_accuracy: 0.9257 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1507 - accuracy: 0.9377 - val_loss: 0.1804 - val_accuracy: 0.9260 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1463 - accuracy: 0.9390 - val_loss: 0.1983 - val_accuracy: 0.9218 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1349 - accuracy: 0.9439 - val_loss: 0.1742 - val_accuracy: 0.9284 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1308 - accuracy: 0.9463 - val_loss: 0.1732 - val_accuracy: 0.9299 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1263 - accuracy: 0.9463 - val_loss: 0.1766 - val_accuracy: 0.9295 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1226 - accuracy: 0.9513 - val_loss: 0.1766 - val_accuracy: 0.9311 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1168 - accuracy: 0.9537 - val_loss: 0.1758 - val_accuracy: 0.9303 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1158 - accuracy: 0.9543 - val_loss: 0.1785 - val_accuracy: 0.9299 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1099 - accuracy: 0.9574 - val_loss: 0.1769 - val_accuracy: 0.9288 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1081 - accuracy: 0.9567 - val_loss: 0.1751 - val_accuracy: 0.9311 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1098 - accuracy: 0.9559 - val_loss: 0.1734 - val_accuracy: 0.9342 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1062 - accuracy: 0.9600 - val_loss: 0.1728 - val_accuracy: 0.9323 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 4s 18ms/step - loss: 0.1011 - accuracy: 0.9615 - val_loss: 0.1720 - val_accuracy: 0.9369 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1009 - accuracy: 0.9619 - val_loss: 0.1736 - val_accuracy: 0.9346 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1750 - val_accuracy: 0.9323 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0992 - accuracy: 0.9620 - val_loss: 0.1762 - val_accuracy: 0.9319 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1006 - accuracy: 0.9599 - val_loss: 0.1725 - val_accuracy: 0.9346 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0977 - accuracy: 0.9634 - val_loss: 0.1734 - val_accuracy: 0.9319 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0954 - accuracy: 0.9619 - val_loss: 0.1746 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0972 - accuracy: 0.9659 - val_loss: 0.1740 - val_accuracy: 0.9334 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0987 - accuracy: 0.9633 - val_loss: 0.1734 - val_accuracy: 0.9342 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0955 - accuracy: 0.9626 - val_loss: 0.1740 - val_accuracy: 0.9330 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0962 - accuracy: 0.9626 - val_loss: 0.1747 - val_accuracy: 0.9338 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0943 - accuracy: 0.9637 - val_loss: 0.1749 - val_accuracy: 0.9334 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0954 - accuracy: 0.9617 - val_loss: 0.1743 - val_accuracy: 0.9330 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0953 - accuracy: 0.9635 - val_loss: 0.1737 - val_accuracy: 0.9315 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0934 - accuracy: 0.9663 - val_loss: 0.1740 - val_accuracy: 0.9323 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0939 - accuracy: 0.9664 - val_loss: 0.1740 - val_accuracy: 0.9311 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0948 - accuracy: 0.9642 - val_loss: 0.1742 - val_accuracy: 0.9323 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0937 - accuracy: 0.9648 - val_loss: 0.1740 - val_accuracy: 0.9327 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0947 - accuracy: 0.9660 - val_loss: 0.1740 - val_accuracy: 0.9327 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.0921 - accuracy: 0.9641 - val_loss: 0.1740 - val_accuracy: 0.9334 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0953 - accuracy: 0.9622 - val_loss: 0.1739 - val_accuracy: 0.9334 - lr: 7.8364e-05\n",
            "2570/2570 [==============================] - 4s 1ms/step\n",
            "0.9404669260700389 0.9434542102028273 0.9353128313891834 0.8730265694518851 0.9393835207960053 0.9850120025210835\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 1.0856 - accuracy: 0.6954"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 4s 14ms/step - loss: 1.0837 - accuracy: 0.6953 - val_loss: 0.4660 - val_accuracy: 0.7510 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.4717 - accuracy: 0.7844 - val_loss: 0.3706 - val_accuracy: 0.8732 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2957 - accuracy: 0.8722 - val_loss: 0.3132 - val_accuracy: 0.8681 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.2597 - accuracy: 0.8896 - val_loss: 0.2425 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2374 - accuracy: 0.9027 - val_loss: 0.3194 - val_accuracy: 0.8626 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.2100 - accuracy: 0.9131 - val_loss: 0.2288 - val_accuracy: 0.8981 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.2007 - accuracy: 0.9168 - val_loss: 0.2105 - val_accuracy: 0.9125 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.1956 - accuracy: 0.9175 - val_loss: 0.1941 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1860 - accuracy: 0.9253 - val_loss: 0.2013 - val_accuracy: 0.9128 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1755 - accuracy: 0.9295 - val_loss: 0.1984 - val_accuracy: 0.9144 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1711 - accuracy: 0.9301 - val_loss: 0.1897 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1627 - accuracy: 0.9358 - val_loss: 0.1808 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1592 - accuracy: 0.9329 - val_loss: 0.1806 - val_accuracy: 0.9218 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1578 - accuracy: 0.9364 - val_loss: 0.1847 - val_accuracy: 0.9210 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1518 - accuracy: 0.9404 - val_loss: 0.1763 - val_accuracy: 0.9233 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1479 - accuracy: 0.9408 - val_loss: 0.1788 - val_accuracy: 0.9241 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 5s 19ms/step - loss: 0.1472 - accuracy: 0.9421 - val_loss: 0.1782 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1414 - accuracy: 0.9432 - val_loss: 0.1769 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1418 - accuracy: 0.9432 - val_loss: 0.1758 - val_accuracy: 0.9253 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1381 - accuracy: 0.9438 - val_loss: 0.1735 - val_accuracy: 0.9268 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 6s 24ms/step - loss: 0.1354 - accuracy: 0.9437 - val_loss: 0.1718 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1352 - accuracy: 0.9472 - val_loss: 0.1732 - val_accuracy: 0.9292 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1374 - accuracy: 0.9446 - val_loss: 0.1724 - val_accuracy: 0.9292 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1332 - accuracy: 0.9508 - val_loss: 0.1725 - val_accuracy: 0.9268 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1328 - accuracy: 0.9485 - val_loss: 0.1711 - val_accuracy: 0.9292 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1315 - accuracy: 0.9484 - val_loss: 0.1711 - val_accuracy: 0.9284 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1313 - accuracy: 0.9478 - val_loss: 0.1715 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1314 - accuracy: 0.9468 - val_loss: 0.1715 - val_accuracy: 0.9288 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1298 - accuracy: 0.9487 - val_loss: 0.1705 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1287 - accuracy: 0.9513 - val_loss: 0.1710 - val_accuracy: 0.9284 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1318 - accuracy: 0.9449 - val_loss: 0.1712 - val_accuracy: 0.9292 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1296 - accuracy: 0.9494 - val_loss: 0.1710 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1298 - accuracy: 0.9507 - val_loss: 0.1706 - val_accuracy: 0.9284 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1285 - accuracy: 0.9497 - val_loss: 0.1705 - val_accuracy: 0.9292 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1291 - accuracy: 0.9507 - val_loss: 0.1708 - val_accuracy: 0.9292 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1269 - accuracy: 0.9512 - val_loss: 0.1708 - val_accuracy: 0.9300 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1279 - accuracy: 0.9510 - val_loss: 0.1707 - val_accuracy: 0.9300 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1293 - accuracy: 0.9469 - val_loss: 0.1707 - val_accuracy: 0.9284 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1280 - accuracy: 0.9502 - val_loss: 0.1707 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1275 - accuracy: 0.9534 - val_loss: 0.1707 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1278 - accuracy: 0.9495 - val_loss: 0.1706 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1288 - accuracy: 0.9497 - val_loss: 0.1705 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1281 - accuracy: 0.9497 - val_loss: 0.1706 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1278 - accuracy: 0.9512 - val_loss: 0.1706 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1274 - accuracy: 0.9490 - val_loss: 0.1706 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1294 - accuracy: 0.9513 - val_loss: 0.1706 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1281 - accuracy: 0.9498 - val_loss: 0.1706 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9182561307901907 0.9353421217827997 0.8903688524590164 0.8263713708494274 0.912855487120908 0.9764553296697643\n",
            "Epoch 1/200\n",
            "239/241 [============================>.] - ETA: 0s - loss: 1.7302 - accuracy: 0.6488"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 4s 14ms/step - loss: 1.7225 - accuracy: 0.6480 - val_loss: 0.6049 - val_accuracy: 0.7051 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.5602 - accuracy: 0.7131 - val_loss: 0.4720 - val_accuracy: 0.7875 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.3289 - accuracy: 0.8535 - val_loss: 0.2751 - val_accuracy: 0.8875 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2712 - accuracy: 0.8853 - val_loss: 0.2543 - val_accuracy: 0.8969 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.2441 - accuracy: 0.9001 - val_loss: 0.2452 - val_accuracy: 0.8992 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 4s 15ms/step - loss: 0.2138 - accuracy: 0.9122 - val_loss: 0.2052 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2016 - accuracy: 0.9196 - val_loss: 0.1998 - val_accuracy: 0.9160 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 4s 16ms/step - loss: 0.1967 - accuracy: 0.9194 - val_loss: 0.2067 - val_accuracy: 0.9167 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1808 - accuracy: 0.9272 - val_loss: 0.1978 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1746 - accuracy: 0.9298 - val_loss: 0.1905 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1711 - accuracy: 0.9303 - val_loss: 0.2147 - val_accuracy: 0.9179 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1637 - accuracy: 0.9330 - val_loss: 0.1859 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1566 - accuracy: 0.9342 - val_loss: 0.1831 - val_accuracy: 0.9268 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1510 - accuracy: 0.9380 - val_loss: 0.1866 - val_accuracy: 0.9261 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1452 - accuracy: 0.9407 - val_loss: 0.1823 - val_accuracy: 0.9288 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1408 - accuracy: 0.9417 - val_loss: 0.1910 - val_accuracy: 0.9218 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1427 - accuracy: 0.9421 - val_loss: 0.1832 - val_accuracy: 0.9261 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1351 - accuracy: 0.9417 - val_loss: 0.1840 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1355 - accuracy: 0.9454 - val_loss: 0.1803 - val_accuracy: 0.9296 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1355 - accuracy: 0.9449 - val_loss: 0.1821 - val_accuracy: 0.9272 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1320 - accuracy: 0.9458 - val_loss: 0.1808 - val_accuracy: 0.9288 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1279 - accuracy: 0.9502 - val_loss: 0.1795 - val_accuracy: 0.9319 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1288 - accuracy: 0.9480 - val_loss: 0.1802 - val_accuracy: 0.9280 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1288 - accuracy: 0.9472 - val_loss: 0.1794 - val_accuracy: 0.9292 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1275 - accuracy: 0.9490 - val_loss: 0.1780 - val_accuracy: 0.9311 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1238 - accuracy: 0.9521 - val_loss: 0.1783 - val_accuracy: 0.9304 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1273 - accuracy: 0.9494 - val_loss: 0.1776 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1218 - accuracy: 0.9547 - val_loss: 0.1772 - val_accuracy: 0.9319 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1208 - accuracy: 0.9528 - val_loss: 0.1777 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1234 - accuracy: 0.9502 - val_loss: 0.1787 - val_accuracy: 0.9300 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1239 - accuracy: 0.9525 - val_loss: 0.1775 - val_accuracy: 0.9311 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1229 - accuracy: 0.9535 - val_loss: 0.1777 - val_accuracy: 0.9315 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1220 - accuracy: 0.9525 - val_loss: 0.1769 - val_accuracy: 0.9323 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1196 - accuracy: 0.9519 - val_loss: 0.1773 - val_accuracy: 0.9315 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1212 - accuracy: 0.9521 - val_loss: 0.1770 - val_accuracy: 0.9331 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1174 - accuracy: 0.9542 - val_loss: 0.1773 - val_accuracy: 0.9315 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1191 - accuracy: 0.9520 - val_loss: 0.1773 - val_accuracy: 0.9323 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1231 - accuracy: 0.9517 - val_loss: 0.1771 - val_accuracy: 0.9315 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1212 - accuracy: 0.9513 - val_loss: 0.1770 - val_accuracy: 0.9319 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1169 - accuracy: 0.9550 - val_loss: 0.1769 - val_accuracy: 0.9319 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1204 - accuracy: 0.9537 - val_loss: 0.1770 - val_accuracy: 0.9323 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1200 - accuracy: 0.9520 - val_loss: 0.1770 - val_accuracy: 0.9315 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1196 - accuracy: 0.9516 - val_loss: 0.1771 - val_accuracy: 0.9307 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1206 - accuracy: 0.9529 - val_loss: 0.1771 - val_accuracy: 0.9327 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1199 - accuracy: 0.9525 - val_loss: 0.1771 - val_accuracy: 0.9327 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1201 - accuracy: 0.9517 - val_loss: 0.1772 - val_accuracy: 0.9323 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1215 - accuracy: 0.9523 - val_loss: 0.1771 - val_accuracy: 0.9327 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1195 - accuracy: 0.9516 - val_loss: 0.1772 - val_accuracy: 0.9323 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1191 - accuracy: 0.9520 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1182 - accuracy: 0.9538 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1217 - accuracy: 0.9517 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1199 - accuracy: 0.9526 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1217 - accuracy: 0.9535 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1195 - accuracy: 0.9537 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1195 - accuracy: 0.9526 - val_loss: 0.1771 - val_accuracy: 0.9319 - lr: 1.0156e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9166991047100039 0.9362229102167182 0.8836477987421384 0.8212984316047273 0.9099353544794283 0.9745656223429459\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 2.0146 - accuracy: 0.6185"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 4s 14ms/step - loss: 2.0099 - accuracy: 0.6183 - val_loss: 0.6444 - val_accuracy: 0.6864 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.6507 - accuracy: 0.6395 - val_loss: 0.6413 - val_accuracy: 0.6467 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.6244 - accuracy: 0.6741 - val_loss: 0.6208 - val_accuracy: 0.6673 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.6188 - accuracy: 0.6793 - val_loss: 0.6067 - val_accuracy: 0.6868 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.6109 - accuracy: 0.6826 - val_loss: 0.5934 - val_accuracy: 0.6953 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 5s 19ms/step - loss: 0.5975 - accuracy: 0.6920 - val_loss: 0.5660 - val_accuracy: 0.7086 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 4s 15ms/step - loss: 0.5656 - accuracy: 0.7049 - val_loss: 0.5202 - val_accuracy: 0.8004 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.4097 - accuracy: 0.8060 - val_loss: 0.3377 - val_accuracy: 0.8572 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 5s 19ms/step - loss: 0.3022 - accuracy: 0.8691 - val_loss: 0.2812 - val_accuracy: 0.8864 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2738 - accuracy: 0.8856 - val_loss: 0.2433 - val_accuracy: 0.8942 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.2604 - accuracy: 0.8892 - val_loss: 0.2415 - val_accuracy: 0.8946 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2440 - accuracy: 0.8936 - val_loss: 0.2214 - val_accuracy: 0.9031 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.2341 - accuracy: 0.8996 - val_loss: 0.2165 - val_accuracy: 0.9062 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2282 - accuracy: 0.9006 - val_loss: 0.2166 - val_accuracy: 0.9062 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.2164 - accuracy: 0.9058 - val_loss: 0.2064 - val_accuracy: 0.9089 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2158 - accuracy: 0.9071 - val_loss: 0.2043 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2071 - accuracy: 0.9125 - val_loss: 0.2054 - val_accuracy: 0.9152 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1988 - accuracy: 0.9158 - val_loss: 0.1992 - val_accuracy: 0.9163 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.1988 - accuracy: 0.9179 - val_loss: 0.1973 - val_accuracy: 0.9167 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1984 - accuracy: 0.9167 - val_loss: 0.1955 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1931 - accuracy: 0.9184 - val_loss: 0.1971 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1884 - accuracy: 0.9199 - val_loss: 0.1927 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1888 - accuracy: 0.9220 - val_loss: 0.1914 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1855 - accuracy: 0.9249 - val_loss: 0.1922 - val_accuracy: 0.9152 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1856 - accuracy: 0.9251 - val_loss: 0.1913 - val_accuracy: 0.9191 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1804 - accuracy: 0.9275 - val_loss: 0.1894 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1808 - accuracy: 0.9247 - val_loss: 0.1885 - val_accuracy: 0.9222 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1815 - accuracy: 0.9277 - val_loss: 0.1874 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1785 - accuracy: 0.9260 - val_loss: 0.1876 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1824 - accuracy: 0.9245 - val_loss: 0.1880 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1787 - accuracy: 0.9267 - val_loss: 0.1869 - val_accuracy: 0.9222 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1793 - accuracy: 0.9236 - val_loss: 0.1867 - val_accuracy: 0.9214 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1815 - accuracy: 0.9255 - val_loss: 0.1870 - val_accuracy: 0.9226 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1728 - accuracy: 0.9290 - val_loss: 0.1858 - val_accuracy: 0.9214 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1726 - accuracy: 0.9286 - val_loss: 0.1855 - val_accuracy: 0.9195 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1751 - accuracy: 0.9302 - val_loss: 0.1855 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1733 - accuracy: 0.9281 - val_loss: 0.1852 - val_accuracy: 0.9214 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1755 - accuracy: 0.9281 - val_loss: 0.1852 - val_accuracy: 0.9226 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1763 - accuracy: 0.9281 - val_loss: 0.1850 - val_accuracy: 0.9214 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1701 - accuracy: 0.9289 - val_loss: 0.1849 - val_accuracy: 0.9206 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1764 - accuracy: 0.9269 - val_loss: 0.1849 - val_accuracy: 0.9214 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1740 - accuracy: 0.9308 - val_loss: 0.1849 - val_accuracy: 0.9214 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1726 - accuracy: 0.9280 - val_loss: 0.1848 - val_accuracy: 0.9210 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1753 - accuracy: 0.9292 - val_loss: 0.1848 - val_accuracy: 0.9222 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1749 - accuracy: 0.9311 - val_loss: 0.1848 - val_accuracy: 0.9218 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1748 - accuracy: 0.9289 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1735 - accuracy: 0.9302 - val_loss: 0.1848 - val_accuracy: 0.9218 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1763 - accuracy: 0.9262 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1746 - accuracy: 0.9282 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1743 - accuracy: 0.9284 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1738 - accuracy: 0.9279 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1739 - accuracy: 0.9312 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1738 - accuracy: 0.9272 - val_loss: 0.1847 - val_accuracy: 0.9218 - lr: 1.6927e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.938108213312573 0.949163050216987 0.9194560669456067 0.8677023969898012 0.9343095585812968 0.9826390960475425\n",
            "Epoch 1/200\n",
            "239/241 [============================>.] - ETA: 0s - loss: 1.2366 - accuracy: 0.6960"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 4s 14ms/step - loss: 1.2293 - accuracy: 0.6973 - val_loss: 0.7096 - val_accuracy: 0.7039 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.3671 - accuracy: 0.8355 - val_loss: 0.2653 - val_accuracy: 0.8903 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 5s 20ms/step - loss: 0.2520 - accuracy: 0.8905 - val_loss: 0.2516 - val_accuracy: 0.8926 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.2303 - accuracy: 0.9033 - val_loss: 0.2330 - val_accuracy: 0.9027 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 6s 26ms/step - loss: 0.2189 - accuracy: 0.9072 - val_loss: 0.2120 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.2003 - accuracy: 0.9163 - val_loss: 0.2588 - val_accuracy: 0.8829 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1893 - accuracy: 0.9197 - val_loss: 0.1945 - val_accuracy: 0.9198 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1806 - accuracy: 0.9253 - val_loss: 0.2232 - val_accuracy: 0.9148 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1722 - accuracy: 0.9290 - val_loss: 0.1814 - val_accuracy: 0.9261 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1597 - accuracy: 0.9343 - val_loss: 0.1813 - val_accuracy: 0.9288 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1648 - accuracy: 0.9311 - val_loss: 0.1816 - val_accuracy: 0.9272 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1527 - accuracy: 0.9363 - val_loss: 0.1774 - val_accuracy: 0.9276 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1467 - accuracy: 0.9393 - val_loss: 0.1761 - val_accuracy: 0.9319 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1452 - accuracy: 0.9414 - val_loss: 0.1777 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1394 - accuracy: 0.9437 - val_loss: 0.1767 - val_accuracy: 0.9288 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1339 - accuracy: 0.9460 - val_loss: 0.1713 - val_accuracy: 0.9327 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1329 - accuracy: 0.9450 - val_loss: 0.1738 - val_accuracy: 0.9304 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1291 - accuracy: 0.9469 - val_loss: 0.1722 - val_accuracy: 0.9339 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1303 - accuracy: 0.9486 - val_loss: 0.1710 - val_accuracy: 0.9335 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 4s 16ms/step - loss: 0.1280 - accuracy: 0.9476 - val_loss: 0.1731 - val_accuracy: 0.9342 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1245 - accuracy: 0.9493 - val_loss: 0.1717 - val_accuracy: 0.9335 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 4s 17ms/step - loss: 0.1220 - accuracy: 0.9510 - val_loss: 0.1729 - val_accuracy: 0.9346 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1207 - accuracy: 0.9497 - val_loss: 0.1734 - val_accuracy: 0.9331 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1210 - accuracy: 0.9510 - val_loss: 0.1715 - val_accuracy: 0.9339 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1169 - accuracy: 0.9528 - val_loss: 0.1729 - val_accuracy: 0.9342 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1213 - accuracy: 0.9541 - val_loss: 0.1736 - val_accuracy: 0.9323 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1183 - accuracy: 0.9538 - val_loss: 0.1716 - val_accuracy: 0.9335 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1165 - accuracy: 0.9529 - val_loss: 0.1716 - val_accuracy: 0.9339 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1184 - accuracy: 0.9515 - val_loss: 0.1710 - val_accuracy: 0.9339 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1163 - accuracy: 0.9538 - val_loss: 0.1713 - val_accuracy: 0.9350 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1129 - accuracy: 0.9560 - val_loss: 0.1711 - val_accuracy: 0.9335 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1149 - accuracy: 0.9560 - val_loss: 0.1713 - val_accuracy: 0.9335 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1133 - accuracy: 0.9554 - val_loss: 0.1709 - val_accuracy: 0.9331 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1151 - accuracy: 0.9529 - val_loss: 0.1709 - val_accuracy: 0.9331 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1147 - accuracy: 0.9545 - val_loss: 0.1712 - val_accuracy: 0.9335 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1139 - accuracy: 0.9551 - val_loss: 0.1711 - val_accuracy: 0.9335 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1162 - accuracy: 0.9529 - val_loss: 0.1714 - val_accuracy: 0.9346 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1147 - accuracy: 0.9552 - val_loss: 0.1714 - val_accuracy: 0.9339 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1159 - accuracy: 0.9538 - val_loss: 0.1712 - val_accuracy: 0.9331 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1151 - accuracy: 0.9559 - val_loss: 0.1713 - val_accuracy: 0.9342 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1142 - accuracy: 0.9561 - val_loss: 0.1714 - val_accuracy: 0.9342 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1149 - accuracy: 0.9558 - val_loss: 0.1713 - val_accuracy: 0.9335 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1132 - accuracy: 0.9550 - val_loss: 0.1714 - val_accuracy: 0.9339 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1133 - accuracy: 0.9563 - val_loss: 0.1714 - val_accuracy: 0.9335 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1125 - accuracy: 0.9547 - val_loss: 0.1713 - val_accuracy: 0.9331 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1123 - accuracy: 0.9567 - val_loss: 0.1713 - val_accuracy: 0.9331 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1171 - accuracy: 0.9537 - val_loss: 0.1712 - val_accuracy: 0.9327 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1150 - accuracy: 0.9521 - val_loss: 0.1712 - val_accuracy: 0.9327 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 2s 7ms/step - loss: 0.1127 - accuracy: 0.9543 - val_loss: 0.1711 - val_accuracy: 0.9327 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1151 - accuracy: 0.9547 - val_loss: 0.1712 - val_accuracy: 0.9327 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9342156481121059 0.9424414927261227 0.9210526315789473 0.8614175708431099 0.931747062152535 0.9834823703544366\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4847 - accuracy: 0.8614 - val_loss: 0.3931 - val_accuracy: 0.7707 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2283 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2234 - accuracy: 0.9010 - val_loss: 0.2536 - val_accuracy: 0.8863 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9223 - val_loss: 0.1933 - val_accuracy: 0.9237 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9297 - val_loss: 0.2039 - val_accuracy: 0.9175 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1559 - accuracy: 0.9343 - val_loss: 0.1902 - val_accuracy: 0.9257 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1357 - accuracy: 0.9429 - val_loss: 0.1826 - val_accuracy: 0.9260 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1308 - accuracy: 0.9478 - val_loss: 0.1936 - val_accuracy: 0.9151 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9478 - val_loss: 0.1821 - val_accuracy: 0.9303 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9577 - val_loss: 0.1864 - val_accuracy: 0.9288 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9556 - val_loss: 0.1880 - val_accuracy: 0.9257 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1003 - accuracy: 0.9596 - val_loss: 0.1890 - val_accuracy: 0.9288 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9643 - val_loss: 0.1875 - val_accuracy: 0.9299 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9650 - val_loss: 0.1870 - val_accuracy: 0.9268 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9672 - val_loss: 0.1858 - val_accuracy: 0.9292 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9682 - val_loss: 0.1849 - val_accuracy: 0.9311 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9707 - val_loss: 0.1893 - val_accuracy: 0.9295 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0730 - accuracy: 0.9724 - val_loss: 0.1884 - val_accuracy: 0.9311 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9731 - val_loss: 0.1884 - val_accuracy: 0.9330 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9751 - val_loss: 0.1882 - val_accuracy: 0.9330 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9766 - val_loss: 0.1884 - val_accuracy: 0.9323 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9751 - val_loss: 0.1898 - val_accuracy: 0.9323 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9777 - val_loss: 0.1897 - val_accuracy: 0.9334 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0645 - accuracy: 0.9776 - val_loss: 0.1902 - val_accuracy: 0.9334 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9765 - val_loss: 0.1925 - val_accuracy: 0.9323 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.1905 - val_accuracy: 0.9334 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9772 - val_loss: 0.1910 - val_accuracy: 0.9319 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0650 - accuracy: 0.9772 - val_loss: 0.1913 - val_accuracy: 0.9334 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9794 - val_loss: 0.1904 - val_accuracy: 0.9334 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9794 - val_loss: 0.1909 - val_accuracy: 0.9330 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.1912 - val_accuracy: 0.9330 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 0.9814 - val_loss: 0.1919 - val_accuracy: 0.9338 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.1914 - val_accuracy: 0.9342 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9783 - val_loss: 0.1917 - val_accuracy: 0.9334 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9790 - val_loss: 0.1915 - val_accuracy: 0.9334 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0604 - accuracy: 0.9791 - val_loss: 0.1910 - val_accuracy: 0.9334 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.1916 - val_accuracy: 0.9334 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0602 - accuracy: 0.9795 - val_loss: 0.1916 - val_accuracy: 0.9330 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9813 - val_loss: 0.1914 - val_accuracy: 0.9346 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0601 - accuracy: 0.9796 - val_loss: 0.1915 - val_accuracy: 0.9334 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9786 - val_loss: 0.1915 - val_accuracy: 0.9338 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9799 - val_loss: 0.1914 - val_accuracy: 0.9334 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9770 - val_loss: 0.1914 - val_accuracy: 0.9334 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 0.1914 - val_accuracy: 0.9334 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 0.1916 - val_accuracy: 0.9334 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9824 - val_loss: 0.1915 - val_accuracy: 0.9334 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9777 - val_loss: 0.1915 - val_accuracy: 0.9334 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0625 - accuracy: 0.9795 - val_loss: 0.1916 - val_accuracy: 0.9334 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0614 - accuracy: 0.9791 - val_loss: 0.1915 - val_accuracy: 0.9334 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 0.1914 - val_accuracy: 0.9334 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9785 - val_loss: 0.1915 - val_accuracy: 0.9330 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9801 - val_loss: 0.1914 - val_accuracy: 0.9330 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 0.1915 - val_accuracy: 0.9330 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.1915 - val_accuracy: 0.9330 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0581 - accuracy: 0.9813 - val_loss: 0.1916 - val_accuracy: 0.9330 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9801 - val_loss: 0.1916 - val_accuracy: 0.9334 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9796 - val_loss: 0.1915 - val_accuracy: 0.9334 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9813 - val_loss: 0.1914 - val_accuracy: 0.9330 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0604 - accuracy: 0.9783 - val_loss: 0.1914 - val_accuracy: 0.9330 - lr: 6.0936e-06\n",
            "2570/2570 [==============================] - 4s 1ms/step\n",
            "0.9404669260700389 0.9489858635525507 0.9257688229056203 0.8722785427854326 0.9373773432290855 0.986537492643038\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.5806 - accuracy: 0.8677 - val_loss: 0.3231 - val_accuracy: 0.8630 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.1679 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2208 - accuracy: 0.9088 - val_loss: 0.2050 - val_accuracy: 0.9148 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9250 - val_loss: 0.1818 - val_accuracy: 0.9249 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9269 - val_loss: 0.1791 - val_accuracy: 0.9218 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1582 - accuracy: 0.9338 - val_loss: 0.1771 - val_accuracy: 0.9218 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1386 - accuracy: 0.9407 - val_loss: 0.1822 - val_accuracy: 0.9272 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9463 - val_loss: 0.1849 - val_accuracy: 0.9253 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1254 - accuracy: 0.9491 - val_loss: 0.1696 - val_accuracy: 0.9319 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9545 - val_loss: 0.1687 - val_accuracy: 0.9307 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9550 - val_loss: 0.1712 - val_accuracy: 0.9323 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9583 - val_loss: 0.1694 - val_accuracy: 0.9342 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9629 - val_loss: 0.1666 - val_accuracy: 0.9335 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9646 - val_loss: 0.1679 - val_accuracy: 0.9300 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9669 - val_loss: 0.1703 - val_accuracy: 0.9315 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0835 - accuracy: 0.9683 - val_loss: 0.1651 - val_accuracy: 0.9370 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0841 - accuracy: 0.9691 - val_loss: 0.1648 - val_accuracy: 0.9354 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9721 - val_loss: 0.1701 - val_accuracy: 0.9350 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9729 - val_loss: 0.1656 - val_accuracy: 0.9346 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0766 - accuracy: 0.9709 - val_loss: 0.1643 - val_accuracy: 0.9374 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 0.1645 - val_accuracy: 0.9358 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0713 - accuracy: 0.9755 - val_loss: 0.1662 - val_accuracy: 0.9370 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0713 - accuracy: 0.9759 - val_loss: 0.1662 - val_accuracy: 0.9374 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9752 - val_loss: 0.1663 - val_accuracy: 0.9366 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9772 - val_loss: 0.1666 - val_accuracy: 0.9370 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0685 - accuracy: 0.9776 - val_loss: 0.1658 - val_accuracy: 0.9374 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9765 - val_loss: 0.1675 - val_accuracy: 0.9370 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9747 - val_loss: 0.1677 - val_accuracy: 0.9370 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9752 - val_loss: 0.1678 - val_accuracy: 0.9358 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.1676 - val_accuracy: 0.9366 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9761 - val_loss: 0.1676 - val_accuracy: 0.9362 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0633 - accuracy: 0.9773 - val_loss: 0.1681 - val_accuracy: 0.9358 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9766 - val_loss: 0.1681 - val_accuracy: 0.9350 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9752 - val_loss: 0.1678 - val_accuracy: 0.9370 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9755 - val_loss: 0.1674 - val_accuracy: 0.9366 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.1678 - val_accuracy: 0.9362 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9778 - val_loss: 0.1678 - val_accuracy: 0.9370 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9770 - val_loss: 0.1679 - val_accuracy: 0.9370 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9760 - val_loss: 0.1678 - val_accuracy: 0.9374 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.1679 - val_accuracy: 0.9374 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9357726741922927 0.9504080351537979 0.9118852459016393 0.8635071122953727 0.9311466405277187 0.9811856174040113\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.7068 - accuracy: 0.8549 - val_loss: 0.3189 - val_accuracy: 0.8743 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.0786 - accuracy: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9061 - val_loss: 0.2038 - val_accuracy: 0.9105 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1778 - accuracy: 0.9285 - val_loss: 0.1887 - val_accuracy: 0.9202 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9301 - val_loss: 0.2026 - val_accuracy: 0.9136 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1547 - accuracy: 0.9346 - val_loss: 0.1866 - val_accuracy: 0.9226 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9439 - val_loss: 0.1806 - val_accuracy: 0.9268 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1261 - accuracy: 0.9510 - val_loss: 0.1838 - val_accuracy: 0.9280 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1216 - accuracy: 0.9515 - val_loss: 0.1792 - val_accuracy: 0.9288 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9534 - val_loss: 0.1743 - val_accuracy: 0.9319 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9606 - val_loss: 0.1744 - val_accuracy: 0.9292 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.9580 - val_loss: 0.1699 - val_accuracy: 0.9350 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9616 - val_loss: 0.1767 - val_accuracy: 0.9319 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9655 - val_loss: 0.1808 - val_accuracy: 0.9331 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9655 - val_loss: 0.1726 - val_accuracy: 0.9331 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9691 - val_loss: 0.1736 - val_accuracy: 0.9350 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9694 - val_loss: 0.1761 - val_accuracy: 0.9307 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0796 - accuracy: 0.9711 - val_loss: 0.1740 - val_accuracy: 0.9362 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9724 - val_loss: 0.1722 - val_accuracy: 0.9346 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.1720 - val_accuracy: 0.9354 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9707 - val_loss: 0.1737 - val_accuracy: 0.9346 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9730 - val_loss: 0.1727 - val_accuracy: 0.9362 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9753 - val_loss: 0.1739 - val_accuracy: 0.9358 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9737 - val_loss: 0.1724 - val_accuracy: 0.9358 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0712 - accuracy: 0.9751 - val_loss: 0.1730 - val_accuracy: 0.9350 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9742 - val_loss: 0.1731 - val_accuracy: 0.9362 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9740 - val_loss: 0.1731 - val_accuracy: 0.9374 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9768 - val_loss: 0.1736 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9764 - val_loss: 0.1735 - val_accuracy: 0.9366 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.1738 - val_accuracy: 0.9362 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9756 - val_loss: 0.1737 - val_accuracy: 0.9370 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0702 - accuracy: 0.9737 - val_loss: 0.1739 - val_accuracy: 0.9354 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9770 - val_loss: 0.1739 - val_accuracy: 0.9358 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9772 - val_loss: 0.1739 - val_accuracy: 0.9362 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9744 - val_loss: 0.1741 - val_accuracy: 0.9350 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9757 - val_loss: 0.1739 - val_accuracy: 0.9366 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.1741 - val_accuracy: 0.9350 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.1741 - val_accuracy: 0.9370 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.1741 - val_accuracy: 0.9370 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0668 - accuracy: 0.9763 - val_loss: 0.1743 - val_accuracy: 0.9358 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9744 - val_loss: 0.1743 - val_accuracy: 0.9358 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9761 - val_loss: 0.1745 - val_accuracy: 0.9350 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.1744 - val_accuracy: 0.9350 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0662 - accuracy: 0.9764 - val_loss: 0.1745 - val_accuracy: 0.9350 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9765 - val_loss: 0.1743 - val_accuracy: 0.9350 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9735 - val_loss: 0.1742 - val_accuracy: 0.9350 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0679 - accuracy: 0.9766 - val_loss: 0.1742 - val_accuracy: 0.9350 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9256520046710782 0.9424148606811146 0.8972746331236897 0.8405983951539208 0.9198447469024021 0.9771309980463553\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.4441 - accuracy: 0.8640 - val_loss: 0.3183 - val_accuracy: 0.8911 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.1600 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2256 - accuracy: 0.9045 - val_loss: 0.2086 - val_accuracy: 0.9089 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9202 - val_loss: 0.1912 - val_accuracy: 0.9187 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1698 - accuracy: 0.9316 - val_loss: 0.1867 - val_accuracy: 0.9175 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1580 - accuracy: 0.9337 - val_loss: 0.1850 - val_accuracy: 0.9202 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9415 - val_loss: 0.1766 - val_accuracy: 0.9195 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9468 - val_loss: 0.1897 - val_accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9537 - val_loss: 0.1774 - val_accuracy: 0.9249 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9577 - val_loss: 0.1734 - val_accuracy: 0.9268 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9585 - val_loss: 0.1731 - val_accuracy: 0.9300 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9624 - val_loss: 0.1696 - val_accuracy: 0.9288 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9655 - val_loss: 0.1761 - val_accuracy: 0.9257 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9664 - val_loss: 0.1740 - val_accuracy: 0.9292 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0825 - accuracy: 0.9694 - val_loss: 0.1748 - val_accuracy: 0.9261 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9728 - val_loss: 0.1796 - val_accuracy: 0.9272 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9704 - val_loss: 0.1741 - val_accuracy: 0.9284 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9752 - val_loss: 0.1778 - val_accuracy: 0.9300 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9747 - val_loss: 0.1792 - val_accuracy: 0.9268 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9753 - val_loss: 0.1778 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0670 - accuracy: 0.9751 - val_loss: 0.1788 - val_accuracy: 0.9284 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9774 - val_loss: 0.1786 - val_accuracy: 0.9296 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9801 - val_loss: 0.1787 - val_accuracy: 0.9304 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.9783 - val_loss: 0.1784 - val_accuracy: 0.9300 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0633 - accuracy: 0.9769 - val_loss: 0.1792 - val_accuracy: 0.9304 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.1792 - val_accuracy: 0.9307 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9785 - val_loss: 0.1788 - val_accuracy: 0.9311 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 0.1790 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.1791 - val_accuracy: 0.9307 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9798 - val_loss: 0.1790 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.1794 - val_accuracy: 0.9304 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.1797 - val_accuracy: 0.9311 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.1798 - val_accuracy: 0.9307 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.1799 - val_accuracy: 0.9307 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9786 - val_loss: 0.1796 - val_accuracy: 0.9315 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0592 - accuracy: 0.9801 - val_loss: 0.1798 - val_accuracy: 0.9319 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.1798 - val_accuracy: 0.9307 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.1800 - val_accuracy: 0.9319 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9809 - val_loss: 0.1800 - val_accuracy: 0.9323 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9817 - val_loss: 0.1801 - val_accuracy: 0.9319 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 0.1802 - val_accuracy: 0.9307 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.1802 - val_accuracy: 0.9319 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.1802 - val_accuracy: 0.9323 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.1802 - val_accuracy: 0.9323 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9814 - val_loss: 0.1802 - val_accuracy: 0.9323 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9791 - val_loss: 0.1801 - val_accuracy: 0.9323 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9798 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.1802 - val_accuracy: 0.9319 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0584 - accuracy: 0.9824 - val_loss: 0.1801 - val_accuracy: 0.9327 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9809 - val_loss: 0.1802 - val_accuracy: 0.9319 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9821 - val_loss: 0.1801 - val_accuracy: 0.9319 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9804 - val_loss: 0.1802 - val_accuracy: 0.9319 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.1802 - val_accuracy: 0.9311 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9786 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0576 - accuracy: 0.9809 - val_loss: 0.1800 - val_accuracy: 0.9315 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9814 - val_loss: 0.1801 - val_accuracy: 0.9311 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 0.1801 - val_accuracy: 0.9315 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.1803 - val_accuracy: 0.9315 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9813 - val_loss: 0.1802 - val_accuracy: 0.9311 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9831 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9809 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.9809 - val_loss: 0.1802 - val_accuracy: 0.9315 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9812 - val_loss: 0.1803 - val_accuracy: 0.9315 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.1801 - val_accuracy: 0.9315 - lr: 1.3162e-06\n",
            "Epoch 68/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0592 - accuracy: 0.9803 - val_loss: 0.1801 - val_accuracy: 0.9315 - lr: 1.3162e-06\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9435578045932269 0.9510229386236826 0.9309623430962343 0.8796007435469091 0.9409926408599585 0.9868689154801339\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.9976 - accuracy: 0.8513 - val_loss: 0.3053 - val_accuracy: 0.8747 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 1s - loss: 0.2116 - accuracy: 0.9375"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2343 - accuracy: 0.9013 - val_loss: 0.1949 - val_accuracy: 0.9125 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1893 - accuracy: 0.9183 - val_loss: 0.1821 - val_accuracy: 0.9233 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1786 - accuracy: 0.9255 - val_loss: 0.1942 - val_accuracy: 0.9175 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1726 - accuracy: 0.9263 - val_loss: 0.1947 - val_accuracy: 0.9163 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 6ms/step - loss: 0.1552 - accuracy: 0.9346 - val_loss: 0.1758 - val_accuracy: 0.9284 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9393 - val_loss: 0.1784 - val_accuracy: 0.9233 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9417 - val_loss: 0.1746 - val_accuracy: 0.9280 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1301 - accuracy: 0.9460 - val_loss: 0.1767 - val_accuracy: 0.9280 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1278 - accuracy: 0.9475 - val_loss: 0.1684 - val_accuracy: 0.9374 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9534 - val_loss: 0.1693 - val_accuracy: 0.9342 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1182 - accuracy: 0.9515 - val_loss: 0.1680 - val_accuracy: 0.9335 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9555 - val_loss: 0.1649 - val_accuracy: 0.9366 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9552 - val_loss: 0.1642 - val_accuracy: 0.9377 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9585 - val_loss: 0.1650 - val_accuracy: 0.9362 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9590 - val_loss: 0.1652 - val_accuracy: 0.9377 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9591 - val_loss: 0.1656 - val_accuracy: 0.9335 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9616 - val_loss: 0.1633 - val_accuracy: 0.9393 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9622 - val_loss: 0.1665 - val_accuracy: 0.9362 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9654 - val_loss: 0.1635 - val_accuracy: 0.9385 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9644 - val_loss: 0.1634 - val_accuracy: 0.9381 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9630 - val_loss: 0.1635 - val_accuracy: 0.9381 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9674 - val_loss: 0.1629 - val_accuracy: 0.9389 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9659 - val_loss: 0.1632 - val_accuracy: 0.9389 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0891 - accuracy: 0.9664 - val_loss: 0.1636 - val_accuracy: 0.9389 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9654 - val_loss: 0.1633 - val_accuracy: 0.9409 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9643 - val_loss: 0.1626 - val_accuracy: 0.9405 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9692 - val_loss: 0.1625 - val_accuracy: 0.9401 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.9656 - val_loss: 0.1625 - val_accuracy: 0.9401 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9677 - val_loss: 0.1624 - val_accuracy: 0.9397 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9660 - val_loss: 0.1623 - val_accuracy: 0.9401 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9672 - val_loss: 0.1624 - val_accuracy: 0.9397 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.1625 - val_accuracy: 0.9401 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9669 - val_loss: 0.1625 - val_accuracy: 0.9401 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9665 - val_loss: 0.1625 - val_accuracy: 0.9401 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9685 - val_loss: 0.1624 - val_accuracy: 0.9397 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9683 - val_loss: 0.1624 - val_accuracy: 0.9401 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9695 - val_loss: 0.1624 - val_accuracy: 0.9397 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9690 - val_loss: 0.1625 - val_accuracy: 0.9397 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9664 - val_loss: 0.1625 - val_accuracy: 0.9405 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.9657 - val_loss: 0.1625 - val_accuracy: 0.9405 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.9659 - val_loss: 0.1625 - val_accuracy: 0.9405 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9674 - val_loss: 0.1624 - val_accuracy: 0.9397 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9673 - val_loss: 0.1623 - val_accuracy: 0.9397 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0846 - accuracy: 0.9683 - val_loss: 0.1624 - val_accuracy: 0.9401 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9672 - val_loss: 0.1624 - val_accuracy: 0.9397 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9412222654729466 0.9557242251739405 0.9180161943319838 0.8756045717771597 0.9368702097529622 0.9839990064198594\n",
            "Epoch 1/200\n",
            "235/241 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.8693"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.5219 - accuracy: 0.8699 - val_loss: 0.3808 - val_accuracy: 0.8665 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2179 - accuracy: 0.9096 - val_loss: 0.2226 - val_accuracy: 0.9070 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.1763 - accuracy: 0.9264 - val_loss: 0.1982 - val_accuracy: 0.9229 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9290 - val_loss: 0.1890 - val_accuracy: 0.9186 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1458 - accuracy: 0.9416 - val_loss: 0.1915 - val_accuracy: 0.9260 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1296 - accuracy: 0.9502 - val_loss: 0.1916 - val_accuracy: 0.9233 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1187 - accuracy: 0.9506 - val_loss: 0.1850 - val_accuracy: 0.9264 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1111 - accuracy: 0.9542 - val_loss: 0.1783 - val_accuracy: 0.9346 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9621 - val_loss: 0.1989 - val_accuracy: 0.9194 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9617 - val_loss: 0.1849 - val_accuracy: 0.9311 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0841 - accuracy: 0.9667 - val_loss: 0.1863 - val_accuracy: 0.9350 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9720 - val_loss: 0.1853 - val_accuracy: 0.9319 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9735 - val_loss: 0.1849 - val_accuracy: 0.9346 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0694 - accuracy: 0.9751 - val_loss: 0.1945 - val_accuracy: 0.9292 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0673 - accuracy: 0.9755 - val_loss: 0.1923 - val_accuracy: 0.9366 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 0.9787 - val_loss: 0.1941 - val_accuracy: 0.9307 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0615 - accuracy: 0.9789 - val_loss: 0.1938 - val_accuracy: 0.9327 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0578 - accuracy: 0.9826 - val_loss: 0.1871 - val_accuracy: 0.9381 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.1913 - val_accuracy: 0.9381 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0555 - accuracy: 0.9795 - val_loss: 0.1908 - val_accuracy: 0.9369 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.1903 - val_accuracy: 0.9377 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.1910 - val_accuracy: 0.9358 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9830 - val_loss: 0.1913 - val_accuracy: 0.9377 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.1910 - val_accuracy: 0.9366 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9827 - val_loss: 0.1908 - val_accuracy: 0.9362 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.1918 - val_accuracy: 0.9377 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.1922 - val_accuracy: 0.9362 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.1922 - val_accuracy: 0.9366 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.1923 - val_accuracy: 0.9373 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0496 - accuracy: 0.9851 - val_loss: 0.1928 - val_accuracy: 0.9377 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.1929 - val_accuracy: 0.9354 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.1931 - val_accuracy: 0.9373 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.1930 - val_accuracy: 0.9369 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9861 - val_loss: 0.1930 - val_accuracy: 0.9373 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0481 - accuracy: 0.9856 - val_loss: 0.1932 - val_accuracy: 0.9373 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.1930 - val_accuracy: 0.9366 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.1930 - val_accuracy: 0.9366 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.1930 - val_accuracy: 0.9369 - lr: 2.1768e-04\n",
            "2570/2570 [==============================] - 4s 1ms/step\n",
            "0.9396887159533074 0.9465273509526736 0.9278897136797455 0.8708386363850344 0.9372085323162096 0.9865065331126842\n",
            "Epoch 1/200\n",
            "233/241 [============================>.] - ETA: 0s - loss: 0.5860 - accuracy: 0.8671"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.5740 - accuracy: 0.8677 - val_loss: 0.3355 - val_accuracy: 0.8852 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.2133 - accuracy: 0.9131 - val_loss: 0.2280 - val_accuracy: 0.9004 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1742 - accuracy: 0.9268 - val_loss: 0.1900 - val_accuracy: 0.9113 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1591 - accuracy: 0.9350 - val_loss: 0.1740 - val_accuracy: 0.9276 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.9378 - val_loss: 0.1793 - val_accuracy: 0.9241 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1266 - accuracy: 0.9500 - val_loss: 0.1733 - val_accuracy: 0.9280 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9500 - val_loss: 0.1798 - val_accuracy: 0.9249 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1099 - accuracy: 0.9561 - val_loss: 0.1686 - val_accuracy: 0.9319 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9611 - val_loss: 0.1752 - val_accuracy: 0.9292 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9647 - val_loss: 0.1671 - val_accuracy: 0.9304 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0849 - accuracy: 0.9678 - val_loss: 0.1687 - val_accuracy: 0.9362 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 0.1726 - val_accuracy: 0.9350 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9743 - val_loss: 0.1755 - val_accuracy: 0.9342 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.1735 - val_accuracy: 0.9323 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.1758 - val_accuracy: 0.9335 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 0.9794 - val_loss: 0.1745 - val_accuracy: 0.9315 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0611 - accuracy: 0.9782 - val_loss: 0.1880 - val_accuracy: 0.9300 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9827 - val_loss: 0.1843 - val_accuracy: 0.9327 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9809 - val_loss: 0.1757 - val_accuracy: 0.9346 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 0.1779 - val_accuracy: 0.9366 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.1799 - val_accuracy: 0.9346 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.1854 - val_accuracy: 0.9342 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.1780 - val_accuracy: 0.9354 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0505 - accuracy: 0.9834 - val_loss: 0.1799 - val_accuracy: 0.9350 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0506 - accuracy: 0.9833 - val_loss: 0.1803 - val_accuracy: 0.9350 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9839 - val_loss: 0.1791 - val_accuracy: 0.9342 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9855 - val_loss: 0.1797 - val_accuracy: 0.9342 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.1809 - val_accuracy: 0.9354 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.1807 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.1797 - val_accuracy: 0.9342 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0481 - accuracy: 0.9861 - val_loss: 0.1802 - val_accuracy: 0.9342 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9874 - val_loss: 0.1800 - val_accuracy: 0.9354 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.1803 - val_accuracy: 0.9350 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.1805 - val_accuracy: 0.9342 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.1809 - val_accuracy: 0.9346 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0479 - accuracy: 0.9856 - val_loss: 0.1806 - val_accuracy: 0.9346 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.1808 - val_accuracy: 0.9346 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 0.1809 - val_accuracy: 0.9346 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.1809 - val_accuracy: 0.9350 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 0.1807 - val_accuracy: 0.9354 - lr: 1.3061e-04\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9311015959517321 0.9403640929064658 0.9159836065573771 0.8541934616051956 0.9281738497319214 0.9813386949049634\n",
            "Epoch 1/200\n",
            "236/241 [============================>.] - ETA: 0s - loss: 0.5629 - accuracy: 0.8716"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.5556 - accuracy: 0.8722 - val_loss: 0.3775 - val_accuracy: 0.8451 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2111 - accuracy: 0.9142 - val_loss: 0.2196 - val_accuracy: 0.9019 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1705 - accuracy: 0.9273 - val_loss: 0.1838 - val_accuracy: 0.9245 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1504 - accuracy: 0.9350 - val_loss: 0.1787 - val_accuracy: 0.9226 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1398 - accuracy: 0.9412 - val_loss: 0.2098 - val_accuracy: 0.9214 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1224 - accuracy: 0.9500 - val_loss: 0.1870 - val_accuracy: 0.9222 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1129 - accuracy: 0.9534 - val_loss: 0.1820 - val_accuracy: 0.9288 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9556 - val_loss: 0.1829 - val_accuracy: 0.9265 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0946 - accuracy: 0.9626 - val_loss: 0.1778 - val_accuracy: 0.9304 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0899 - accuracy: 0.9641 - val_loss: 0.1881 - val_accuracy: 0.9276 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0853 - accuracy: 0.9668 - val_loss: 0.1806 - val_accuracy: 0.9346 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9705 - val_loss: 0.1812 - val_accuracy: 0.9323 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9722 - val_loss: 0.1833 - val_accuracy: 0.9342 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0725 - accuracy: 0.9737 - val_loss: 0.1900 - val_accuracy: 0.9311 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0663 - accuracy: 0.9772 - val_loss: 0.1827 - val_accuracy: 0.9319 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 0.9764 - val_loss: 0.1857 - val_accuracy: 0.9331 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0628 - accuracy: 0.9781 - val_loss: 0.1835 - val_accuracy: 0.9342 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 0.1863 - val_accuracy: 0.9315 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0581 - accuracy: 0.9807 - val_loss: 0.1875 - val_accuracy: 0.9331 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.1857 - val_accuracy: 0.9335 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.1886 - val_accuracy: 0.9319 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.1882 - val_accuracy: 0.9323 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.1879 - val_accuracy: 0.9319 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0539 - accuracy: 0.9814 - val_loss: 0.1883 - val_accuracy: 0.9331 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.1915 - val_accuracy: 0.9307 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.1894 - val_accuracy: 0.9327 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.1900 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.1898 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.1892 - val_accuracy: 0.9339 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1895 - val_accuracy: 0.9331 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0508 - accuracy: 0.9853 - val_loss: 0.1896 - val_accuracy: 0.9323 - lr: 6.0466e-04\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9233164655507979 0.9343653250773993 0.9046121593291404 0.836351570346014 0.9194887422032698 0.9752211642684218\n",
            "Epoch 1/200\n",
            "236/241 [============================>.] - ETA: 0s - loss: 1.4289 - accuracy: 0.6049"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 1.4137 - accuracy: 0.6049 - val_loss: 0.6694 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6722 - accuracy: 0.6158 - val_loss: 0.6600 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.6106 - accuracy: 0.6796 - val_loss: 0.5456 - val_accuracy: 0.7125 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5708 - accuracy: 0.7162 - val_loss: 0.3690 - val_accuracy: 0.8288 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4046 - accuracy: 0.8124 - val_loss: 0.2811 - val_accuracy: 0.8778 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.2605 - accuracy: 0.8861 - val_loss: 0.2358 - val_accuracy: 0.9019 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2389 - accuracy: 0.8989 - val_loss: 0.2154 - val_accuracy: 0.9027 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9070 - val_loss: 0.2373 - val_accuracy: 0.9000 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.1981 - accuracy: 0.9190 - val_loss: 0.1941 - val_accuracy: 0.9233 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1863 - accuracy: 0.9233 - val_loss: 0.1958 - val_accuracy: 0.9163 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1762 - accuracy: 0.9264 - val_loss: 0.1862 - val_accuracy: 0.9241 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1666 - accuracy: 0.9311 - val_loss: 0.1868 - val_accuracy: 0.9253 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1635 - accuracy: 0.9333 - val_loss: 0.1842 - val_accuracy: 0.9222 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.1560 - accuracy: 0.9354 - val_loss: 0.1805 - val_accuracy: 0.9268 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1457 - accuracy: 0.9412 - val_loss: 0.1736 - val_accuracy: 0.9280 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1434 - accuracy: 0.9436 - val_loss: 0.1774 - val_accuracy: 0.9304 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1391 - accuracy: 0.9436 - val_loss: 0.1738 - val_accuracy: 0.9339 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1330 - accuracy: 0.9464 - val_loss: 0.1741 - val_accuracy: 0.9311 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9493 - val_loss: 0.1776 - val_accuracy: 0.9319 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1275 - accuracy: 0.9490 - val_loss: 0.1749 - val_accuracy: 0.9342 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9526 - val_loss: 0.1761 - val_accuracy: 0.9339 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1213 - accuracy: 0.9526 - val_loss: 0.1748 - val_accuracy: 0.9354 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9535 - val_loss: 0.1741 - val_accuracy: 0.9323 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.9545 - val_loss: 0.1727 - val_accuracy: 0.9350 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9528 - val_loss: 0.1740 - val_accuracy: 0.9342 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9546 - val_loss: 0.1728 - val_accuracy: 0.9350 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1177 - accuracy: 0.9571 - val_loss: 0.1715 - val_accuracy: 0.9354 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9583 - val_loss: 0.1719 - val_accuracy: 0.9331 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9580 - val_loss: 0.1717 - val_accuracy: 0.9342 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9547 - val_loss: 0.1708 - val_accuracy: 0.9339 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9539 - val_loss: 0.1709 - val_accuracy: 0.9342 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9551 - val_loss: 0.1707 - val_accuracy: 0.9327 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9593 - val_loss: 0.1706 - val_accuracy: 0.9335 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9581 - val_loss: 0.1713 - val_accuracy: 0.9354 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9572 - val_loss: 0.1708 - val_accuracy: 0.9335 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9574 - val_loss: 0.1711 - val_accuracy: 0.9339 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9594 - val_loss: 0.1713 - val_accuracy: 0.9339 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9594 - val_loss: 0.1713 - val_accuracy: 0.9342 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9582 - val_loss: 0.1714 - val_accuracy: 0.9335 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9568 - val_loss: 0.1712 - val_accuracy: 0.9331 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9600 - val_loss: 0.1711 - val_accuracy: 0.9335 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1126 - accuracy: 0.9577 - val_loss: 0.1712 - val_accuracy: 0.9331 - lr: 7.8364e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9420007785130401 0.9578425294482331 0.9152719665271967 0.875590844011588 0.9365572479877149 0.9854571382620809\n",
            "Epoch 1/200\n",
            "231/241 [===========================>..] - ETA: 0s - loss: 0.8078 - accuracy: 0.8608"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 4s 11ms/step - loss: 0.7858 - accuracy: 0.8619 - val_loss: 0.3226 - val_accuracy: 0.8965 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2222 - accuracy: 0.9011 - val_loss: 0.2095 - val_accuracy: 0.9125 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1813 - accuracy: 0.9231 - val_loss: 0.1839 - val_accuracy: 0.9237 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9271 - val_loss: 0.1886 - val_accuracy: 0.9237 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1611 - accuracy: 0.9337 - val_loss: 0.1903 - val_accuracy: 0.9195 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1390 - accuracy: 0.9391 - val_loss: 0.1802 - val_accuracy: 0.9304 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1290 - accuracy: 0.9465 - val_loss: 0.1685 - val_accuracy: 0.9339 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1214 - accuracy: 0.9503 - val_loss: 0.1931 - val_accuracy: 0.9198 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9556 - val_loss: 0.1752 - val_accuracy: 0.9335 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9574 - val_loss: 0.1680 - val_accuracy: 0.9323 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1016 - accuracy: 0.9599 - val_loss: 0.1690 - val_accuracy: 0.9339 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9635 - val_loss: 0.1702 - val_accuracy: 0.9327 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0912 - accuracy: 0.9641 - val_loss: 0.1692 - val_accuracy: 0.9342 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9663 - val_loss: 0.1700 - val_accuracy: 0.9339 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0835 - accuracy: 0.9681 - val_loss: 0.1658 - val_accuracy: 0.9389 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9712 - val_loss: 0.1669 - val_accuracy: 0.9385 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.0787 - accuracy: 0.9707 - val_loss: 0.1654 - val_accuracy: 0.9397 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.9726 - val_loss: 0.1675 - val_accuracy: 0.9389 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9721 - val_loss: 0.1711 - val_accuracy: 0.9370 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0740 - accuracy: 0.9733 - val_loss: 0.1669 - val_accuracy: 0.9393 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0700 - accuracy: 0.9742 - val_loss: 0.1681 - val_accuracy: 0.9397 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0692 - accuracy: 0.9751 - val_loss: 0.1679 - val_accuracy: 0.9409 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0664 - accuracy: 0.9776 - val_loss: 0.1678 - val_accuracy: 0.9401 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9748 - val_loss: 0.1696 - val_accuracy: 0.9385 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0674 - accuracy: 0.9764 - val_loss: 0.1694 - val_accuracy: 0.9385 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 0.1679 - val_accuracy: 0.9420 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0689 - accuracy: 0.9746 - val_loss: 0.1676 - val_accuracy: 0.9409 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9794 - val_loss: 0.1689 - val_accuracy: 0.9405 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.1686 - val_accuracy: 0.9401 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.1676 - val_accuracy: 0.9409 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0663 - accuracy: 0.9770 - val_loss: 0.1677 - val_accuracy: 0.9409 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 0.9798 - val_loss: 0.1689 - val_accuracy: 0.9397 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9763 - val_loss: 0.1684 - val_accuracy: 0.9405 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0629 - accuracy: 0.9798 - val_loss: 0.1683 - val_accuracy: 0.9405 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 0.9756 - val_loss: 0.1683 - val_accuracy: 0.9405 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 0.1682 - val_accuracy: 0.9409 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0640 - accuracy: 0.9781 - val_loss: 0.1682 - val_accuracy: 0.9401 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.1684 - val_accuracy: 0.9405 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 0.9782 - val_loss: 0.1685 - val_accuracy: 0.9409 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9764 - val_loss: 0.1686 - val_accuracy: 0.9409 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9794 - val_loss: 0.1683 - val_accuracy: 0.9405 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 0.1681 - val_accuracy: 0.9401 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.1683 - val_accuracy: 0.9405 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0640 - accuracy: 0.9783 - val_loss: 0.1683 - val_accuracy: 0.9401 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 0.9778 - val_loss: 0.1684 - val_accuracy: 0.9405 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0646 - accuracy: 0.9773 - val_loss: 0.1682 - val_accuracy: 0.9405 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9388867263526665 0.9487666034155597 0.9230769230769231 0.8710242046478224 0.9359217632462414 0.9836075281621073\n",
            "Epoch 1/200\n",
            "237/241 [============================>.] - ETA: 0s - loss: 2.8747 - accuracy: 0.6499"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 10ms/step - loss: 2.8381 - accuracy: 0.6507 - val_loss: 0.5815 - val_accuracy: 0.7088 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.6739 - val_loss: 0.6409 - val_accuracy: 0.6053 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5741 - accuracy: 0.7036 - val_loss: 0.4467 - val_accuracy: 0.8357 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4398 - accuracy: 0.7959 - val_loss: 0.3246 - val_accuracy: 0.8622 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 5s 19ms/step - loss: 0.3248 - accuracy: 0.8535 - val_loss: 0.2880 - val_accuracy: 0.8801 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2676 - accuracy: 0.8841 - val_loss: 0.2444 - val_accuracy: 0.8926 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2576 - accuracy: 0.8883 - val_loss: 0.2298 - val_accuracy: 0.8996 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2419 - accuracy: 0.8994 - val_loss: 0.2368 - val_accuracy: 0.8992 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2292 - accuracy: 0.9040 - val_loss: 0.2317 - val_accuracy: 0.9058 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9058 - val_loss: 0.2379 - val_accuracy: 0.8937 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2121 - accuracy: 0.9090 - val_loss: 0.2151 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9128 - val_loss: 0.2132 - val_accuracy: 0.9097 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9153 - val_loss: 0.2098 - val_accuracy: 0.9093 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1976 - accuracy: 0.9175 - val_loss: 0.2079 - val_accuracy: 0.9159 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1914 - accuracy: 0.9179 - val_loss: 0.2075 - val_accuracy: 0.9128 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1919 - accuracy: 0.9181 - val_loss: 0.2019 - val_accuracy: 0.9186 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1895 - accuracy: 0.9205 - val_loss: 0.2075 - val_accuracy: 0.9163 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1808 - accuracy: 0.9246 - val_loss: 0.1990 - val_accuracy: 0.9190 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1829 - accuracy: 0.9276 - val_loss: 0.1997 - val_accuracy: 0.9175 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1790 - accuracy: 0.9257 - val_loss: 0.1983 - val_accuracy: 0.9218 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9254 - val_loss: 0.1961 - val_accuracy: 0.9210 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1768 - accuracy: 0.9249 - val_loss: 0.1967 - val_accuracy: 0.9190 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.9233 - val_loss: 0.1956 - val_accuracy: 0.9183 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9312 - val_loss: 0.1956 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1739 - accuracy: 0.9297 - val_loss: 0.1964 - val_accuracy: 0.9198 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1728 - accuracy: 0.9286 - val_loss: 0.1951 - val_accuracy: 0.9202 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.9305 - val_loss: 0.1958 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1715 - accuracy: 0.9285 - val_loss: 0.1952 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1689 - accuracy: 0.9312 - val_loss: 0.1956 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1699 - accuracy: 0.9320 - val_loss: 0.1959 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1726 - accuracy: 0.9271 - val_loss: 0.1953 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1692 - accuracy: 0.9286 - val_loss: 0.1949 - val_accuracy: 0.9206 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9323 - val_loss: 0.1950 - val_accuracy: 0.9210 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1684 - accuracy: 0.9307 - val_loss: 0.1953 - val_accuracy: 0.9206 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1668 - accuracy: 0.9308 - val_loss: 0.1949 - val_accuracy: 0.9210 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1699 - accuracy: 0.9301 - val_loss: 0.1948 - val_accuracy: 0.9210 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1676 - accuracy: 0.9312 - val_loss: 0.1947 - val_accuracy: 0.9202 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1693 - accuracy: 0.9286 - val_loss: 0.1945 - val_accuracy: 0.9210 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1701 - accuracy: 0.9308 - val_loss: 0.1943 - val_accuracy: 0.9210 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9316 - val_loss: 0.1944 - val_accuracy: 0.9214 - lr: 1.3061e-04\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9287937743190662 0.9440688383527965 0.9024390243902439 0.846696895809997 0.9232539313715202 0.9795308620893055\n",
            "Epoch 1/200\n",
            "235/241 [============================>.] - ETA: 0s - loss: 0.7189 - accuracy: 0.7814"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.7094 - accuracy: 0.7832 - val_loss: 0.3882 - val_accuracy: 0.7961 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2644 - accuracy: 0.8862 - val_loss: 0.2285 - val_accuracy: 0.8965 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.2109 - accuracy: 0.9127 - val_loss: 0.1955 - val_accuracy: 0.9198 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1954 - accuracy: 0.9207 - val_loss: 0.2108 - val_accuracy: 0.9074 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9209 - val_loss: 0.1952 - val_accuracy: 0.9093 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9327 - val_loss: 0.1752 - val_accuracy: 0.9183 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1550 - accuracy: 0.9356 - val_loss: 0.1794 - val_accuracy: 0.9226 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9408 - val_loss: 0.1731 - val_accuracy: 0.9218 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1325 - accuracy: 0.9486 - val_loss: 0.1782 - val_accuracy: 0.9171 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1287 - accuracy: 0.9497 - val_loss: 0.1667 - val_accuracy: 0.9284 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9504 - val_loss: 0.1682 - val_accuracy: 0.9257 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1157 - accuracy: 0.9526 - val_loss: 0.1624 - val_accuracy: 0.9288 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1110 - accuracy: 0.9564 - val_loss: 0.1620 - val_accuracy: 0.9300 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9558 - val_loss: 0.1688 - val_accuracy: 0.9284 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1007 - accuracy: 0.9606 - val_loss: 0.1657 - val_accuracy: 0.9311 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9641 - val_loss: 0.1646 - val_accuracy: 0.9292 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9617 - val_loss: 0.1638 - val_accuracy: 0.9296 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0920 - accuracy: 0.9643 - val_loss: 0.1664 - val_accuracy: 0.9300 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0878 - accuracy: 0.9648 - val_loss: 0.1656 - val_accuracy: 0.9304 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.1718 - val_accuracy: 0.9276 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9669 - val_loss: 0.1649 - val_accuracy: 0.9292 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0814 - accuracy: 0.9700 - val_loss: 0.1669 - val_accuracy: 0.9296 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9715 - val_loss: 0.1676 - val_accuracy: 0.9272 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.1683 - val_accuracy: 0.9300 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9694 - val_loss: 0.1673 - val_accuracy: 0.9296 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9720 - val_loss: 0.1670 - val_accuracy: 0.9304 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0785 - accuracy: 0.9705 - val_loss: 0.1664 - val_accuracy: 0.9319 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.9715 - val_loss: 0.1672 - val_accuracy: 0.9300 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.1659 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9731 - val_loss: 0.1671 - val_accuracy: 0.9311 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9699 - val_loss: 0.1665 - val_accuracy: 0.9319 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 0.1662 - val_accuracy: 0.9319 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9728 - val_loss: 0.1670 - val_accuracy: 0.9307 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0765 - accuracy: 0.9709 - val_loss: 0.1671 - val_accuracy: 0.9304 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9717 - val_loss: 0.1671 - val_accuracy: 0.9304 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 0.1671 - val_accuracy: 0.9307 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9724 - val_loss: 0.1672 - val_accuracy: 0.9307 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0769 - accuracy: 0.9711 - val_loss: 0.1670 - val_accuracy: 0.9307 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9738 - val_loss: 0.1672 - val_accuracy: 0.9304 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9746 - val_loss: 0.1675 - val_accuracy: 0.9304 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9722 - val_loss: 0.1673 - val_accuracy: 0.9307 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9716 - val_loss: 0.1671 - val_accuracy: 0.9311 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9737 - val_loss: 0.1671 - val_accuracy: 0.9315 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0760 - accuracy: 0.9716 - val_loss: 0.1672 - val_accuracy: 0.9315 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0754 - accuracy: 0.9731 - val_loss: 0.1672 - val_accuracy: 0.9311 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0739 - accuracy: 0.9731 - val_loss: 0.1672 - val_accuracy: 0.9315 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9709 - val_loss: 0.1673 - val_accuracy: 0.9311 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0766 - accuracy: 0.9715 - val_loss: 0.1671 - val_accuracy: 0.9315 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9722 - val_loss: 0.1670 - val_accuracy: 0.9311 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.928766056831452 0.9428750784682988 0.9057377049180327 0.8487814899381411 0.9243063916931658 0.9799478121494654\n",
            "Epoch 1/200\n",
            "241/241 [==============================] - ETA: 0s - loss: 1.7897 - accuracy: 0.6380"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 10ms/step - loss: 1.7897 - accuracy: 0.6380 - val_loss: 0.5892 - val_accuracy: 0.7047 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5554 - accuracy: 0.7218 - val_loss: 0.3588 - val_accuracy: 0.8117 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.3295 - accuracy: 0.8562 - val_loss: 0.2582 - val_accuracy: 0.8961 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2735 - accuracy: 0.8880 - val_loss: 0.2358 - val_accuracy: 0.8949 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2457 - accuracy: 0.8987 - val_loss: 0.2197 - val_accuracy: 0.9066 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2148 - accuracy: 0.9098 - val_loss: 0.2048 - val_accuracy: 0.9086 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2055 - accuracy: 0.9102 - val_loss: 0.1973 - val_accuracy: 0.9191 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1937 - accuracy: 0.9171 - val_loss: 0.2067 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 4s 15ms/step - loss: 0.1798 - accuracy: 0.9262 - val_loss: 0.1892 - val_accuracy: 0.9210 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1686 - accuracy: 0.9276 - val_loss: 0.1989 - val_accuracy: 0.9167 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.1647 - accuracy: 0.9325 - val_loss: 0.1843 - val_accuracy: 0.9245 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1575 - accuracy: 0.9341 - val_loss: 0.1878 - val_accuracy: 0.9230 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1497 - accuracy: 0.9408 - val_loss: 0.1844 - val_accuracy: 0.9261 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9385 - val_loss: 0.1835 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1386 - accuracy: 0.9437 - val_loss: 0.1854 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1377 - accuracy: 0.9441 - val_loss: 0.1832 - val_accuracy: 0.9249 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1345 - accuracy: 0.9432 - val_loss: 0.1801 - val_accuracy: 0.9268 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1341 - accuracy: 0.9452 - val_loss: 0.1836 - val_accuracy: 0.9230 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1241 - accuracy: 0.9512 - val_loss: 0.1814 - val_accuracy: 0.9268 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1273 - accuracy: 0.9487 - val_loss: 0.1825 - val_accuracy: 0.9268 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1234 - accuracy: 0.9516 - val_loss: 0.1874 - val_accuracy: 0.9237 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.1856 - val_accuracy: 0.9245 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1213 - accuracy: 0.9512 - val_loss: 0.1809 - val_accuracy: 0.9288 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.9516 - val_loss: 0.1801 - val_accuracy: 0.9288 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1194 - accuracy: 0.9510 - val_loss: 0.1788 - val_accuracy: 0.9280 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9533 - val_loss: 0.1820 - val_accuracy: 0.9265 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9550 - val_loss: 0.1802 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1129 - accuracy: 0.9587 - val_loss: 0.1806 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9532 - val_loss: 0.1805 - val_accuracy: 0.9292 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.9541 - val_loss: 0.1814 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1189 - accuracy: 0.9533 - val_loss: 0.1812 - val_accuracy: 0.9276 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1143 - accuracy: 0.9543 - val_loss: 0.1813 - val_accuracy: 0.9280 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1121 - accuracy: 0.9573 - val_loss: 0.1808 - val_accuracy: 0.9265 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9550 - val_loss: 0.1800 - val_accuracy: 0.9300 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9561 - val_loss: 0.1801 - val_accuracy: 0.9296 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9548 - val_loss: 0.1802 - val_accuracy: 0.9292 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9550 - val_loss: 0.1803 - val_accuracy: 0.9284 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9555 - val_loss: 0.1803 - val_accuracy: 0.9288 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9563 - val_loss: 0.1802 - val_accuracy: 0.9288 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9578 - val_loss: 0.1802 - val_accuracy: 0.9296 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9571 - val_loss: 0.1805 - val_accuracy: 0.9284 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1121 - accuracy: 0.9542 - val_loss: 0.1804 - val_accuracy: 0.9288 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9571 - val_loss: 0.1804 - val_accuracy: 0.9296 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9556 - val_loss: 0.1805 - val_accuracy: 0.9280 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9565 - val_loss: 0.1804 - val_accuracy: 0.9288 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9537 - val_loss: 0.1803 - val_accuracy: 0.9300 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9583 - val_loss: 0.1805 - val_accuracy: 0.9296 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1134 - accuracy: 0.9571 - val_loss: 0.1803 - val_accuracy: 0.9300 - lr: 2.8211e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9194239003503308 0.9331269349845202 0.8962264150943396 0.8277784956349171 0.91467667503943 0.9742229231977465\n",
            "Epoch 1/200\n",
            "237/241 [============================>.] - ETA: 0s - loss: 0.8224 - accuracy: 0.7725"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.8136 - accuracy: 0.7748 - val_loss: 0.3375 - val_accuracy: 0.8634 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2648 - accuracy: 0.8876 - val_loss: 0.2330 - val_accuracy: 0.9016 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2249 - accuracy: 0.9049 - val_loss: 0.2236 - val_accuracy: 0.9051 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 4s 15ms/step - loss: 0.2066 - accuracy: 0.9116 - val_loss: 0.2009 - val_accuracy: 0.9167 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9186 - val_loss: 0.1998 - val_accuracy: 0.9136 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1746 - accuracy: 0.9267 - val_loss: 0.1853 - val_accuracy: 0.9233 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1679 - accuracy: 0.9281 - val_loss: 0.1869 - val_accuracy: 0.9230 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9353 - val_loss: 0.1937 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1459 - accuracy: 0.9403 - val_loss: 0.1805 - val_accuracy: 0.9280 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1382 - accuracy: 0.9430 - val_loss: 0.1781 - val_accuracy: 0.9280 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1345 - accuracy: 0.9441 - val_loss: 0.1734 - val_accuracy: 0.9284 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1216 - accuracy: 0.9499 - val_loss: 0.1776 - val_accuracy: 0.9268 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1165 - accuracy: 0.9556 - val_loss: 0.1723 - val_accuracy: 0.9276 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1142 - accuracy: 0.9550 - val_loss: 0.1731 - val_accuracy: 0.9300 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1084 - accuracy: 0.9583 - val_loss: 0.1694 - val_accuracy: 0.9323 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1059 - accuracy: 0.9580 - val_loss: 0.1698 - val_accuracy: 0.9346 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1054 - accuracy: 0.9569 - val_loss: 0.1677 - val_accuracy: 0.9339 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0967 - accuracy: 0.9630 - val_loss: 0.1693 - val_accuracy: 0.9319 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0978 - accuracy: 0.9619 - val_loss: 0.1700 - val_accuracy: 0.9339 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.1704 - val_accuracy: 0.9327 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0943 - accuracy: 0.9626 - val_loss: 0.1702 - val_accuracy: 0.9350 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9672 - val_loss: 0.1714 - val_accuracy: 0.9331 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9664 - val_loss: 0.1717 - val_accuracy: 0.9350 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9668 - val_loss: 0.1709 - val_accuracy: 0.9339 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9704 - val_loss: 0.1713 - val_accuracy: 0.9339 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0837 - accuracy: 0.9695 - val_loss: 0.1703 - val_accuracy: 0.9366 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9685 - val_loss: 0.1703 - val_accuracy: 0.9335 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9690 - val_loss: 0.1705 - val_accuracy: 0.9346 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9669 - val_loss: 0.1704 - val_accuracy: 0.9358 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9699 - val_loss: 0.1703 - val_accuracy: 0.9350 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9708 - val_loss: 0.1701 - val_accuracy: 0.9350 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0831 - accuracy: 0.9703 - val_loss: 0.1699 - val_accuracy: 0.9354 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0830 - accuracy: 0.9708 - val_loss: 0.1700 - val_accuracy: 0.9354 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9700 - val_loss: 0.1700 - val_accuracy: 0.9342 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9695 - val_loss: 0.1703 - val_accuracy: 0.9350 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9716 - val_loss: 0.1703 - val_accuracy: 0.9346 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0784 - accuracy: 0.9716 - val_loss: 0.1704 - val_accuracy: 0.9350 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0816 - accuracy: 0.9705 - val_loss: 0.1704 - val_accuracy: 0.9350 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9703 - val_loss: 0.1704 - val_accuracy: 0.9350 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0804 - accuracy: 0.9715 - val_loss: 0.1702 - val_accuracy: 0.9358 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9702 - val_loss: 0.1704 - val_accuracy: 0.9350 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9704 - val_loss: 0.1704 - val_accuracy: 0.9358 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9702 - val_loss: 0.1706 - val_accuracy: 0.9354 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 0.1703 - val_accuracy: 0.9362 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9704 - val_loss: 0.1704 - val_accuracy: 0.9362 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.0808 - accuracy: 0.9722 - val_loss: 0.1703 - val_accuracy: 0.9362 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.9408330089529 0.9547427154370738 0.9173640167364017 0.8732338087551562 0.9360533660867377 0.9867787744450814\n",
            "Epoch 1/200\n",
            "234/241 [============================>.] - ETA: 0s - loss: 1.0040 - accuracy: 0.7561"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 0.9836 - accuracy: 0.7592 - val_loss: 0.3130 - val_accuracy: 0.8630 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2921 - accuracy: 0.8735 - val_loss: 0.2387 - val_accuracy: 0.9000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2421 - accuracy: 0.9000 - val_loss: 0.2197 - val_accuracy: 0.9078 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2294 - accuracy: 0.9023 - val_loss: 0.2086 - val_accuracy: 0.9160 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2189 - accuracy: 0.9097 - val_loss: 0.1993 - val_accuracy: 0.9148 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1939 - accuracy: 0.9166 - val_loss: 0.1990 - val_accuracy: 0.9152 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1914 - accuracy: 0.9189 - val_loss: 0.1863 - val_accuracy: 0.9226 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1837 - accuracy: 0.9240 - val_loss: 0.1957 - val_accuracy: 0.9121 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1710 - accuracy: 0.9337 - val_loss: 0.1803 - val_accuracy: 0.9241 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1611 - accuracy: 0.9319 - val_loss: 0.1828 - val_accuracy: 0.9253 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1612 - accuracy: 0.9347 - val_loss: 0.1768 - val_accuracy: 0.9261 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1503 - accuracy: 0.9381 - val_loss: 0.1768 - val_accuracy: 0.9265 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.1469 - accuracy: 0.9411 - val_loss: 0.1748 - val_accuracy: 0.9315 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1409 - accuracy: 0.9462 - val_loss: 0.1757 - val_accuracy: 0.9292 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.9462 - val_loss: 0.1705 - val_accuracy: 0.9315 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1334 - accuracy: 0.9464 - val_loss: 0.1683 - val_accuracy: 0.9381 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1314 - accuracy: 0.9459 - val_loss: 0.1748 - val_accuracy: 0.9272 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9477 - val_loss: 0.1684 - val_accuracy: 0.9358 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9511 - val_loss: 0.1679 - val_accuracy: 0.9335 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.9513 - val_loss: 0.1688 - val_accuracy: 0.9362 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1175 - accuracy: 0.9548 - val_loss: 0.1675 - val_accuracy: 0.9389 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9572 - val_loss: 0.1667 - val_accuracy: 0.9377 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1165 - accuracy: 0.9555 - val_loss: 0.1660 - val_accuracy: 0.9381 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9564 - val_loss: 0.1676 - val_accuracy: 0.9385 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1137 - accuracy: 0.9574 - val_loss: 0.1650 - val_accuracy: 0.9397 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9547 - val_loss: 0.1650 - val_accuracy: 0.9385 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9565 - val_loss: 0.1646 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1094 - accuracy: 0.9558 - val_loss: 0.1646 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1098 - accuracy: 0.9558 - val_loss: 0.1653 - val_accuracy: 0.9377 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9572 - val_loss: 0.1648 - val_accuracy: 0.9393 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1060 - accuracy: 0.9612 - val_loss: 0.1650 - val_accuracy: 0.9389 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.9556 - val_loss: 0.1651 - val_accuracy: 0.9381 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.1647 - val_accuracy: 0.9377 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1067 - accuracy: 0.9590 - val_loss: 0.1647 - val_accuracy: 0.9377 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9582 - val_loss: 0.1648 - val_accuracy: 0.9385 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9594 - val_loss: 0.1648 - val_accuracy: 0.9381 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9587 - val_loss: 0.1647 - val_accuracy: 0.9389 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9582 - val_loss: 0.1645 - val_accuracy: 0.9393 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1075 - accuracy: 0.9587 - val_loss: 0.1645 - val_accuracy: 0.9393 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9587 - val_loss: 0.1646 - val_accuracy: 0.9389 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9602 - val_loss: 0.1645 - val_accuracy: 0.9389 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9580 - val_loss: 0.1644 - val_accuracy: 0.9389 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9568 - val_loss: 0.1644 - val_accuracy: 0.9393 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1066 - accuracy: 0.9598 - val_loss: 0.1644 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1075 - accuracy: 0.9596 - val_loss: 0.1643 - val_accuracy: 0.9389 - lr: 4.7018e-05\n",
            "2569/2569 [==============================] - 4s 2ms/step\n",
            "0.9338263915920592 0.948134092346616 0.9109311740890689 0.8600552674752554 0.9295326332178424 0.9818774055266615\n",
            "Epoch 1/200\n",
            "231/241 [===========================>..] - ETA: 0s - loss: 1.0422 - accuracy: 0.6771"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 1.0228 - accuracy: 0.6808 - val_loss: 0.5725 - val_accuracy: 0.7505 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4487 - accuracy: 0.7977 - val_loss: 0.3401 - val_accuracy: 0.8194 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2785 - accuracy: 0.8801 - val_loss: 0.2454 - val_accuracy: 0.8906 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2428 - accuracy: 0.8987 - val_loss: 0.2223 - val_accuracy: 0.9019 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2228 - accuracy: 0.9058 - val_loss: 0.2272 - val_accuracy: 0.8984 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1993 - accuracy: 0.9158 - val_loss: 0.2051 - val_accuracy: 0.9163 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1933 - accuracy: 0.9137 - val_loss: 0.2075 - val_accuracy: 0.9101 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9245 - val_loss: 0.2028 - val_accuracy: 0.9159 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1658 - accuracy: 0.9340 - val_loss: 0.2030 - val_accuracy: 0.9155 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1628 - accuracy: 0.9319 - val_loss: 0.1918 - val_accuracy: 0.9190 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1586 - accuracy: 0.9343 - val_loss: 0.1967 - val_accuracy: 0.9214 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.9415 - val_loss: 0.1927 - val_accuracy: 0.9214 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.1441 - accuracy: 0.9410 - val_loss: 0.1918 - val_accuracy: 0.9245 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1390 - accuracy: 0.9414 - val_loss: 0.1893 - val_accuracy: 0.9233 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1314 - accuracy: 0.9452 - val_loss: 0.1867 - val_accuracy: 0.9280 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1305 - accuracy: 0.9503 - val_loss: 0.1868 - val_accuracy: 0.9299 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1286 - accuracy: 0.9500 - val_loss: 0.1882 - val_accuracy: 0.9319 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1235 - accuracy: 0.9511 - val_loss: 0.1906 - val_accuracy: 0.9264 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1195 - accuracy: 0.9533 - val_loss: 0.1876 - val_accuracy: 0.9327 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.9523 - val_loss: 0.1872 - val_accuracy: 0.9311 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.9508 - val_loss: 0.1869 - val_accuracy: 0.9303 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9561 - val_loss: 0.1881 - val_accuracy: 0.9303 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9539 - val_loss: 0.1866 - val_accuracy: 0.9315 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9595 - val_loss: 0.1862 - val_accuracy: 0.9311 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9561 - val_loss: 0.1879 - val_accuracy: 0.9319 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9568 - val_loss: 0.1868 - val_accuracy: 0.9319 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1107 - accuracy: 0.9572 - val_loss: 0.1863 - val_accuracy: 0.9303 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1089 - accuracy: 0.9583 - val_loss: 0.1858 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9576 - val_loss: 0.1859 - val_accuracy: 0.9311 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9602 - val_loss: 0.1864 - val_accuracy: 0.9323 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9580 - val_loss: 0.1860 - val_accuracy: 0.9323 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9577 - val_loss: 0.1870 - val_accuracy: 0.9319 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9560 - val_loss: 0.1861 - val_accuracy: 0.9315 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9598 - val_loss: 0.1859 - val_accuracy: 0.9323 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9585 - val_loss: 0.1866 - val_accuracy: 0.9307 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1078 - accuracy: 0.9591 - val_loss: 0.1856 - val_accuracy: 0.9330 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1059 - accuracy: 0.9585 - val_loss: 0.1853 - val_accuracy: 0.9330 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9602 - val_loss: 0.1860 - val_accuracy: 0.9327 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1044 - accuracy: 0.9580 - val_loss: 0.1860 - val_accuracy: 0.9327 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.1860 - val_accuracy: 0.9330 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9573 - val_loss: 0.1861 - val_accuracy: 0.9330 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9571 - val_loss: 0.1862 - val_accuracy: 0.9330 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1096 - accuracy: 0.9556 - val_loss: 0.1859 - val_accuracy: 0.9334 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1025 - accuracy: 0.9604 - val_loss: 0.1858 - val_accuracy: 0.9334 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9580 - val_loss: 0.1859 - val_accuracy: 0.9334 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9583 - val_loss: 0.1861 - val_accuracy: 0.9334 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9581 - val_loss: 0.1861 - val_accuracy: 0.9334 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9594 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9594 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9576 - val_loss: 0.1861 - val_accuracy: 0.9334 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9604 - val_loss: 0.1861 - val_accuracy: 0.9334 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1044 - accuracy: 0.9586 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9580 - val_loss: 0.1859 - val_accuracy: 0.9334 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9567 - val_loss: 0.1859 - val_accuracy: 0.9334 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1042 - accuracy: 0.9608 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9600 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1072 - accuracy: 0.9578 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9591 - val_loss: 0.1859 - val_accuracy: 0.9334 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9586 - val_loss: 0.1859 - val_accuracy: 0.9334 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1074 - accuracy: 0.9574 - val_loss: 0.1861 - val_accuracy: 0.9334 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1065 - accuracy: 0.9576 - val_loss: 0.1861 - val_accuracy: 0.9334 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9578 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "241/241 [==============================] - 1s 6ms/step - loss: 0.1042 - accuracy: 0.9596 - val_loss: 0.1860 - val_accuracy: 0.9334 - lr: 2.1937e-06\n",
            "2570/2570 [==============================] - 4s 1ms/step\n",
            "0.9389105058365759 0.9471419791026429 0.9247083775185578 0.8690130515613773 0.9359251783106004 0.9848581825386944\n",
            "Epoch 1/200\n",
            "231/241 [===========================>..] - ETA: 0s - loss: 3.0690 - accuracy: 0.6135"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 2.9722 - accuracy: 0.6111 - val_loss: 0.6612 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6645 - accuracy: 0.6250 - val_loss: 0.6621 - val_accuracy: 0.6261 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6616 - accuracy: 0.6264 - val_loss: 0.6617 - val_accuracy: 0.6261 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6616 - accuracy: 0.6258 - val_loss: 0.6610 - val_accuracy: 0.6261 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6615 - accuracy: 0.6255 - val_loss: 0.6610 - val_accuracy: 0.6261 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6607 - accuracy: 0.6264 - val_loss: 0.6613 - val_accuracy: 0.6261 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6613 - accuracy: 0.6241 - val_loss: 0.6610 - val_accuracy: 0.6261 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6610 - accuracy: 0.6258 - val_loss: 0.6595 - val_accuracy: 0.6261 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.6472 - val_loss: 0.6606 - val_accuracy: 0.6261 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.6346 - accuracy: 0.6590 - val_loss: 0.6050 - val_accuracy: 0.7027 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6220 - accuracy: 0.6693 - val_loss: 0.5958 - val_accuracy: 0.6911 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.6007 - accuracy: 0.6911 - val_loss: 0.5855 - val_accuracy: 0.7031 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 3s 12ms/step - loss: 0.5974 - accuracy: 0.6943 - val_loss: 0.5856 - val_accuracy: 0.7051 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.5927 - accuracy: 0.6996 - val_loss: 0.5819 - val_accuracy: 0.7082 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5910 - accuracy: 0.7014 - val_loss: 0.5815 - val_accuracy: 0.7074 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5871 - accuracy: 0.7034 - val_loss: 0.5771 - val_accuracy: 0.7097 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5814 - accuracy: 0.7064 - val_loss: 0.5675 - val_accuracy: 0.7113 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.7086 - val_loss: 0.5771 - val_accuracy: 0.7089 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.5648 - accuracy: 0.7208 - val_loss: 0.5418 - val_accuracy: 0.7249 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5626 - accuracy: 0.7216 - val_loss: 0.5334 - val_accuracy: 0.7424 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.7388 - val_loss: 0.5264 - val_accuracy: 0.7280 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7476 - val_loss: 0.5228 - val_accuracy: 0.7276 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5240 - accuracy: 0.7584 - val_loss: 0.5014 - val_accuracy: 0.7436 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5003 - accuracy: 0.7785 - val_loss: 0.4865 - val_accuracy: 0.7588 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4936 - accuracy: 0.7855 - val_loss: 0.4546 - val_accuracy: 0.8179 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.7842 - val_loss: 0.4429 - val_accuracy: 0.8082 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.8055 - val_loss: 0.4350 - val_accuracy: 0.8128 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.7982 - val_loss: 0.4409 - val_accuracy: 0.7965 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4618 - accuracy: 0.8090 - val_loss: 0.4285 - val_accuracy: 0.8533 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4526 - accuracy: 0.8128 - val_loss: 0.4174 - val_accuracy: 0.8195 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4527 - accuracy: 0.8086 - val_loss: 0.4069 - val_accuracy: 0.8393 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4458 - accuracy: 0.8206 - val_loss: 0.4007 - val_accuracy: 0.8506 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.8226 - val_loss: 0.4041 - val_accuracy: 0.8296 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4406 - accuracy: 0.8204 - val_loss: 0.3979 - val_accuracy: 0.8424 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4374 - accuracy: 0.8247 - val_loss: 0.3926 - val_accuracy: 0.8603 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.8298 - val_loss: 0.4034 - val_accuracy: 0.8272 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.4326 - accuracy: 0.8255 - val_loss: 0.3892 - val_accuracy: 0.8630 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.8207 - val_loss: 0.3883 - val_accuracy: 0.8615 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.8364 - val_loss: 0.3947 - val_accuracy: 0.8381 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4303 - accuracy: 0.8274 - val_loss: 0.3905 - val_accuracy: 0.8479 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4302 - accuracy: 0.8276 - val_loss: 0.3925 - val_accuracy: 0.8401 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4343 - accuracy: 0.8238 - val_loss: 0.3900 - val_accuracy: 0.8451 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4293 - accuracy: 0.8264 - val_loss: 0.3927 - val_accuracy: 0.8385 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4251 - accuracy: 0.8308 - val_loss: 0.3907 - val_accuracy: 0.8432 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4239 - accuracy: 0.8305 - val_loss: 0.3868 - val_accuracy: 0.8560 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4273 - accuracy: 0.8302 - val_loss: 0.3904 - val_accuracy: 0.8432 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4271 - accuracy: 0.8320 - val_loss: 0.3970 - val_accuracy: 0.8307 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8300 - val_loss: 0.3865 - val_accuracy: 0.8553 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4293 - accuracy: 0.8296 - val_loss: 0.3915 - val_accuracy: 0.8397 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8299 - val_loss: 0.3859 - val_accuracy: 0.8572 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.8285 - val_loss: 0.3862 - val_accuracy: 0.8560 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.8346 - val_loss: 0.3856 - val_accuracy: 0.8576 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.8312 - val_loss: 0.3880 - val_accuracy: 0.8482 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.8330 - val_loss: 0.3867 - val_accuracy: 0.8553 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4255 - accuracy: 0.8309 - val_loss: 0.3862 - val_accuracy: 0.8553 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8292 - val_loss: 0.3854 - val_accuracy: 0.8580 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.4283 - accuracy: 0.8324 - val_loss: 0.3863 - val_accuracy: 0.8564 - lr: 6.0936e-06\n",
            "2569/2569 [==============================] - 4s 1ms/step\n",
            "0.8711560918645387 0.9259259259259259 0.7817622950819673 0.7236033828310703 0.8538441105039466 0.9313379874039085\n",
            "Epoch 1/200\n",
            "240/241 [============================>.] - ETA: 0s - loss: 2.0134 - accuracy: 0.6159"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 9ms/step - loss: 2.0087 - accuracy: 0.6159 - val_loss: 0.6559 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6621 - accuracy: 0.6228 - val_loss: 0.6491 - val_accuracy: 0.6241 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.6384 - accuracy: 0.6581 - val_loss: 0.6196 - val_accuracy: 0.6856 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.6296 - accuracy: 0.6680 - val_loss: 0.6082 - val_accuracy: 0.6875 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6229 - accuracy: 0.6745 - val_loss: 0.6115 - val_accuracy: 0.6848 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.6134 - accuracy: 0.6834 - val_loss: 0.6056 - val_accuracy: 0.6848 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.6020 - accuracy: 0.6903 - val_loss: 0.5928 - val_accuracy: 0.6922 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.5708 - accuracy: 0.7021 - val_loss: 0.5603 - val_accuracy: 0.7058 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.4121 - accuracy: 0.8059 - val_loss: 0.3368 - val_accuracy: 0.8665 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 4s 18ms/step - loss: 0.3275 - accuracy: 0.8579 - val_loss: 0.2877 - val_accuracy: 0.8712 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 3s 13ms/step - loss: 0.2921 - accuracy: 0.8745 - val_loss: 0.2438 - val_accuracy: 0.8984 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2651 - accuracy: 0.8878 - val_loss: 0.2602 - val_accuracy: 0.8864 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2537 - accuracy: 0.8911 - val_loss: 0.2446 - val_accuracy: 0.9008 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 3s 11ms/step - loss: 0.2447 - accuracy: 0.8958 - val_loss: 0.2181 - val_accuracy: 0.9121 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2383 - accuracy: 0.9002 - val_loss: 0.2169 - val_accuracy: 0.9113 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2357 - accuracy: 0.9029 - val_loss: 0.2193 - val_accuracy: 0.9121 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2291 - accuracy: 0.9053 - val_loss: 0.2163 - val_accuracy: 0.9140 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2251 - accuracy: 0.9083 - val_loss: 0.2097 - val_accuracy: 0.9125 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2153 - accuracy: 0.9116 - val_loss: 0.2082 - val_accuracy: 0.9117 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2209 - accuracy: 0.9087 - val_loss: 0.2139 - val_accuracy: 0.9070 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2089 - accuracy: 0.9118 - val_loss: 0.2064 - val_accuracy: 0.9132 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9145 - val_loss: 0.2065 - val_accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2152 - accuracy: 0.9080 - val_loss: 0.2063 - val_accuracy: 0.9148 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2046 - accuracy: 0.9142 - val_loss: 0.2059 - val_accuracy: 0.9125 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.2075 - accuracy: 0.9141 - val_loss: 0.2047 - val_accuracy: 0.9171 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 3s 14ms/step - loss: 0.2056 - accuracy: 0.9171 - val_loss: 0.2031 - val_accuracy: 0.9179 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2054 - accuracy: 0.9172 - val_loss: 0.2028 - val_accuracy: 0.9167 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9154 - val_loss: 0.2029 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9162 - val_loss: 0.2031 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 1s 5ms/step - loss: 0.2016 - accuracy: 0.9153 - val_loss: 0.2039 - val_accuracy: 0.9128 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "163/241 [===================>..........] - ETA: 0s - loss: 0.2010 - accuracy: 0.9162"
          ]
        }
      ],
      "source": [
        "# 5-Fold CV\n",
        "final_ACC_collection_cv = []\n",
        "final_BACC_collection_cv = []\n",
        "final_Sn_collection_cv = []\n",
        "final_Sp_collection_cv = []\n",
        "final_MCC_collection_cv = []\n",
        "final_AUC_collection_cv = []\n",
        "\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "\n",
        "# split dataset\n",
        "for i in range(len(CNN_channel)):\n",
        "  # collect the value in cross validation\n",
        "  ACC_collection_cv = []\n",
        "  BACC_collection_cv = []\n",
        "  Sn_collection_cv = []\n",
        "  Sp_collection_cv = []\n",
        "  MCC_collection_cv = []\n",
        "  AUC_collection_cv = []\n",
        "\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(X_train_whole, y_train_whole):\n",
        "      X_train, X_valid = X[train_ix], X[test_ix]\n",
        "      y_train, y_valid = y[train_ix], y[test_ix]\n",
        "      X_train_only, X_train_indicator, y_train_only, y_train_indicator = train_test_split( X_train, y_train, test_size=0.25, random_state=random_num,shuffle=True, stratify = y_train)\n",
        "\n",
        "      # train the model\n",
        "      saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i])\n",
        "\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_valid, y_valid)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFQapXWWcXig"
      },
      "outputs": [],
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s74WqstjYVus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgOX83DaYVzr"
      },
      "source": [
        "### final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffef1dd-b805-44c1-cf44-7f743f1b0a7c",
        "id": "UU7lP_7IYVzr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5 5 5\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [64,64,64,32,16,128,16,64,64]\n",
        "dense_node = [8192,2048,8192,8192,2048,4096,2048,1024,1024]\n",
        "kernel_size = [12,12,6,9,12,6,9,9,6]\n",
        "stride_size = [2,4,4,2,2,4,2,1,4]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xBglU_YYVzs"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(640,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "Emh21cZNYVzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcIpzRT5YVzs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t30_150M_UR50D_unified_640_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "cX1bcMe5YVzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO2xbH2kYVzt"
      },
      "outputs": [],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',BACC_collection_test, '\\n',Sn_collection_test, '\\n',Sp_collection_test, '\\n',MCC_collection_test,'\\n', AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shaxu0Gh5DsV"
      },
      "source": [
        "### 1280 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nkHCRyydkIQ"
      },
      "source": [
        "#### defined function for model development and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea9RXDdgdkIR"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, X_valid, y_train, y_valid, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(1280,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "  # set checkpoint and save the best model\n",
        "  mc = ModelCheckpoint('best_model_grid_1280.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lr , early_stop, mc]\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  saved_model = load_model('best_model_grid_1280.h5')\n",
        "  return saved_model\n",
        "\n",
        "  # import gc\n",
        "  # del model\n",
        "  # del saved_model\n",
        "  # import torch\n",
        "  # import gc\n",
        "  # torch.cuda.memory_reserved()\n",
        "  # gc.collect()\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkIhO_TpdWpz"
      },
      "source": [
        "#### 5 Fold CV for optimal hyperparrameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrCHpEZXdWpz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HumcjrGgdWpz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "random_num = 1\n",
        "X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6VUfqtqdWp0",
        "outputId": "4ae3dbda-28f9-46bc-8fec-1e372fe6d99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42 42 42 42\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [32, 128, 32, 32, 32, 16, 64, 16, 16, 64, 64, 64, 43, 128, 64, 16, 128, 64, 128, 16, 128, 16, 64, 16, 16, 256, 32, 16, 32, 128, 16, 32, 32, 64, 256, 128, 128, 16, 64, 32, 128, 256]\n",
        "dense_node = [8192, 4096, 1024, 8192, 2048, 1024, 4096, 512, 8192, 2048, 512, 256, 512, 1024, 1024, 2048, 4096, 1024, 512, 128, 1024, 1024, 512, 256, 32, 32, 32, 64, 64, 64, 128, 128, 128, 256, 256, 256, 256, 512, 512, 512, 512, 256]\n",
        "kernel_size = [9, 12, 9, 9, 6, 12, 9, 12, 12, 9, 9, 12, 6, 12, 9, 12, 12, 12, 12, 12, 12, 6, 12, 3, 12, 6, 12, 6, 12, 12, 12, 12, 12, 12, 9, 9, 9, 12, 9, 6, 12, 9]\n",
        "stride_size = [2, 8, 8, 8, 1, 2, 2, 1, 2, 2, 8, 2, 8, 1, 2, 2, 2, 4, 8, 1, 2, 4, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 8, 2, 1, 8, 8, 8, 1]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXdTM8SkdWp0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "2qIEJ66FdWp1",
        "outputId": "c3111581-5ea9-4d2f-d78e-c24313b2f729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b8b85196bd39>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0;31m# saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_indicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_indicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-79738f05ec72>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, X_valid, y_train, y_valid, filter_size, kernel_size, stride_size, node_units)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m# summary the callbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0;31m# load the save best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model_grid_1280.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 5-Fold CV\n",
        "final_ACC_collection_cv = []\n",
        "final_BACC_collection_cv = []\n",
        "final_Sn_collection_cv = []\n",
        "final_Sp_collection_cv = []\n",
        "final_MCC_collection_cv = []\n",
        "final_AUC_collection_cv = []\n",
        "\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "\n",
        "# split dataset\n",
        "for a in range(len(CNN_channel)):\n",
        "  i = a + 5\n",
        "  # collect the value in cross validation\n",
        "  ACC_collection_cv = []\n",
        "  BACC_collection_cv = []\n",
        "  Sn_collection_cv = []\n",
        "  Sp_collection_cv = []\n",
        "  MCC_collection_cv = []\n",
        "  AUC_collection_cv = []\n",
        "\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(X_train_whole, y_train_whole):\n",
        "      X_train, X_valid = X[train_ix], X[test_ix]\n",
        "      y_train, y_valid = y[train_ix], y[test_ix]\n",
        "      X_train_only, X_train_indicator, y_train_only, y_train_indicator = train_test_split( X_train, y_train, test_size=0.25, random_state=random_num,shuffle=True, stratify = y_train)\n",
        "\n",
        "      # train the model\n",
        "      # saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i])\n",
        "      saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,128,9,2,256)\n",
        "\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_valid, y_valid)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tWWEdd5t8C6Q",
        "outputId": "db79e5dc-b4a8-44be-c971-bc84dbce01e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "241/241 [==============================] - 7s 11ms/step - loss: 0.9252 - accuracy: 0.7964 - val_loss: 0.4502 - val_accuracy: 0.8295 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "  1/241 [..............................] - ETA: 2s - loss: 0.3719 - accuracy: 0.8750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "241/241 [==============================] - 2s 10ms/step - loss: 0.2314 - accuracy: 0.8993 - val_loss: 0.2369 - val_accuracy: 0.9023 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1850 - accuracy: 0.9193 - val_loss: 0.1866 - val_accuracy: 0.9190 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1730 - accuracy: 0.9253 - val_loss: 0.1794 - val_accuracy: 0.9221 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1588 - accuracy: 0.9276 - val_loss: 0.1765 - val_accuracy: 0.9249 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 10ms/step - loss: 0.1416 - accuracy: 0.9350 - val_loss: 0.1761 - val_accuracy: 0.9292 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1319 - accuracy: 0.9424 - val_loss: 0.1793 - val_accuracy: 0.9264 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1257 - accuracy: 0.9464 - val_loss: 0.1804 - val_accuracy: 0.9299 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1140 - accuracy: 0.9480 - val_loss: 0.1921 - val_accuracy: 0.9307 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.1060 - accuracy: 0.9524 - val_loss: 0.2031 - val_accuracy: 0.9276 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.1032 - accuracy: 0.9547 - val_loss: 0.1971 - val_accuracy: 0.9358 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.0955 - accuracy: 0.9598 - val_loss: 0.1787 - val_accuracy: 0.9362 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0886 - accuracy: 0.9634 - val_loss: 0.1912 - val_accuracy: 0.9350 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0883 - accuracy: 0.9604 - val_loss: 0.1969 - val_accuracy: 0.9346 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.0823 - accuracy: 0.9650 - val_loss: 0.1887 - val_accuracy: 0.9366 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0797 - accuracy: 0.9667 - val_loss: 0.1888 - val_accuracy: 0.9354 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.0787 - accuracy: 0.9661 - val_loss: 0.1972 - val_accuracy: 0.9377 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0715 - accuracy: 0.9690 - val_loss: 0.1961 - val_accuracy: 0.9366 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0718 - accuracy: 0.9699 - val_loss: 0.2088 - val_accuracy: 0.9373 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0736 - accuracy: 0.9694 - val_loss: 0.2019 - val_accuracy: 0.9358 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0717 - accuracy: 0.9694 - val_loss: 0.1976 - val_accuracy: 0.9358 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.0696 - accuracy: 0.9716 - val_loss: 0.2003 - val_accuracy: 0.9397 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0704 - accuracy: 0.9734 - val_loss: 0.1968 - val_accuracy: 0.9397 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0679 - accuracy: 0.9730 - val_loss: 0.2027 - val_accuracy: 0.9393 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0670 - accuracy: 0.9734 - val_loss: 0.2025 - val_accuracy: 0.9373 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0659 - accuracy: 0.9747 - val_loss: 0.2039 - val_accuracy: 0.9369 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0655 - accuracy: 0.9718 - val_loss: 0.2004 - val_accuracy: 0.9377 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.0638 - accuracy: 0.9752 - val_loss: 0.2048 - val_accuracy: 0.9404 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: 0.0675 - accuracy: 0.9724 - val_loss: 0.2028 - val_accuracy: 0.9408 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0632 - accuracy: 0.9748 - val_loss: 0.2029 - val_accuracy: 0.9385 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0635 - accuracy: 0.9744 - val_loss: 0.2034 - val_accuracy: 0.9377 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0625 - accuracy: 0.9735 - val_loss: 0.2058 - val_accuracy: 0.9381 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0639 - accuracy: 0.9733 - val_loss: 0.2061 - val_accuracy: 0.9393 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0626 - accuracy: 0.9743 - val_loss: 0.2057 - val_accuracy: 0.9385 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0622 - accuracy: 0.9760 - val_loss: 0.2066 - val_accuracy: 0.9381 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0636 - accuracy: 0.9731 - val_loss: 0.2051 - val_accuracy: 0.9393 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0613 - accuracy: 0.9759 - val_loss: 0.2063 - val_accuracy: 0.9385 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0626 - accuracy: 0.9756 - val_loss: 0.2065 - val_accuracy: 0.9393 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0633 - accuracy: 0.9750 - val_loss: 0.2067 - val_accuracy: 0.9381 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0633 - accuracy: 0.9757 - val_loss: 0.2064 - val_accuracy: 0.9385 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0603 - accuracy: 0.9773 - val_loss: 0.2067 - val_accuracy: 0.9385 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0628 - accuracy: 0.9753 - val_loss: 0.2064 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0622 - accuracy: 0.9753 - val_loss: 0.2063 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0638 - accuracy: 0.9743 - val_loss: 0.2066 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0617 - accuracy: 0.9744 - val_loss: 0.2065 - val_accuracy: 0.9385 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0604 - accuracy: 0.9742 - val_loss: 0.2065 - val_accuracy: 0.9389 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0643 - accuracy: 0.9743 - val_loss: 0.2063 - val_accuracy: 0.9389 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0628 - accuracy: 0.9730 - val_loss: 0.2061 - val_accuracy: 0.9389 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: 0.0621 - accuracy: 0.9743 - val_loss: 0.2061 - val_accuracy: 0.9389 - lr: 2.8211e-05\n",
            "2570/2570 [==============================] - 4s 2ms/step\n",
            "0.9439688715953307 0.9465273509526736 0.9395546129374337 0.8804701587315464 0.9430409819450536 0.9880945940749326\n",
            "Epoch 1/200\n",
            "235/241 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.3855"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/241 [==============================] - 3s 11ms/step - loss: nan - accuracy: 0.3841 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.3737 - val_loss: nan - val_accuracy: 0.3739 - lr: 0.0028\n",
            "2569/2569 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-53500e58df93>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_indicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_indicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mACC_collection_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-79738f05ec72>\u001b[0m in \u001b[0;36mcheck_performance\u001b[0;34m(saved_model, X_test, y_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mpredicted_protability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_protability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_protability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_protability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mpredicted_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScmmIqB9z52n"
      },
      "outputs": [],
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mkx0-LgiYYD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ69ACU5YYKi"
      },
      "source": [
        "#### final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffef1dd-b805-44c1-cf44-7f743f1b0a7c",
        "id": "Js4WDSZTYYKi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5 5 5\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [128,32,32,16,64,64,128,16,32]\n",
        "dense_node = [4096,1024,8192,8192,2048,1024,1024,1024,512]\n",
        "kernel_size = [12,9,9,12,9,12,12,6,6]\n",
        "stride_size = [8,8,8,2,2,4,2,4,8]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkwBYtdHYYKj"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(1280,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "P3STxYcEYYKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNXSFI-kYYKj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "YZs-gGIKYYKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a803b80a-0d3f-4e6f-d727-c804e3f625df",
        "id": "KfcaJcquYYKk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "402/402 [==============================] - 6s 4ms/step - loss: 0.6932 - accuracy: 0.8106 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2737 - accuracy: 0.8842 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2359 - accuracy: 0.8999 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2206 - accuracy: 0.9081 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2108 - accuracy: 0.9126 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1892 - accuracy: 0.9222 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1859 - accuracy: 0.9232 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1786 - accuracy: 0.9269 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9334 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9357 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9383 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9407 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9420 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9431 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1386 - accuracy: 0.9462 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1335 - accuracy: 0.9471 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1334 - accuracy: 0.9492 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1287 - accuracy: 0.9502 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9516 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1245 - accuracy: 0.9530 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1253 - accuracy: 0.9517 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.9534 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9536 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9552 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1189 - accuracy: 0.9545 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1180 - accuracy: 0.9549 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9559 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1197 - accuracy: 0.9563 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1190 - accuracy: 0.9533 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1199 - accuracy: 0.9564 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1176 - accuracy: 0.9546 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9571 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9545 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9552 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1175 - accuracy: 0.9571 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9560 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9554 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1167 - accuracy: 0.9552 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1125 - accuracy: 0.9576 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9557 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9566 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9549 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9557 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9536 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9565 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9352428393524284 0.9283935242839353 0.9420921544209215 0.8705673645942783 0.9352428393524284 0.9817794881895259\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7106 - accuracy: 0.8074 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.8904 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "126/402 [========>.....................] - ETA: 1s - loss: 0.2392 - accuracy: 0.9015"
          ]
        }
      ],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',BACC_collection_test, '\\n',Sn_collection_test, '\\n',Sp_collection_test, '\\n',MCC_collection_test,'\\n', AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKFQm4uYrsIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J2EaTe_fNao"
      },
      "source": [
        "#### final model round 2 from 10 repeated times hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fcd774-703d-4dbf-e245-9bfa01b9cc7b",
        "id": "8O6OBStcfNap"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 6 6 6\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [128,32,32,64,128,16]\n",
        "dense_node = [4096,1024,8192,1024,4096,512]\n",
        "kernel_size = [12,9,9,9,12,12]\n",
        "stride_size = [8,8,8,2,2,1]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyijaYIZfNap"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(1280,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "fd6DK6tyfNaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH88XLtBfNaq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t33_650M_UR50D_unified_1280_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "wq-DoED8fNar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed40ab8b-5625-448f-bcf8-8e4a6f2e8bc6",
        "id": "hDn2s4ukfNar"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 1.0568 - accuracy: 0.5045 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6944 - accuracy: 0.5061 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5193 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6851 - accuracy: 0.5483 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6774 - accuracy: 0.5488 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5393 - accuracy: 0.7087 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4438 - accuracy: 0.7759 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8451 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.8743 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.8804 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2803 - accuracy: 0.8821 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.8909 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.8917 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.8986 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2410 - accuracy: 0.9007 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2379 - accuracy: 0.9023 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2395 - accuracy: 0.9027 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2337 - accuracy: 0.9043 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9073 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2296 - accuracy: 0.9072 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2248 - accuracy: 0.9106 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2226 - accuracy: 0.9093 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2226 - accuracy: 0.9106 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2203 - accuracy: 0.9107 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2190 - accuracy: 0.9133 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2155 - accuracy: 0.9130 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9133 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2200 - accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9141 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2149 - accuracy: 0.9135 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9137 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2181 - accuracy: 0.9118 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2149 - accuracy: 0.9142 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9131 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9139 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2129 - accuracy: 0.9155 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2146 - accuracy: 0.9151 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9165 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.9151 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2153 - accuracy: 0.9139 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9153 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2146 - accuracy: 0.9156 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9152 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2112 - accuracy: 0.9155 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.927148194271482 0.9034869240348692 0.9508094645080947 0.8552545635838974 0.9271481942714819 0.9804531264296868\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5157 - accuracy: 0.8271 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9147 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1758 - accuracy: 0.9303 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9310 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1568 - accuracy: 0.9370 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9430 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1340 - accuracy: 0.9435 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.9481 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1155 - accuracy: 0.9541 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9556 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9566 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0997 - accuracy: 0.9597 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9632 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9618 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9654 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9645 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9658 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0801 - accuracy: 0.9686 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9690 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9692 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9701 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9699 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9686 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0755 - accuracy: 0.9722 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9712 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9719 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0720 - accuracy: 0.9721 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9731 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9712 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9725 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0722 - accuracy: 0.9735 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9731 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9727 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9727 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0700 - accuracy: 0.9742 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9732 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9735 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9728 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9732 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9729 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0720 - accuracy: 0.9731 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9752 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9737 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9722 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0709 - accuracy: 0.9716 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9461394769613948 0.9321295143212951 0.9601494396014943 0.8926294316470963 0.9461394769613947 0.9862777194487049\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.9698 - accuracy: 0.4956 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6940 - accuracy: 0.5001 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5167 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6922 - accuracy: 0.4991 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5059 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6900 - accuracy: 0.5267 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6834 - accuracy: 0.5497 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.5692 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.5830 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6440 - accuracy: 0.6239 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5532 - accuracy: 0.6987 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3732 - accuracy: 0.8262 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8565 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3016 - accuracy: 0.8680 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2687 - accuracy: 0.8877 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2597 - accuracy: 0.8902 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2546 - accuracy: 0.8947 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2329 - accuracy: 0.9050 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2361 - accuracy: 0.9033 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2285 - accuracy: 0.9071 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2210 - accuracy: 0.9155 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2181 - accuracy: 0.9127 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9136 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9148 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2122 - accuracy: 0.9172 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9155 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9192 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9210 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9171 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9195 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9229 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1993 - accuracy: 0.9218 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2035 - accuracy: 0.9204 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2015 - accuracy: 0.9214 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9229 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9205 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9216 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9222 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9218 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9223 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9235 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9218 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1973 - accuracy: 0.9225 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9184308841843088 0.8985056039850561 0.9383561643835616 0.8375270572137005 0.9184308841843088 0.9754027936954974\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5052 - accuracy: 0.8600 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9153 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9293 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1618 - accuracy: 0.9355 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1534 - accuracy: 0.9368 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1387 - accuracy: 0.9432 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1275 - accuracy: 0.9473 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.9513 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9545 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9577 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9600 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9636 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9668 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0882 - accuracy: 0.9642 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9675 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9696 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9698 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9710 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0765 - accuracy: 0.9689 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9709 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9734 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9734 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9731 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9749 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9756 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9752 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9753 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9756 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9736 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9746 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9751 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9755 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.9754 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0656 - accuracy: 0.9763 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9748 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9756 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9751 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9752 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0651 - accuracy: 0.9751 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9778 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0648 - accuracy: 0.9755 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9767 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9744 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9762 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9424034869240349 0.9302615193026152 0.9545454545454546 0.8850679788354717 0.942403486924035 0.9875876034608697\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 1.4752 - accuracy: 0.4929 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6945 - accuracy: 0.4981 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.5049 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5026 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.5047 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.5072 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.4992 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4974 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5050 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.4988 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.4951 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.5005 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.4924 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.5017 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4997 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5035 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6933 - accuracy: 0.4974 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4961 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.5043 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6623 - accuracy: 0.6017 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6342 - accuracy: 0.6274 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6273 - accuracy: 0.6393 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6150 - accuracy: 0.6523 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5975 - accuracy: 0.6684 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.6804 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5774 - accuracy: 0.6912 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5538 - accuracy: 0.7130 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5426 - accuracy: 0.7228 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.5462 - accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5114 - accuracy: 0.7573 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4965 - accuracy: 0.7690 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4991 - accuracy: 0.7667 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.7848 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.7898 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.7900 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4603 - accuracy: 0.7943 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4536 - accuracy: 0.7982 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.8031 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4379 - accuracy: 0.8124 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4408 - accuracy: 0.8115 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4393 - accuracy: 0.8116 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4349 - accuracy: 0.8113 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.8145 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4334 - accuracy: 0.8164 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4363 - accuracy: 0.8133 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.8798256537982565 0.8754669987546699 0.8841843088418431 0.7596801727609844 0.8798256537982565 0.9391967233707966\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9097 - accuracy: 0.5175 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.5240 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6683 - accuracy: 0.5877 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.8719 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2297 - accuracy: 0.9068 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9187 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9263 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9310 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1628 - accuracy: 0.9343 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1604 - accuracy: 0.9367 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9400 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9463 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9479 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.9461 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9496 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1240 - accuracy: 0.9502 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9509 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1195 - accuracy: 0.9535 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1176 - accuracy: 0.9539 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9547 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9574 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9554 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9560 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1120 - accuracy: 0.9566 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9575 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9582 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1061 - accuracy: 0.9580 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.9597 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1054 - accuracy: 0.9601 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9587 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9594 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9589 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9605 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1022 - accuracy: 0.9603 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9614 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9587 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1023 - accuracy: 0.9606 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9613 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9612 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9615 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9604 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9608 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1018 - accuracy: 0.9601 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9601 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1045 - accuracy: 0.9592 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9439601494396015 0.9234122042341221 0.9645080946450809 0.8886710419030667 0.9439601494396015 0.9884938795829463\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 1.4544 - accuracy: 0.5023 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6951 - accuracy: 0.4976 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6954 - accuracy: 0.4991 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5061 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.4882 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4995 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5020 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5026 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.4934 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.4991 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6922 - accuracy: 0.4991 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6922 - accuracy: 0.4991 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5009 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.4931 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.4966 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5016 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.5033 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.4981 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.4981 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5033 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.4917 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.4950 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.4994 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5016 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.4947 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.4981 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.5022 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.5020 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.5023 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6920 - accuracy: 0.5018 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5022 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.5023 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5026 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5022 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.5024 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.5023 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5022 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5022 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5023 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6918 - accuracy: 0.5019 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5021 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5023 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5023 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5018 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5022 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.5021793275217933 0.0049813200498132005 0.9993773349937733 0.04122857420244236 0.5021793275217933 0.5021801029452132\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 7.5015 - accuracy: 0.5020 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6945 - accuracy: 0.5087 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6974 - accuracy: 0.5322 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6640 - accuracy: 0.5687 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6405 - accuracy: 0.5771 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6400 - accuracy: 0.6013 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6204 - accuracy: 0.6128 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6006 - accuracy: 0.6411 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4644 - accuracy: 0.7719 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8804 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2375 - accuracy: 0.9029 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2191 - accuracy: 0.9138 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1923 - accuracy: 0.9225 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1878 - accuracy: 0.9262 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1753 - accuracy: 0.9313 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1671 - accuracy: 0.9313 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1701 - accuracy: 0.9332 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.9375 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9397 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9370 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1490 - accuracy: 0.9411 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1475 - accuracy: 0.9419 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9409 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9449 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1423 - accuracy: 0.9430 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9437 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9455 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9447 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1342 - accuracy: 0.9468 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1375 - accuracy: 0.9466 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1332 - accuracy: 0.9480 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9466 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9467 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1335 - accuracy: 0.9468 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9449 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9475 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.9489 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9485 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1329 - accuracy: 0.9475 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1351 - accuracy: 0.9465 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1342 - accuracy: 0.9486 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9446 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9447 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1335 - accuracy: 0.9472 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9468 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9433374844333748 0.9265255292652553 0.9601494396014943 0.887176617150515 0.9433374844333748 0.9850056373282631\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7447 - accuracy: 0.7007 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2404 - accuracy: 0.9023 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9231 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9273 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1680 - accuracy: 0.9319 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1522 - accuracy: 0.9385 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1433 - accuracy: 0.9426 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1371 - accuracy: 0.9447 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1242 - accuracy: 0.9492 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9520 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1153 - accuracy: 0.9542 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9570 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1043 - accuracy: 0.9605 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1019 - accuracy: 0.9601 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9608 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9636 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9648 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0893 - accuracy: 0.9636 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9658 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9675 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9653 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0849 - accuracy: 0.9682 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9668 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9687 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0813 - accuracy: 0.9682 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9699 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9689 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9693 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9689 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0803 - accuracy: 0.9681 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9702 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9684 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9704 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9703 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0772 - accuracy: 0.9697 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9693 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9713 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9712 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9700 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0776 - accuracy: 0.9708 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9702 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9722 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0797 - accuracy: 0.9686 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9715 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9708 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9436488169364882 0.933997509339975 0.9533001245330013 0.8874629796147853 0.9436488169364882 0.9884345596913194\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 3.3269 - accuracy: 0.7862 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2686 - accuracy: 0.8732 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2169 - accuracy: 0.8920 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1960 - accuracy: 0.9050 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1824 - accuracy: 0.9123 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9253 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9296 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9344 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1368 - accuracy: 0.9365 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9422 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1241 - accuracy: 0.9447 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9483 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9503 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9499 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9532 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9545 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1018 - accuracy: 0.9566 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9572 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9559 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9600 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9601 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0934 - accuracy: 0.9611 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9625 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9628 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9624 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9624 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9629 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9623 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9650 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9649 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9618 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9640 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9636 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.9609 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9632 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0881 - accuracy: 0.9631 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0849 - accuracy: 0.9664 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9631 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0895 - accuracy: 0.9632 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9659 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9642 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9650 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9629 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9640 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9467621419676214 0.925280199252802 0.9682440846824408 0.894350103599473 0.9467621419676214 0.986892630220732\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-23ade762423b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;31m# train the model with the optimal parameters in the cross validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_whole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_whole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN_channel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# optimal paraemters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0;31m# performance evaluation at the independent test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  i = i+5\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG-2u4cJLNp0",
        "outputId": "9f5ace45-3723-451a-8518-c1d9fe7855a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.889±0.138'] \n",
            " ['0.889±0.138'] \n",
            " ['0.825±0.289'] \n",
            " ['0.953±0.029'] \n",
            " ['0.783±0.264'] \n",
            " ['0.932±0.152']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJeo_SEMKC8E",
        "outputId": "9c4a9e95-4382-4f54-c0d3-5479e23e256f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.947±0.004', '0.946±0.005', '0.946±0.004', '0.904±0.141'] \n",
            " ['0.947±0.004', '0.946±0.005', '0.946±0.004', '0.904±0.141'] \n",
            " ['0.935±0.006', '0.931±0.009', '0.932±0.006', '0.845±0.295'] \n",
            " ['0.959±0.004', '0.961±0.003', '0.961±0.008', '0.963±0.013'] \n",
            " ['0.894±0.009', '0.892±0.01', '0.893±0.008', '0.81±0.275'] \n",
            " ['0.988±0.001', '0.988±0.001', '0.988±0.001', '0.94±0.154']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqp51vUi5DsY"
      },
      "source": [
        "### 2560 feature dimension embedding test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15NhF_b8eB64"
      },
      "source": [
        "#### defined function for model development and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG77feh8eB7C"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, X_valid, y_train, y_valid, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(1280,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 20,verbose=0,restore_best_weights = True)\n",
        "  # set checkpoint and save the best model\n",
        "  mc = ModelCheckpoint('best_model_grid_2560.h5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=True, save_weights_only=False)\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lr , early_stop, mc]\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  saved_model = load_model('best_model_grid_2560.h5')\n",
        "  return saved_model\n",
        "\n",
        "  # import gc\n",
        "  # del model\n",
        "  # del saved_model\n",
        "  # import torch\n",
        "  # import gc\n",
        "  # torch.cuda.memory_reserved()\n",
        "  # gc.collect()\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo1csPt1d4__"
      },
      "source": [
        "#### 5 Fold CV for optimal hyperparrameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vie3t8Lqd4__"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svOBZaXhd4__"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t36_3B_UR50D_unified_2560_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "random_num = 1\n",
        "X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tkg64s0d4__",
        "outputId": "69f07346-06a9-4c00-9ac6-b652c04cef69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34 34 34 34\n"
          ]
        }
      ],
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [128, 64, 64, 16, 64, 128, 32, 128, 64, 32, 32, 128, 64, 16, 32, 16, 32, 64, 16, 64, 32, 32, 16, 64, 32, 32, 64, 128, 256, 32, 32, 16, 16, 16, 32, 16, 16]\n",
        "dense_node = [2048, 2048, 4096, 512, 4096, 1024, 2048, 4096, 1024, 256, 2048, 1024, 128, 4096, 4096, 32, 32, 32, 32, 64, 64, 64, 64, 128, 128, 128, 128, 256, 256, 256, 256, 256, 512, 512, 512, 512, 512]\n",
        "kernel_size = [6, 9, 12, 6, 6, 9, 6, 12, 9, 12, 12, 6, 9, 6, 3, 6, 12, 9, 3, 3, 9, 9, 3, 6, 6, 6, 9, 6, 9, 9, 12, 3, 6, 6, 6, 6, 3]\n",
        "stride_size = [4, 8, 8, 4, 4, 8, 8, 8, 1, 8, 8, 8, 1, 8, 4, 4, 2, 2, 4, 1, 8, 4, 2, 1, 4, 8, 1, 4, 1, 2, 8, 2, 4, 2, 2, 8, 2]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkJBM-Ojd5AA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsG4b_tPd5AA",
        "outputId": "2f8aa763-14f7-4b47-a41e-63c0b1c1dccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        }
      ],
      "source": [
        "# 5-Fold CV\n",
        "final_ACC_collection_cv = []\n",
        "final_BACC_collection_cv = []\n",
        "final_Sn_collection_cv = []\n",
        "final_Sp_collection_cv = []\n",
        "final_MCC_collection_cv = []\n",
        "final_AUC_collection_cv = []\n",
        "\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "\n",
        "# split dataset\n",
        "for i in range(len(CNN_channel)):\n",
        "  # collect the value in cross validation\n",
        "  ACC_collection_cv = []\n",
        "  BACC_collection_cv = []\n",
        "  Sn_collection_cv = []\n",
        "  Sp_collection_cv = []\n",
        "  MCC_collection_cv = []\n",
        "  AUC_collection_cv = []\n",
        "\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(X_train_whole, y_train_whole):\n",
        "      X_train, X_valid = X[train_ix], X[test_ix]\n",
        "      y_train, y_valid = y[train_ix], y[test_ix]\n",
        "      X_train_only, X_train_indicator, y_train_only, y_train_indicator = train_test_split( X_train, y_train, test_size=0.25, random_state=random_num,shuffle=True, stratify = y_train)\n",
        "\n",
        "      # train the model\n",
        "      saved_model = train_model(X_train_only, X_train_indicator, y_train_only, y_train_indicator,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i])\n",
        "\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_valid, y_valid)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "  final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "  final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "  final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "  final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe6_Hah1d5AA"
      },
      "outputs": [],
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kuvj9d1WYcjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNMAzPKaYcpT"
      },
      "source": [
        "### final model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [32,16,16]\n",
        "dense_node = [2048,32,512]\n",
        "kernel_size = [6,6,6]\n",
        "stride_size = [8,4,8]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvw2cJp2O73Y",
        "outputId": "6a211bfe-3f20-4059-b9f2-44b14c8a5d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 3 3 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdUNuOA4YcpU"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(2560,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "f3zI1-C9YcpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xRRFPIjYcpV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t36_3B_UR50D_unified_2560_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "qumCgQLjYcpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab70283-b44d-4cb0-aa5d-102e59b02d1b",
        "id": "r45CF_PhYcpV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "402/402 [==============================] - 14s 5ms/step - loss: 0.2896 - accuracy: 0.8896 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1800 - accuracy: 0.9264 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1394 - accuracy: 0.9433 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1221 - accuracy: 0.9515 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1051 - accuracy: 0.9597 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0873 - accuracy: 0.9671 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0797 - accuracy: 0.9689 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0732 - accuracy: 0.9722 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0592 - accuracy: 0.9777 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.9816 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.9809 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.9847 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9863 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9865 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0338 - accuracy: 0.9880 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0322 - accuracy: 0.9898 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9892 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9900 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0291 - accuracy: 0.9900 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0278 - accuracy: 0.9914 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9913 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9915 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0264 - accuracy: 0.9915 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9921 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9926 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9925 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9917 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9924 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9921 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9934 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9923 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.9918 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9927 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9923 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9943 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9931 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9936 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9924 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9936 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0236 - accuracy: 0.9935 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9943 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0225 - accuracy: 0.9930 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0224 - accuracy: 0.9941 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9931 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9545454545454546 0.9433374844333748 0.9657534246575342 0.9093193926435603 0.9545454545454546 0.990498349123539\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 0.3143 - accuracy: 0.8924 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1662 - accuracy: 0.9324 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1294 - accuracy: 0.9485 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1101 - accuracy: 0.9553 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0976 - accuracy: 0.9601 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0782 - accuracy: 0.9689 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0674 - accuracy: 0.9753 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0628 - accuracy: 0.9756 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0516 - accuracy: 0.9801 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9829 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.9840 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0353 - accuracy: 0.9885 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0328 - accuracy: 0.9896 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0286 - accuracy: 0.9913 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9918 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9913 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0248 - accuracy: 0.9927 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9924 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9928 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9931 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9934 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9927 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.9934 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9943 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9946 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9935 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0208 - accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9944 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9947 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0203 - accuracy: 0.9945 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9938 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9942 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9930 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9945 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9953 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9950 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9946 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0202 - accuracy: 0.9943 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9934 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9944 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9943 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9948 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9931 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9480074719800747 0.937733499377335 0.9582814445828145 0.8962041607224837 0.9480074719800747 0.9881011276207372\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2903 - accuracy: 0.8905 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1764 - accuracy: 0.9275 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1351 - accuracy: 0.9450 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1196 - accuracy: 0.9517 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1071 - accuracy: 0.9540 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0867 - accuracy: 0.9654 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0757 - accuracy: 0.9699 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0691 - accuracy: 0.9728 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0561 - accuracy: 0.9791 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.9795 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0488 - accuracy: 0.9815 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0414 - accuracy: 0.9858 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9868 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9866 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0341 - accuracy: 0.9884 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.9897 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.9886 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9914 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0285 - accuracy: 0.9913 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0262 - accuracy: 0.9917 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9913 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9929 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.9919 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9926 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9934 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9921 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9924 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9935 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9935 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9930 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0236 - accuracy: 0.9931 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9937 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9931 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9928 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9936 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.9942 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.9935 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9931 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9939 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9927 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9930 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9928 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9928 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0245 - accuracy: 0.9923 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9945 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9480074719800747 0.9371108343711083 0.958904109589041 0.8962277995196883 0.9480074719800746 0.988183128647398\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2915 - accuracy: 0.8922 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1684 - accuracy: 0.9317 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1321 - accuracy: 0.9462 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1148 - accuracy: 0.9544 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1043 - accuracy: 0.9578 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0799 - accuracy: 0.9706 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0737 - accuracy: 0.9726 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0649 - accuracy: 0.9755 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0531 - accuracy: 0.9796 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0487 - accuracy: 0.9816 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9840 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.9882 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0353 - accuracy: 0.9886 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0341 - accuracy: 0.9890 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0316 - accuracy: 0.9896 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9903 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0286 - accuracy: 0.9908 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0259 - accuracy: 0.9919 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9914 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9917 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0248 - accuracy: 0.9919 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9925 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9927 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.9937 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9936 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9936 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9931 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9938 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9924 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0201 - accuracy: 0.9942 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0202 - accuracy: 0.9939 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.9928 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9942 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9939 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9941 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9943 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9944 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0193 - accuracy: 0.9952 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9932 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9940 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9941 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9948 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9939 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9939 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0202 - accuracy: 0.9935 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9483188044831881 0.9371108343711083 0.9595267745952677 0.8968629626073471 0.9483188044831881 0.9889219133107634\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3073 - accuracy: 0.8930 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1740 - accuracy: 0.9295 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1323 - accuracy: 0.9471 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1145 - accuracy: 0.9534 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1061 - accuracy: 0.9573 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0813 - accuracy: 0.9681 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.9730 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0658 - accuracy: 0.9752 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0551 - accuracy: 0.9795 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0518 - accuracy: 0.9812 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0453 - accuracy: 0.9847 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9871 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 0.9870 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9886 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.9904 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0290 - accuracy: 0.9903 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0296 - accuracy: 0.9907 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0265 - accuracy: 0.9919 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9924 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9934 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9935 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9931 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9924 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9931 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9933 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9938 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9934 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9945 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0208 - accuracy: 0.9939 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9939 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9929 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9939 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0208 - accuracy: 0.9939 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9944 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9942 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9933 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9934 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9936 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9939 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9933 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9935 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9946 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9949 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9941 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9551681195516812 0.9470734744707348 0.9632627646326276 0.9104555589892978 0.9551681195516812 0.9906377314832765\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2846 - accuracy: 0.8920 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1743 - accuracy: 0.9292 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1368 - accuracy: 0.9440 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1202 - accuracy: 0.9512 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1046 - accuracy: 0.9572 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0851 - accuracy: 0.9683 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0760 - accuracy: 0.9705 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0681 - accuracy: 0.9730 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0566 - accuracy: 0.9784 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0524 - accuracy: 0.9809 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0473 - accuracy: 0.9826 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9857 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0362 - accuracy: 0.9871 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.9886 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.9898 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0309 - accuracy: 0.9895 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0284 - accuracy: 0.9903 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0271 - accuracy: 0.9903 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0269 - accuracy: 0.9912 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0273 - accuracy: 0.9910 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9905 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0242 - accuracy: 0.9928 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9918 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0249 - accuracy: 0.9921 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9922 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0236 - accuracy: 0.9935 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9930 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9924 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9918 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9930 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9930 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9928 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9920 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9929 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0218 - accuracy: 0.9944 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9929 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9938 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9929 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9923 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9931 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9930 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9930 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9936 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9452054794520548 0.9290161892901619 0.9613947696139477 0.8908780673793439 0.9452054794520548 0.989602347361777\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3092 - accuracy: 0.8910 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1775 - accuracy: 0.9292 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1336 - accuracy: 0.9467 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1177 - accuracy: 0.9540 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9587 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0859 - accuracy: 0.9668 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0756 - accuracy: 0.9711 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0696 - accuracy: 0.9737 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.9766 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0539 - accuracy: 0.9798 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0513 - accuracy: 0.9812 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0427 - accuracy: 0.9845 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0387 - accuracy: 0.9865 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9868 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0324 - accuracy: 0.9897 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9889 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0316 - accuracy: 0.9898 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9886 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0300 - accuracy: 0.9896 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.9917 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9914 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0266 - accuracy: 0.9903 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9919 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9913 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0248 - accuracy: 0.9922 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9928 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0245 - accuracy: 0.9924 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0242 - accuracy: 0.9926 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9931 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0245 - accuracy: 0.9924 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9928 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9929 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9917 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9934 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9928 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9926 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0242 - accuracy: 0.9926 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9914 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9915 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9931 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9936 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9939 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9928 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9928 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9930 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9542341220423413 0.9514321295143213 0.9570361145703612 0.9084825094836265 0.9542341220423413 0.9893001260838481\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3143 - accuracy: 0.8861 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1733 - accuracy: 0.9298 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1360 - accuracy: 0.9424 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1218 - accuracy: 0.9491 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1069 - accuracy: 0.9575 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0846 - accuracy: 0.9666 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0769 - accuracy: 0.9708 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0724 - accuracy: 0.9717 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9761 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.9809 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.9809 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0423 - accuracy: 0.9841 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9856 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.9852 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9879 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0347 - accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0336 - accuracy: 0.9889 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.9905 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0298 - accuracy: 0.9907 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0293 - accuracy: 0.9909 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0288 - accuracy: 0.9911 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0275 - accuracy: 0.9907 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9915 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0264 - accuracy: 0.9917 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.9918 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9921 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0259 - accuracy: 0.9924 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0250 - accuracy: 0.9924 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9916 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9920 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9917 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9935 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9925 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9923 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9932 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9935 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9918 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9922 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0242 - accuracy: 0.9924 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9919 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9930 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9928 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.9923 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9935 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9551681195516812 0.9495641344956414 0.960772104607721 0.9103934220700786 0.9551681195516812 0.9899883143690612\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2929 - accuracy: 0.8920 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1766 - accuracy: 0.9282 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1349 - accuracy: 0.9469 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1177 - accuracy: 0.9533 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1049 - accuracy: 0.9601 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0796 - accuracy: 0.9696 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0726 - accuracy: 0.9729 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0688 - accuracy: 0.9731 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.9812 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0472 - accuracy: 0.9837 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0468 - accuracy: 0.9824 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.9870 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.9866 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0344 - accuracy: 0.9879 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0310 - accuracy: 0.9897 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0293 - accuracy: 0.9903 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0304 - accuracy: 0.9890 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0270 - accuracy: 0.9913 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0248 - accuracy: 0.9928 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9932 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9923 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9923 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9925 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9925 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9941 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9930 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9937 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9942 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9946 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9947 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9947 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.9933 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9941 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9939 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9942 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9944 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9931 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9943 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9942 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9942 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9953 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9943 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9946 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9945 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9480074719800747 0.9427148194271482 0.9533001245330013 0.8960651468268027 0.9480074719800747 0.9903977379347992\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3145 - accuracy: 0.8908 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1724 - accuracy: 0.9310 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1337 - accuracy: 0.9459 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1176 - accuracy: 0.9531 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1037 - accuracy: 0.9596 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0814 - accuracy: 0.9683 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0734 - accuracy: 0.9704 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0683 - accuracy: 0.9738 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0548 - accuracy: 0.9787 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0525 - accuracy: 0.9821 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9842 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9861 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9866 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9887 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9893 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9902 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0303 - accuracy: 0.9901 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0291 - accuracy: 0.9912 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0270 - accuracy: 0.9914 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9912 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9920 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0245 - accuracy: 0.9923 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0252 - accuracy: 0.9917 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9924 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9910 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9928 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9931 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0225 - accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9922 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0236 - accuracy: 0.9929 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9926 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9919 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9938 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9937 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9933 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9939 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9926 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9942 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9935 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9939 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9939 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9943 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9939 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9931 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9539227895392279 0.9439601494396015 0.9638854296388543 0.9080258477267653 0.9539227895392279 0.9896066121905867\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.4137 - accuracy: 0.8049 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2431 - accuracy: 0.9063 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2072 - accuracy: 0.9239 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1964 - accuracy: 0.9247 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1896 - accuracy: 0.9282 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1707 - accuracy: 0.9383 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1696 - accuracy: 0.9387 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1661 - accuracy: 0.9397 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1510 - accuracy: 0.9454 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1490 - accuracy: 0.9443 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1465 - accuracy: 0.9467 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1420 - accuracy: 0.9495 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1403 - accuracy: 0.9483 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1362 - accuracy: 0.9520 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1234 - accuracy: 0.9567 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1313 - accuracy: 0.9542 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1273 - accuracy: 0.9552 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1208 - accuracy: 0.9570 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1244 - accuracy: 0.9557 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1311 - accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1225 - accuracy: 0.9564 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1201 - accuracy: 0.9581 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1214 - accuracy: 0.9579 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1188 - accuracy: 0.9571 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1204 - accuracy: 0.9581 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1163 - accuracy: 0.9592 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1191 - accuracy: 0.9574 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1193 - accuracy: 0.9569 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1189 - accuracy: 0.9591 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1190 - accuracy: 0.9584 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1215 - accuracy: 0.9574 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1208 - accuracy: 0.9582 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1184 - accuracy: 0.9584 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1132 - accuracy: 0.9608 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1164 - accuracy: 0.9603 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1178 - accuracy: 0.9587 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1157 - accuracy: 0.9601 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1164 - accuracy: 0.9596 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1160 - accuracy: 0.9603 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1176 - accuracy: 0.9584 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1184 - accuracy: 0.9594 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1148 - accuracy: 0.9608 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1172 - accuracy: 0.9594 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1130 - accuracy: 0.9601 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1201 - accuracy: 0.9584 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9508094645080947 0.9315068493150684 0.9701120797011208 0.9022915510608344 0.9508094645080947 0.9857077832350355\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.4471 - accuracy: 0.8111 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2233 - accuracy: 0.9131 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1990 - accuracy: 0.9211 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1827 - accuracy: 0.9274 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1730 - accuracy: 0.9321 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1618 - accuracy: 0.9356 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1539 - accuracy: 0.9408 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1525 - accuracy: 0.9397 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1416 - accuracy: 0.9461 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1414 - accuracy: 0.9446 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1381 - accuracy: 0.9454 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1319 - accuracy: 0.9486 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1300 - accuracy: 0.9495 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1291 - accuracy: 0.9489 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1230 - accuracy: 0.9540 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1202 - accuracy: 0.9554 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1193 - accuracy: 0.9546 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1161 - accuracy: 0.9552 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1143 - accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1162 - accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1129 - accuracy: 0.9547 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1199 - accuracy: 0.9531 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1142 - accuracy: 0.9566 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1136 - accuracy: 0.9565 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9580 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1098 - accuracy: 0.9590 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1143 - accuracy: 0.9550 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1113 - accuracy: 0.9571 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1118 - accuracy: 0.9572 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1113 - accuracy: 0.9563 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1131 - accuracy: 0.9552 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1150 - accuracy: 0.9553 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1126 - accuracy: 0.9564 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1074 - accuracy: 0.9571 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1119 - accuracy: 0.9569 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1111 - accuracy: 0.9571 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1150 - accuracy: 0.9559 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1119 - accuracy: 0.9561 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1102 - accuracy: 0.9577 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1074 - accuracy: 0.9575 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1091 - accuracy: 0.9579 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1097 - accuracy: 0.9566 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1128 - accuracy: 0.9566 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1083 - accuracy: 0.9568 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1128 - accuracy: 0.9555 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9424034869240349 0.9234122042341221 0.9613947696139477 0.8854459098353064 0.9424034869240349 0.9857504315231332\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3997 - accuracy: 0.8200 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2219 - accuracy: 0.9106 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1912 - accuracy: 0.9254 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1819 - accuracy: 0.9313 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1725 - accuracy: 0.9327 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1605 - accuracy: 0.9391 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1556 - accuracy: 0.9390 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1544 - accuracy: 0.9372 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1453 - accuracy: 0.9430 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1392 - accuracy: 0.9454 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1368 - accuracy: 0.9472 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1312 - accuracy: 0.9485 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1297 - accuracy: 0.9503 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1274 - accuracy: 0.9503 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1242 - accuracy: 0.9497 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1207 - accuracy: 0.9524 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1211 - accuracy: 0.9527 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1190 - accuracy: 0.9531 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1168 - accuracy: 0.9541 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1174 - accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1147 - accuracy: 0.9556 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1119 - accuracy: 0.9562 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1163 - accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1134 - accuracy: 0.9560 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1149 - accuracy: 0.9559 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1116 - accuracy: 0.9566 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1120 - accuracy: 0.9560 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1088 - accuracy: 0.9584 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1137 - accuracy: 0.9555 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1113 - accuracy: 0.9558 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1097 - accuracy: 0.9570 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1119 - accuracy: 0.9563 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1137 - accuracy: 0.9573 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1053 - accuracy: 0.9584 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1078 - accuracy: 0.9592 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1103 - accuracy: 0.9577 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1097 - accuracy: 0.9590 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9550 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1094 - accuracy: 0.9588 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1123 - accuracy: 0.9567 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1080 - accuracy: 0.9576 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9589 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1073 - accuracy: 0.9587 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1087 - accuracy: 0.9589 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1122 - accuracy: 0.9559 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9480074719800747 0.9458281444582815 0.950186799501868 0.8960234552708315 0.9480074719800747 0.9870482964722886\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.7696 - accuracy: 0.4995 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.4963 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.6698 - accuracy: 0.5385 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2898 - accuracy: 0.8732 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2292 - accuracy: 0.9060 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1951 - accuracy: 0.9215 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1857 - accuracy: 0.9255 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1794 - accuracy: 0.9274 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1629 - accuracy: 0.9347 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1598 - accuracy: 0.9355 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1544 - accuracy: 0.9393 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1489 - accuracy: 0.9403 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1443 - accuracy: 0.9413 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1478 - accuracy: 0.9393 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1426 - accuracy: 0.9437 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1348 - accuracy: 0.9456 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1357 - accuracy: 0.9478 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1341 - accuracy: 0.9452 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1308 - accuracy: 0.9471 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1309 - accuracy: 0.9502 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1285 - accuracy: 0.9492 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1287 - accuracy: 0.9485 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1246 - accuracy: 0.9489 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1286 - accuracy: 0.9500 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1265 - accuracy: 0.9504 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1251 - accuracy: 0.9498 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1238 - accuracy: 0.9521 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1260 - accuracy: 0.9492 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1234 - accuracy: 0.9499 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1265 - accuracy: 0.9489 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1214 - accuracy: 0.9520 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1230 - accuracy: 0.9505 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1270 - accuracy: 0.9496 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1236 - accuracy: 0.9511 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1208 - accuracy: 0.9525 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1215 - accuracy: 0.9521 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1235 - accuracy: 0.9513 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1184 - accuracy: 0.9535 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1244 - accuracy: 0.9515 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1249 - accuracy: 0.9523 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1207 - accuracy: 0.9519 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1224 - accuracy: 0.9498 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1235 - accuracy: 0.9532 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1204 - accuracy: 0.9534 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1229 - accuracy: 0.9533 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9361768368617683 0.927148194271482 0.9452054794520548 0.8724959307526958 0.9361768368617684 0.984073772233328\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3595 - accuracy: 0.8612 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2107 - accuracy: 0.9110 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1773 - accuracy: 0.9242 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1680 - accuracy: 0.9285 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1578 - accuracy: 0.9299 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1447 - accuracy: 0.9379 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1407 - accuracy: 0.9380 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1378 - accuracy: 0.9401 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1273 - accuracy: 0.9406 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1309 - accuracy: 0.9413 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1253 - accuracy: 0.9401 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1175 - accuracy: 0.9468 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.9475 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1140 - accuracy: 0.9479 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1135 - accuracy: 0.9501 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1114 - accuracy: 0.9500 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1095 - accuracy: 0.9496 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1056 - accuracy: 0.9506 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1078 - accuracy: 0.9510 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1040 - accuracy: 0.9514 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9533 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9522 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9528 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9510 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1040 - accuracy: 0.9531 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1030 - accuracy: 0.9530 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1033 - accuracy: 0.9519 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9524 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1001 - accuracy: 0.9531 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1021 - accuracy: 0.9505 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9524 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1008 - accuracy: 0.9535 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0988 - accuracy: 0.9540 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1017 - accuracy: 0.9515 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1017 - accuracy: 0.9525 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1001 - accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0994 - accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1029 - accuracy: 0.9524 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0979 - accuracy: 0.9563 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0981 - accuracy: 0.9548 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1026 - accuracy: 0.9527 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1011 - accuracy: 0.9530 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0981 - accuracy: 0.9552 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0994 - accuracy: 0.9549 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0994 - accuracy: 0.9533 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9473848069738481 0.9352428393524284 0.9595267745952677 0.8950335577667649 0.947384806973848 0.9881800269537181\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3970 - accuracy: 0.8449 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2240 - accuracy: 0.9050 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1970 - accuracy: 0.9132 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1820 - accuracy: 0.9200 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1848 - accuracy: 0.9186 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1679 - accuracy: 0.9241 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1637 - accuracy: 0.9272 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1599 - accuracy: 0.9274 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1501 - accuracy: 0.9319 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1550 - accuracy: 0.9281 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1491 - accuracy: 0.9305 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1434 - accuracy: 0.9329 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1417 - accuracy: 0.9341 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1415 - accuracy: 0.9358 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9353 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1336 - accuracy: 0.9373 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1366 - accuracy: 0.9353 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1343 - accuracy: 0.9346 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1303 - accuracy: 0.9366 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1300 - accuracy: 0.9357 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1297 - accuracy: 0.9398 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1318 - accuracy: 0.9362 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1286 - accuracy: 0.9381 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1322 - accuracy: 0.9361 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1256 - accuracy: 0.9405 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1302 - accuracy: 0.9370 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1299 - accuracy: 0.9379 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1249 - accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1267 - accuracy: 0.9390 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1278 - accuracy: 0.9383 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1288 - accuracy: 0.9369 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1256 - accuracy: 0.9390 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1248 - accuracy: 0.9401 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1295 - accuracy: 0.9368 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1249 - accuracy: 0.9404 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1291 - accuracy: 0.9361 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1263 - accuracy: 0.9401 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1273 - accuracy: 0.9383 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1270 - accuracy: 0.9361 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1295 - accuracy: 0.9383 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1258 - accuracy: 0.9411 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1284 - accuracy: 0.9377 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1258 - accuracy: 0.9390 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1240 - accuracy: 0.9407 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1217 - accuracy: 0.9409 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9380448318804483 0.9146948941469489 0.9613947696139477 0.8770465516861286 0.9380448318804483 0.9863498338267612\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.5052 - accuracy: 0.7229 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2301 - accuracy: 0.9053 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1869 - accuracy: 0.9229 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1750 - accuracy: 0.9284 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1702 - accuracy: 0.9287 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1514 - accuracy: 0.9387 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1475 - accuracy: 0.9394 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1436 - accuracy: 0.9403 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1294 - accuracy: 0.9467 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1314 - accuracy: 0.9439 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1250 - accuracy: 0.9455 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1201 - accuracy: 0.9496 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1175 - accuracy: 0.9510 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1151 - accuracy: 0.9534 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1137 - accuracy: 0.9517 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9576 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1063 - accuracy: 0.9565 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1050 - accuracy: 0.9590 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1017 - accuracy: 0.9587 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1022 - accuracy: 0.9568 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1032 - accuracy: 0.9576 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1000 - accuracy: 0.9598 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0992 - accuracy: 0.9599 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0957 - accuracy: 0.9617 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0987 - accuracy: 0.9613 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0984 - accuracy: 0.9604 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0984 - accuracy: 0.9593 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0973 - accuracy: 0.9610 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1016 - accuracy: 0.9580 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0947 - accuracy: 0.9615 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0965 - accuracy: 0.9607 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0963 - accuracy: 0.9612 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0958 - accuracy: 0.9621 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0960 - accuracy: 0.9619 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0946 - accuracy: 0.9621 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0940 - accuracy: 0.9632 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0937 - accuracy: 0.9632 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0949 - accuracy: 0.9608 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0983 - accuracy: 0.9603 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0969 - accuracy: 0.9609 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0953 - accuracy: 0.9615 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0935 - accuracy: 0.9615 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0947 - accuracy: 0.9615 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0934 - accuracy: 0.9619 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0971 - accuracy: 0.9616 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9430261519302615 0.9371108343711083 0.9489414694894147 0.8861143180505331 0.9430261519302615 0.9866035911409425\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3748 - accuracy: 0.8551 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2077 - accuracy: 0.9130 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1757 - accuracy: 0.9267 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1685 - accuracy: 0.9303 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1598 - accuracy: 0.9341 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1443 - accuracy: 0.9403 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1406 - accuracy: 0.9429 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1360 - accuracy: 0.9443 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1300 - accuracy: 0.9485 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1231 - accuracy: 0.9513 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1232 - accuracy: 0.9502 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1167 - accuracy: 0.9521 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1144 - accuracy: 0.9541 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1087 - accuracy: 0.9563 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1032 - accuracy: 0.9584 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9591 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1045 - accuracy: 0.9587 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.9580 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1013 - accuracy: 0.9603 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1010 - accuracy: 0.9608 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0957 - accuracy: 0.9635 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0974 - accuracy: 0.9618 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0983 - accuracy: 0.9614 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0977 - accuracy: 0.9608 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0951 - accuracy: 0.9626 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0943 - accuracy: 0.9622 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0923 - accuracy: 0.9627 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0971 - accuracy: 0.9626 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0923 - accuracy: 0.9633 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0960 - accuracy: 0.9608 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0952 - accuracy: 0.9629 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0932 - accuracy: 0.9639 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0906 - accuracy: 0.9660 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0923 - accuracy: 0.9635 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0932 - accuracy: 0.9643 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0952 - accuracy: 0.9622 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0907 - accuracy: 0.9658 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0944 - accuracy: 0.9638 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0949 - accuracy: 0.9625 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0916 - accuracy: 0.9629 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0924 - accuracy: 0.9633 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0909 - accuracy: 0.9654 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0951 - accuracy: 0.9634 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0930 - accuracy: 0.9651 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0930 - accuracy: 0.9637 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9445828144458281 0.9259028642590287 0.9632627646326276 0.8897868111018878 0.9445828144458281 0.9874493842362622\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.5148 - accuracy: 0.7732 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2260 - accuracy: 0.9066 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1907 - accuracy: 0.9219 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1808 - accuracy: 0.9250 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1766 - accuracy: 0.9267 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1583 - accuracy: 0.9362 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1512 - accuracy: 0.9383 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1482 - accuracy: 0.9404 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1404 - accuracy: 0.9427 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1360 - accuracy: 0.9454 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1348 - accuracy: 0.9453 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1271 - accuracy: 0.9485 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1245 - accuracy: 0.9496 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1221 - accuracy: 0.9513 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1235 - accuracy: 0.9507 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1202 - accuracy: 0.9528 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1171 - accuracy: 0.9528 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1110 - accuracy: 0.9568 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1114 - accuracy: 0.9552 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1133 - accuracy: 0.9536 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9568 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1090 - accuracy: 0.9571 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1106 - accuracy: 0.9569 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1068 - accuracy: 0.9571 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1085 - accuracy: 0.9575 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1054 - accuracy: 0.9566 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1077 - accuracy: 0.9559 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1084 - accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1070 - accuracy: 0.9589 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1062 - accuracy: 0.9576 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1062 - accuracy: 0.9591 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1044 - accuracy: 0.9587 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1054 - accuracy: 0.9598 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1076 - accuracy: 0.9595 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1067 - accuracy: 0.9581 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1075 - accuracy: 0.9584 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1067 - accuracy: 0.9582 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1056 - accuracy: 0.9602 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9589 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1058 - accuracy: 0.9587 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1048 - accuracy: 0.9583 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9583 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1033 - accuracy: 0.9595 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1032 - accuracy: 0.9600 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1060 - accuracy: 0.9585 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9433374844333748 0.927148194271482 0.9595267745952677 0.8871401174462837 0.9433374844333748 0.9885140405918652\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3613 - accuracy: 0.8600 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2104 - accuracy: 0.9141 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1759 - accuracy: 0.9270 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1683 - accuracy: 0.9293 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1658 - accuracy: 0.9309 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1502 - accuracy: 0.9394 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1420 - accuracy: 0.9405 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1391 - accuracy: 0.9432 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1345 - accuracy: 0.9436 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1261 - accuracy: 0.9475 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1217 - accuracy: 0.9487 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1187 - accuracy: 0.9507 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1176 - accuracy: 0.9501 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1148 - accuracy: 0.9531 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1127 - accuracy: 0.9546 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1123 - accuracy: 0.9523 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1083 - accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1069 - accuracy: 0.9565 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1072 - accuracy: 0.9559 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1055 - accuracy: 0.9566 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1067 - accuracy: 0.9566 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1008 - accuracy: 0.9597 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1036 - accuracy: 0.9580 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9571 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1027 - accuracy: 0.9566 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1016 - accuracy: 0.9587 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0997 - accuracy: 0.9574 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0990 - accuracy: 0.9605 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1050 - accuracy: 0.9572 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1015 - accuracy: 0.9579 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1014 - accuracy: 0.9590 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1005 - accuracy: 0.9571 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0962 - accuracy: 0.9596 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1007 - accuracy: 0.9577 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0977 - accuracy: 0.9603 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0989 - accuracy: 0.9596 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0994 - accuracy: 0.9582 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1001 - accuracy: 0.9593 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1003 - accuracy: 0.9584 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0982 - accuracy: 0.9600 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0994 - accuracy: 0.9597 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0974 - accuracy: 0.9596 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0979 - accuracy: 0.9588 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0994 - accuracy: 0.9591 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.9600 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9461394769613948 0.9364881693648817 0.9557907845579079 0.8924452279213946 0.9461394769613948 0.9869424511754643\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2776 - accuracy: 0.8909 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1841 - accuracy: 0.9235 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1463 - accuracy: 0.9418 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1336 - accuracy: 0.9448 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1235 - accuracy: 0.9524 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0986 - accuracy: 0.9607 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9619 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0838 - accuracy: 0.9666 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9706 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0693 - accuracy: 0.9752 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0656 - accuracy: 0.9741 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0588 - accuracy: 0.9790 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.9785 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.9784 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0502 - accuracy: 0.9820 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0493 - accuracy: 0.9816 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.9825 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0414 - accuracy: 0.9850 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.9847 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0422 - accuracy: 0.9847 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0405 - accuracy: 0.9858 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.9854 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.9861 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0402 - accuracy: 0.9866 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0394 - accuracy: 0.9863 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0376 - accuracy: 0.9866 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0394 - accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0381 - accuracy: 0.9861 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0377 - accuracy: 0.9863 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0361 - accuracy: 0.9881 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0376 - accuracy: 0.9868 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.9861 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0383 - accuracy: 0.9862 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9870 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9870 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0372 - accuracy: 0.9867 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9871 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.9874 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9863 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9864 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9876 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.9868 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9880 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0361 - accuracy: 0.9874 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9557907845579079 0.9470734744707348 0.9645080946450809 0.9117201456013064 0.9557907845579079 0.9913381326873539\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2927 - accuracy: 0.8873 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9254 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9414 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1327 - accuracy: 0.9466 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1203 - accuracy: 0.9522 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1003 - accuracy: 0.9609 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0931 - accuracy: 0.9630 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9664 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0727 - accuracy: 0.9717 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9731 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9752 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9791 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9792 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0545 - accuracy: 0.9802 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9825 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9817 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9841 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9838 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9851 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0442 - accuracy: 0.9844 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9865 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0391 - accuracy: 0.9876 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.9852 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9868 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.9874 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9862 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.9868 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.9861 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9872 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0368 - accuracy: 0.9878 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0356 - accuracy: 0.9889 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.9869 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.9884 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9873 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9852 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9870 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0343 - accuracy: 0.9886 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9870 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9876 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0341 - accuracy: 0.9895 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9865 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9862 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9486301369863014 0.9364881693648817 0.960772104607721 0.8975249524995882 0.9486301369863013 0.9878338003967065\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2890 - accuracy: 0.8868 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1835 - accuracy: 0.9240 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1446 - accuracy: 0.9415 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1335 - accuracy: 0.9452 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1232 - accuracy: 0.9516 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0995 - accuracy: 0.9603 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0928 - accuracy: 0.9625 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0912 - accuracy: 0.9630 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0776 - accuracy: 0.9675 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0723 - accuracy: 0.9717 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0668 - accuracy: 0.9745 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0611 - accuracy: 0.9770 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0587 - accuracy: 0.9779 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.9790 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9794 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9811 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0490 - accuracy: 0.9817 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.9819 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.9837 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0464 - accuracy: 0.9821 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0435 - accuracy: 0.9847 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.9837 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0436 - accuracy: 0.9829 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9852 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0418 - accuracy: 0.9855 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9849 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9852 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0387 - accuracy: 0.9868 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0415 - accuracy: 0.9854 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0374 - accuracy: 0.9871 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9865 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9862 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9870 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9855 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9861 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9861 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9867 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9861 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0389 - accuracy: 0.9858 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0385 - accuracy: 0.9866 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.9879 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0388 - accuracy: 0.9873 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9862 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9461394769613948 0.9352428393524284 0.9570361145703612 0.8924909219678342 0.9461394769613948 0.988277924160488\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2960 - accuracy: 0.8876 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1776 - accuracy: 0.9302 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1418 - accuracy: 0.9426 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1289 - accuracy: 0.9476 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1191 - accuracy: 0.9520 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0984 - accuracy: 0.9609 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0899 - accuracy: 0.9650 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0853 - accuracy: 0.9659 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0729 - accuracy: 0.9728 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0686 - accuracy: 0.9729 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0657 - accuracy: 0.9741 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0573 - accuracy: 0.9794 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0554 - accuracy: 0.9787 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0540 - accuracy: 0.9797 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9821 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0474 - accuracy: 0.9829 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0471 - accuracy: 0.9830 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0454 - accuracy: 0.9830 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9851 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9845 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0418 - accuracy: 0.9844 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0401 - accuracy: 0.9868 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9850 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0410 - accuracy: 0.9854 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9872 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9877 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9853 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0387 - accuracy: 0.9861 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0370 - accuracy: 0.9870 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9872 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9862 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9866 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9879 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9874 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0369 - accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9868 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9869 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9868 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9880 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0364 - accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9878 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9458281444582815 0.9346201743462017 0.9570361145703612 0.8918803905928618 0.9458281444582815 0.9882141455841963\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3020 - accuracy: 0.8842 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1861 - accuracy: 0.9238 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1501 - accuracy: 0.9387 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1375 - accuracy: 0.9437 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1230 - accuracy: 0.9510 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1000 - accuracy: 0.9601 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0952 - accuracy: 0.9608 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0889 - accuracy: 0.9635 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0796 - accuracy: 0.9699 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0717 - accuracy: 0.9728 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0679 - accuracy: 0.9738 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0617 - accuracy: 0.9774 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0610 - accuracy: 0.9764 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0566 - accuracy: 0.9787 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0524 - accuracy: 0.9820 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.9823 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0495 - accuracy: 0.9823 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.9823 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.9837 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0441 - accuracy: 0.9841 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.9844 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0434 - accuracy: 0.9852 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0420 - accuracy: 0.9845 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9857 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0421 - accuracy: 0.9846 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0415 - accuracy: 0.9860 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9871 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9862 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9863 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9865 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.9855 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9883 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0401 - accuracy: 0.9859 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9857 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9864 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9874 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9865 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9866 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0408 - accuracy: 0.9860 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9884 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9866 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9867 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9557907845579079 0.9495641344956414 0.9620174346201743 0.9116522635084247 0.9557907845579079 0.9906958882397734\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2748 - accuracy: 0.8871 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1788 - accuracy: 0.9280 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1428 - accuracy: 0.9428 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1286 - accuracy: 0.9481 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1193 - accuracy: 0.9527 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1008 - accuracy: 0.9599 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0931 - accuracy: 0.9639 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0852 - accuracy: 0.9665 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0729 - accuracy: 0.9712 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0694 - accuracy: 0.9727 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0665 - accuracy: 0.9734 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0564 - accuracy: 0.9782 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0555 - accuracy: 0.9784 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0544 - accuracy: 0.9793 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9815 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0483 - accuracy: 0.9826 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9825 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.9850 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.9855 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0423 - accuracy: 0.9861 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9849 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9854 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9861 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.9849 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9872 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0364 - accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9866 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9865 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9866 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9879 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9870 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9867 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9871 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9863 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9884 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9886 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9851 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9857 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0364 - accuracy: 0.9871 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0349 - accuracy: 0.9889 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.9871 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9861 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9470734744707348 0.9371108343711083 0.9570361145703612 0.8943244974867182 0.9470734744707348 0.9902060144942144\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.2856 - accuracy: 0.8904 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1802 - accuracy: 0.9268 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1472 - accuracy: 0.9413 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1303 - accuracy: 0.9485 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1202 - accuracy: 0.9518 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1019 - accuracy: 0.9600 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0919 - accuracy: 0.9654 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0828 - accuracy: 0.9677 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0759 - accuracy: 0.9710 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0698 - accuracy: 0.9714 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0684 - accuracy: 0.9728 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0568 - accuracy: 0.9795 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0582 - accuracy: 0.9791 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0548 - accuracy: 0.9784 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0529 - accuracy: 0.9801 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0481 - accuracy: 0.9813 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0474 - accuracy: 0.9823 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9849 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0441 - accuracy: 0.9857 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0446 - accuracy: 0.9845 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0427 - accuracy: 0.9847 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9863 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0407 - accuracy: 0.9857 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.9859 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0398 - accuracy: 0.9861 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9866 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9852 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9855 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9862 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9856 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.9868 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9859 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9861 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9888 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.9866 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9866 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9869 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9858 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9879 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9872 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9863 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9864 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0389 - accuracy: 0.9862 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9861 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9858 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9539227895392279 0.9427148194271482 0.9651307596513076 0.9080737496399389 0.9539227895392279 0.9894557923354047\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3040 - accuracy: 0.8820 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1859 - accuracy: 0.9250 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1477 - accuracy: 0.9409 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1354 - accuracy: 0.9462 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1238 - accuracy: 0.9504 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9604 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0955 - accuracy: 0.9604 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0879 - accuracy: 0.9667 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0770 - accuracy: 0.9693 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0739 - accuracy: 0.9723 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0706 - accuracy: 0.9724 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0620 - accuracy: 0.9759 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0615 - accuracy: 0.9770 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0562 - accuracy: 0.9795 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.9799 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.9817 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.9812 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9823 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0481 - accuracy: 0.9827 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9828 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9837 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9847 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.9841 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.9851 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0421 - accuracy: 0.9856 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.9847 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0420 - accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0423 - accuracy: 0.9848 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0401 - accuracy: 0.9861 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9863 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9854 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0427 - accuracy: 0.9840 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9856 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9851 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9869 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9861 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9858 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0398 - accuracy: 0.9858 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9854 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9847 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0412 - accuracy: 0.9868 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9874 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.9861 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0425 - accuracy: 0.9847 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9861 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9564134495641345 0.9452054794520548 0.9676214196762142 0.9130563216544242 0.9564134495641345 0.9898828567839468\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3008 - accuracy: 0.8865 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1848 - accuracy: 0.9259 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1454 - accuracy: 0.9439 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1344 - accuracy: 0.9466 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1199 - accuracy: 0.9532 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1020 - accuracy: 0.9601 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0936 - accuracy: 0.9629 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0891 - accuracy: 0.9652 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0778 - accuracy: 0.9709 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0695 - accuracy: 0.9736 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0665 - accuracy: 0.9751 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0598 - accuracy: 0.9777 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0555 - accuracy: 0.9800 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9800 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.9816 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0484 - accuracy: 0.9832 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.9836 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.9826 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0453 - accuracy: 0.9845 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9856 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9868 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0398 - accuracy: 0.9871 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.9851 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9872 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9868 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9863 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9873 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9879 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0385 - accuracy: 0.9871 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0361 - accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9865 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.9877 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9860 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9878 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9890 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0370 - accuracy: 0.9871 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9885 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9878 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0344 - accuracy: 0.9886 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9865 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0366 - accuracy: 0.9879 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0358 - accuracy: 0.9870 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9473848069738481 0.9389788293897883 0.9557907845579079 0.8948960904224839 0.9473848069738481 0.989880142801977\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 5ms/step - loss: 0.3006 - accuracy: 0.8835 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1845 - accuracy: 0.9260 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1507 - accuracy: 0.9397 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1345 - accuracy: 0.9459 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1243 - accuracy: 0.9484 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1038 - accuracy: 0.9589 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0953 - accuracy: 0.9625 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0916 - accuracy: 0.9634 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0786 - accuracy: 0.9693 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0735 - accuracy: 0.9703 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0696 - accuracy: 0.9738 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0628 - accuracy: 0.9758 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0596 - accuracy: 0.9782 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0570 - accuracy: 0.9780 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0529 - accuracy: 0.9808 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0524 - accuracy: 0.9798 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.9807 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0484 - accuracy: 0.9826 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9838 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.9838 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9830 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9845 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9844 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.9842 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0427 - accuracy: 0.9839 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0415 - accuracy: 0.9837 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0416 - accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0407 - accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9857 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9879 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9848 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9855 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9851 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9865 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.9856 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9869 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9870 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.9854 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9852 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9867 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9869 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9868 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0387 - accuracy: 0.9864 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9869 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9523661270236613 0.9389788293897883 0.9657534246575342 0.9050567202649481 0.9523661270236612 0.9890508274543314\n",
            "['0.951±0.004', '0.944±0.004', '0.951±0.004'] \n",
            " ['0.951±0.004', '0.944±0.004', '0.951±0.004'] \n",
            " ['0.942±0.007', '0.93±0.009', '0.941±0.005'] \n",
            " ['0.96±0.004', '0.958±0.008', '0.961±0.004'] \n",
            " ['0.902±0.008', '0.888±0.009', '0.902±0.009'] \n",
            " ['0.99±0.001', '0.987±0.001', '0.989±0.001']\n"
          ]
        }
      ],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True, stratify = y)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ],
      "metadata": {
        "id": "CHXDOMK7d5qJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d07788-8b19-459a-ba8a-ae298c67b78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[] \n",
            " [] \n",
            " [] \n",
            " [] \n",
            " [] \n",
            " []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "上面这个漏了第一二个，但是似乎第一组参数本身会报错\n",
        "# set the selected hyperparameters from above grid search\n",
        "CNN_channel = [64,128,32,16,16]\n",
        "dense_node = [4096,1024,2048,32,512]\n",
        "kernel_size = [12,9,6,6,6]\n",
        "stride_size = [8,8,8,4,8]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "029xJbjOO-Op",
        "outputId": "f1299aed-bd3c-474e-cdd6-c44c741bb422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-5de02d1d4b34>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    上面这个漏了第一二个，但是似乎第一组参数本身会报错\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '，' (U+FF0C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475QQQ4td6H2"
      },
      "source": [
        "### final model round 2 from 10 repeated times hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de00043-b0c9-4ff1-c3c2-9ccbf679a01d",
        "id": "qFQCSDkGd6H2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37 37 37 37\n"
          ]
        }
      ],
      "source": [
        "# set best parameters\n",
        "CNN_channel = [128, 64, 64, 16, 64, 128, 32, 128, 64, 32, 32, 128, 64, 16, 32, 16, 32, 64, 16, 64, 32, 32, 16, 64, 32, 32, 64, 128, 256, 32, 32, 16, 16, 16, 32, 16, 16]\n",
        "dense_node = [2048, 2048, 4096, 512, 4096, 1024, 2048, 4096, 1024, 256, 2048, 1024, 128, 4096, 4096, 32, 32, 32, 32, 64, 64, 64, 64, 128, 128, 128, 128, 256, 256, 256, 256, 256, 512, 512, 512, 512, 512]\n",
        "kernel_size = [6, 9, 12, 6, 6, 9, 6, 12, 9, 12, 12, 6, 9, 6, 3, 6, 12, 9, 3, 3, 9, 9, 3, 6, 6, 6, 9, 6, 9, 9, 12, 3, 6, 6, 6, 6, 3]\n",
        "stride_size = [4, 8, 8, 4, 4, 8, 8, 8, 1, 8, 8, 8, 1, 8, 4, 4, 2, 2, 4, 1, 8, 4, 2, 1, 4, 8, 1, 4, 1, 2, 8, 2, 4, 2, 2, 8, 2]\n",
        "print(len(CNN_channel),len(dense_node), len(kernel_size),len(stride_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYMD7a-Vd6H3"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train, filter_size,kernel_size,stride_size,node_units):\n",
        "  inputShape=(2560,1) # input feature size\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(filter_size,(kernel_size),strides = (stride_size),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(node_units,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(learning_rate=0.01, momentum=momentum, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate\n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lr = LearningRateScheduler(step_decay)\n",
        "   # summary the callbacks_list\n",
        "  callbacks_list = [ lr ]\n",
        "  model_history = model.fit(X_train, y_train,  epochs=45,callbacks=callbacks_list,batch_size = 32, verbose=1)\n",
        "  # load the save best model\n",
        "  return model\n",
        "\n",
        "\n",
        "def check_performance(saved_model, X_test, y_test):\n",
        "  # result collection list\n",
        "  # confusion matrix\n",
        "  predicted_class= []\n",
        "  predicted_protability = saved_model.predict(X_test,batch_size=1)\n",
        "  for p in range(predicted_protability.shape[0]):\n",
        "    index = np.where(predicted_protability[p] == np.amax(predicted_protability[p]))[0][0]\n",
        "    predicted_class.append(index)\n",
        "  predicted_class = np.array(predicted_class)\n",
        "  y_true = y_test\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import math\n",
        "  # np.ravel() return a flatten 1D array\n",
        "  TN, FP, FN, TP = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "  ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "  Sn = (TP/(TP+FN))\n",
        "  Sp = (TN/(TN+FP))\n",
        "  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "  BACC = (0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "  return ACC, Sn, Sp, MCC, BACC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/universal_allergenicity_new')"
      ],
      "metadata": {
        "id": "JwNZX35qd6H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmUi0G-Nd6H3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm\n",
        "import statistics\n",
        "# whole dataset loading and dataset splitting\n",
        "dataset = pd.read_excel('allergens_dataset.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "\n",
        "# generate the peptide embeddings\n",
        "sequence_list = dataset['sequence']\n",
        "y = dataset['label']\n",
        "y = np.array(y) # transformed as np.array for CNN model\n",
        "\n",
        "# read the peptide embeddings\n",
        "X_data_name = 'whole_sample_dataset_esm2_t36_3B_UR50D_unified_2560_dimension.csv'\n",
        "X_data = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X_data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "pzreUv-7d6H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1665bab6-a733-404b-d8e2-89a2bcb9b175",
        "id": "ZlGvF_Lod6H3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.6674 - accuracy: 0.8254 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.2244 - accuracy: 0.9116 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 5ms/step - loss: 0.1701 - accuracy: 0.9299 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1523 - accuracy: 0.9401 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1420 - accuracy: 0.9436 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1232 - accuracy: 0.9504 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1154 - accuracy: 0.9534 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1078 - accuracy: 0.9580 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0938 - accuracy: 0.9631 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9664 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.9643 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9701 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0686 - accuracy: 0.9740 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0666 - accuracy: 0.9731 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0575 - accuracy: 0.9798 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0560 - accuracy: 0.9787 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9794 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.9828 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0502 - accuracy: 0.9813 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0487 - accuracy: 0.9820 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9842 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0441 - accuracy: 0.9845 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0463 - accuracy: 0.9833 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0428 - accuracy: 0.9853 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0431 - accuracy: 0.9847 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.9846 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0400 - accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0405 - accuracy: 0.9858 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9847 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.9862 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0397 - accuracy: 0.9872 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0390 - accuracy: 0.9879 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0387 - accuracy: 0.9863 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0376 - accuracy: 0.9868 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.9878 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0391 - accuracy: 0.9869 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9879 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9860 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0386 - accuracy: 0.9867 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9866 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9872 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0381 - accuracy: 0.9868 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0383 - accuracy: 0.9873 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9480074719800747 0.943089430894309 0.9528828270303782 0.8960478238374434 0.9479861289623436 0.9887402503191898\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 1.1945 - accuracy: 0.5302 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5398 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2745 - accuracy: 0.8829 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2035 - accuracy: 0.9176 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1802 - accuracy: 0.9270 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1550 - accuracy: 0.9363 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1444 - accuracy: 0.9409 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1376 - accuracy: 0.9450 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1187 - accuracy: 0.9520 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1151 - accuracy: 0.9529 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1072 - accuracy: 0.9568 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9635 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0946 - accuracy: 0.9645 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9657 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9702 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9696 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0732 - accuracy: 0.9718 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9735 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9753 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9762 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0630 - accuracy: 0.9781 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9777 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0612 - accuracy: 0.9782 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9794 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.9799 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.9799 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0553 - accuracy: 0.9801 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.9812 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0539 - accuracy: 0.9812 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0536 - accuracy: 0.9819 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0509 - accuracy: 0.9827 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.9824 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0521 - accuracy: 0.9830 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.9811 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0549 - accuracy: 0.9808 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0509 - accuracy: 0.9824 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0516 - accuracy: 0.9813 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0517 - accuracy: 0.9827 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.9830 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.9819 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0509 - accuracy: 0.9836 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0520 - accuracy: 0.9819 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0531 - accuracy: 0.9823 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9542341220423413 0.9454660748256183 0.962691131498471 0.9085228532392244 0.9540786031620446 0.9899501434031637\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.8222 - accuracy: 0.7944 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2075 - accuracy: 0.9134 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1697 - accuracy: 0.9313 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1542 - accuracy: 0.9373 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1435 - accuracy: 0.9423 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1218 - accuracy: 0.9516 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1148 - accuracy: 0.9556 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1069 - accuracy: 0.9588 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0925 - accuracy: 0.9647 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0866 - accuracy: 0.9669 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0813 - accuracy: 0.9682 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.9716 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.9745 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0637 - accuracy: 0.9753 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.9784 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.9790 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9797 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0507 - accuracy: 0.9812 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0486 - accuracy: 0.9824 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0461 - accuracy: 0.9842 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0448 - accuracy: 0.9837 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9849 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0448 - accuracy: 0.9849 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9852 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0415 - accuracy: 0.9852 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0405 - accuracy: 0.9865 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0405 - accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0416 - accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0383 - accuracy: 0.9870 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0386 - accuracy: 0.9866 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9872 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0392 - accuracy: 0.9870 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0383 - accuracy: 0.9877 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0361 - accuracy: 0.9879 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9868 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9869 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0390 - accuracy: 0.9866 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.9886 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0372 - accuracy: 0.9872 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0347 - accuracy: 0.9893 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9872 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9533001245330013 0.9458779106356199 0.9605668515095502 0.9066613505857892 0.9532223810725851 0.9899177842739693\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.9295 - accuracy: 0.7806 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2086 - accuracy: 0.9138 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1705 - accuracy: 0.9320 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1539 - accuracy: 0.9364 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1459 - accuracy: 0.9418 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1239 - accuracy: 0.9513 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1165 - accuracy: 0.9541 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1108 - accuracy: 0.9553 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9611 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0904 - accuracy: 0.9654 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9672 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0763 - accuracy: 0.9712 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9742 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9729 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0613 - accuracy: 0.9772 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0618 - accuracy: 0.9757 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.9781 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0524 - accuracy: 0.9801 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0518 - accuracy: 0.9807 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9829 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0494 - accuracy: 0.9825 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.9835 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9853 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0441 - accuracy: 0.9851 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0448 - accuracy: 0.9848 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0436 - accuracy: 0.9852 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0421 - accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9856 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.9872 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0407 - accuracy: 0.9865 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9857 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0392 - accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9857 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9869 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0391 - accuracy: 0.9877 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0401 - accuracy: 0.9872 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0389 - accuracy: 0.9874 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0392 - accuracy: 0.9864 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0394 - accuracy: 0.9865 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.9854 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9858 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0399 - accuracy: 0.9865 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9884 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9542341220423413 0.9446233097231166 0.9632308619650392 0.9084317273408403 0.9539270858440778 0.991155386898212\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.8660 - accuracy: 0.7040 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2220 - accuracy: 0.9085 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1808 - accuracy: 0.9278 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1674 - accuracy: 0.9329 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1548 - accuracy: 0.9363 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1314 - accuracy: 0.9489 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1264 - accuracy: 0.9485 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1182 - accuracy: 0.9513 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1016 - accuracy: 0.9596 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0970 - accuracy: 0.9619 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0919 - accuracy: 0.9640 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.9700 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0759 - accuracy: 0.9714 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0736 - accuracy: 0.9738 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9763 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0636 - accuracy: 0.9764 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9796 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.9783 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0531 - accuracy: 0.9791 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0534 - accuracy: 0.9799 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0512 - accuracy: 0.9820 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9816 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0475 - accuracy: 0.9834 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0454 - accuracy: 0.9849 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0469 - accuracy: 0.9827 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0464 - accuracy: 0.9840 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0439 - accuracy: 0.9858 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0426 - accuracy: 0.9847 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9835 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0423 - accuracy: 0.9858 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.9851 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0414 - accuracy: 0.9865 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.9847 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0414 - accuracy: 0.9863 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.9847 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9860 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0418 - accuracy: 0.9871 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0398 - accuracy: 0.9876 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0409 - accuracy: 0.9871 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.9865 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0418 - accuracy: 0.9854 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.9852 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.952988792029888 0.9539114614918133 0.9520153550863724 0.9059118786051876 0.9529634082890928 0.9883346971176622\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 1.2106 - accuracy: 0.5036 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6944 - accuracy: 0.5103 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6910 - accuracy: 0.5255 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3651 - accuracy: 0.8266 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2050 - accuracy: 0.9172 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1688 - accuracy: 0.9331 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1588 - accuracy: 0.9343 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1485 - accuracy: 0.9415 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1324 - accuracy: 0.9462 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1244 - accuracy: 0.9499 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1207 - accuracy: 0.9514 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1053 - accuracy: 0.9567 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1038 - accuracy: 0.9580 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0957 - accuracy: 0.9625 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0881 - accuracy: 0.9656 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0860 - accuracy: 0.9678 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.9684 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0778 - accuracy: 0.9717 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9728 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9724 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0687 - accuracy: 0.9745 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0646 - accuracy: 0.9756 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9759 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9763 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9782 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0609 - accuracy: 0.9779 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.9784 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0610 - accuracy: 0.9777 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.9789 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0576 - accuracy: 0.9795 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0565 - accuracy: 0.9801 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.9805 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0566 - accuracy: 0.9786 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0562 - accuracy: 0.9799 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0538 - accuracy: 0.9824 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.9802 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0553 - accuracy: 0.9802 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0536 - accuracy: 0.9806 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0563 - accuracy: 0.9802 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9810 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0569 - accuracy: 0.9801 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0546 - accuracy: 0.9811 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0544 - accuracy: 0.9824 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0562 - accuracy: 0.9799 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9458281444582815 0.941692789968652 0.9499072356215214 0.8916705567561127 0.9458000127950867 0.9868860054708689\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 1.1329 - accuracy: 0.5596 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6961 - accuracy: 0.5072 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.5026 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5124 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5442 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4580 - accuracy: 0.7709 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2555 - accuracy: 0.8924 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2174 - accuracy: 0.9109 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1909 - accuracy: 0.9242 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1787 - accuracy: 0.9281 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1707 - accuracy: 0.9304 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1553 - accuracy: 0.9376 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1518 - accuracy: 0.9394 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1480 - accuracy: 0.9415 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1357 - accuracy: 0.9448 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1344 - accuracy: 0.9459 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1323 - accuracy: 0.9485 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1241 - accuracy: 0.9491 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1218 - accuracy: 0.9506 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1181 - accuracy: 0.9528 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1131 - accuracy: 0.9544 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1129 - accuracy: 0.9550 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1112 - accuracy: 0.9543 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1071 - accuracy: 0.9587 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1083 - accuracy: 0.9586 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1058 - accuracy: 0.9580 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1063 - accuracy: 0.9573 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1049 - accuracy: 0.9596 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1006 - accuracy: 0.9605 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9603 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9598 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1017 - accuracy: 0.9611 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1010 - accuracy: 0.9606 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0994 - accuracy: 0.9633 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1009 - accuracy: 0.9619 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.9629 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1010 - accuracy: 0.9621 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1009 - accuracy: 0.9616 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9615 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1026 - accuracy: 0.9617 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0997 - accuracy: 0.9614 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0990 - accuracy: 0.9609 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1001 - accuracy: 0.9613 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9612 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1009 - accuracy: 0.9609 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9461394769613948 0.9251992642550583 0.967741935483871 0.8931994692057689 0.9464705998694647 0.9877930405167744\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 1.3687 - accuracy: 0.5044 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6946 - accuracy: 0.5040 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6939 - accuracy: 0.4963 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.5132 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6286 - accuracy: 0.6123 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4115 - accuracy: 0.7932 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2236 - accuracy: 0.9064 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1952 - accuracy: 0.9197 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1732 - accuracy: 0.9300 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1651 - accuracy: 0.9341 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1570 - accuracy: 0.9387 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1469 - accuracy: 0.9419 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1399 - accuracy: 0.9452 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1337 - accuracy: 0.9473 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1274 - accuracy: 0.9478 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1236 - accuracy: 0.9503 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1192 - accuracy: 0.9518 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1158 - accuracy: 0.9558 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1105 - accuracy: 0.9568 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1084 - accuracy: 0.9584 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1045 - accuracy: 0.9608 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1060 - accuracy: 0.9581 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9616 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1001 - accuracy: 0.9617 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0986 - accuracy: 0.9609 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0997 - accuracy: 0.9625 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0973 - accuracy: 0.9623 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0969 - accuracy: 0.9627 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0961 - accuracy: 0.9640 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0946 - accuracy: 0.9623 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0961 - accuracy: 0.9631 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0959 - accuracy: 0.9634 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0939 - accuracy: 0.9649 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0934 - accuracy: 0.9645 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0919 - accuracy: 0.9657 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0921 - accuracy: 0.9659 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0924 - accuracy: 0.9658 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0919 - accuracy: 0.9656 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0929 - accuracy: 0.9650 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0927 - accuracy: 0.9657 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9656 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0923 - accuracy: 0.9657 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0918 - accuracy: 0.9668 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0919 - accuracy: 0.9660 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9424034869240349 0.9306174411203055 0.9536867763558805 0.8848877536832959 0.9421521087380931 0.9856135214318326\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.8029 - accuracy: 0.7456 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2324 - accuracy: 0.9055 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1892 - accuracy: 0.9225 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1735 - accuracy: 0.9299 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1648 - accuracy: 0.9361 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1468 - accuracy: 0.9423 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1409 - accuracy: 0.9467 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1333 - accuracy: 0.9469 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1188 - accuracy: 0.9536 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1166 - accuracy: 0.9537 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9584 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0999 - accuracy: 0.9617 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0988 - accuracy: 0.9614 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0933 - accuracy: 0.9635 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0869 - accuracy: 0.9676 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9664 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0825 - accuracy: 0.9682 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9712 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0770 - accuracy: 0.9696 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0760 - accuracy: 0.9722 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9737 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0698 - accuracy: 0.9757 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0688 - accuracy: 0.9730 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0703 - accuracy: 0.9753 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.9748 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0685 - accuracy: 0.9758 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0644 - accuracy: 0.9773 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9754 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9791 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0658 - accuracy: 0.9770 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.9756 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0636 - accuracy: 0.9787 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9769 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0626 - accuracy: 0.9785 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0645 - accuracy: 0.9781 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0644 - accuracy: 0.9763 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0613 - accuracy: 0.9784 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0633 - accuracy: 0.9767 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0638 - accuracy: 0.9763 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9780 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9786 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9782 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.9787 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.9772 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0619 - accuracy: 0.9780 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.951120797011208 0.9346201743462017 0.9676214196762142 0.9027333033198334 0.9511207970112079 0.9898838260632219\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 0.5253 - accuracy: 0.8556 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1946 - accuracy: 0.9233 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1608 - accuracy: 0.9360 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1457 - accuracy: 0.9415 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1377 - accuracy: 0.9461 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1180 - accuracy: 0.9532 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1086 - accuracy: 0.9582 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9603 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9666 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0856 - accuracy: 0.9666 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9688 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9725 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.9740 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9766 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0536 - accuracy: 0.9803 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9795 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0524 - accuracy: 0.9804 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0485 - accuracy: 0.9830 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0454 - accuracy: 0.9833 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.9848 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.9853 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.9853 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0402 - accuracy: 0.9872 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9863 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9865 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0368 - accuracy: 0.9876 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0381 - accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0356 - accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.9876 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.9876 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0367 - accuracy: 0.9882 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0343 - accuracy: 0.9890 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.9885 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9874 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0353 - accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0356 - accuracy: 0.9880 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0337 - accuracy: 0.9889 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0360 - accuracy: 0.9876 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0336 - accuracy: 0.9892 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0348 - accuracy: 0.9889 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0348 - accuracy: 0.9884 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0351 - accuracy: 0.9882 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0349 - accuracy: 0.9875 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 6s 2ms/step\n",
            "0.9495641344956414 0.9473015873015873 0.9517409896151496 0.8990886087537344 0.9495212884583685 0.9907874450941035\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 4ms/step - loss: 1.2669 - accuracy: 0.5396 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.5057 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5031 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5055 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6939 - accuracy: 0.4911 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.4912 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6958 - accuracy: 0.4963 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6937 - accuracy: 0.5002 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.4956 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5044 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.4941 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.4984 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.4958 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.4966 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5043 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.4960 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5103 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6891 - accuracy: 0.5283 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6888 - accuracy: 0.5304 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5015 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6684 - accuracy: 0.5954 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6654 - accuracy: 0.5892 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6393 - accuracy: 0.6291 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5727 - accuracy: 0.7163 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5474 - accuracy: 0.7330 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5101 - accuracy: 0.7680 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4744 - accuracy: 0.7927 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4664 - accuracy: 0.7969 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4603 - accuracy: 0.7985 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4507 - accuracy: 0.8045 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4441 - accuracy: 0.8108 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4373 - accuracy: 0.8140 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4303 - accuracy: 0.8167 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4274 - accuracy: 0.8217 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4298 - accuracy: 0.8199 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4207 - accuracy: 0.8236 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4219 - accuracy: 0.8258 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4195 - accuracy: 0.8244 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4252 - accuracy: 0.8211 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4159 - accuracy: 0.8263 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4156 - accuracy: 0.8273 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4154 - accuracy: 0.8271 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4148 - accuracy: 0.8276 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4145 - accuracy: 0.8264 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4131 - accuracy: 0.8269 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9025529265255293 0.9212007504690432 0.8840669559826411 0.8057156439312214 0.9026338532258421 0.9609190803148435\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3649 - accuracy: 0.8774 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1999 - accuracy: 0.9211 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1653 - accuracy: 0.9324 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1554 - accuracy: 0.9360 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1461 - accuracy: 0.9402 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1298 - accuracy: 0.9479 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1200 - accuracy: 0.9495 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1184 - accuracy: 0.9548 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1058 - accuracy: 0.9581 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0996 - accuracy: 0.9606 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0976 - accuracy: 0.9615 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0872 - accuracy: 0.9682 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9679 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0834 - accuracy: 0.9689 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0755 - accuracy: 0.9714 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0754 - accuracy: 0.9716 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9718 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.9742 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0668 - accuracy: 0.9753 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9740 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9750 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9762 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9769 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0636 - accuracy: 0.9761 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9781 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9772 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0621 - accuracy: 0.9768 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0600 - accuracy: 0.9780 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0595 - accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0586 - accuracy: 0.9789 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9784 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0584 - accuracy: 0.9787 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.9772 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0584 - accuracy: 0.9793 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9785 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9801 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.9793 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9791 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0584 - accuracy: 0.9784 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0571 - accuracy: 0.9804 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0583 - accuracy: 0.9784 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0575 - accuracy: 0.9802 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.9774 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0570 - accuracy: 0.9787 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0574 - accuracy: 0.9787 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9554794520547946 0.9473684210526315 0.963302752293578 0.9110003510591804 0.9553355866731048 0.9904632533029268\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8205 - accuracy: 0.5378 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6386 - accuracy: 0.5588 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6313 - accuracy: 0.5670 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6294 - accuracy: 0.5631 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6243 - accuracy: 0.5684 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6175 - accuracy: 0.5929 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2776 - accuracy: 0.8807 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2081 - accuracy: 0.9151 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1817 - accuracy: 0.9274 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1717 - accuracy: 0.9321 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1618 - accuracy: 0.9350 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1526 - accuracy: 0.9404 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1419 - accuracy: 0.9450 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1376 - accuracy: 0.9470 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1287 - accuracy: 0.9491 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1237 - accuracy: 0.9505 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1187 - accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1132 - accuracy: 0.9550 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1126 - accuracy: 0.9565 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1103 - accuracy: 0.9574 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1057 - accuracy: 0.9594 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9589 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1044 - accuracy: 0.9594 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0998 - accuracy: 0.9605 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9621 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1005 - accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9637 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0959 - accuracy: 0.9646 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0970 - accuracy: 0.9631 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0940 - accuracy: 0.9652 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9647 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9615 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0923 - accuracy: 0.9657 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0931 - accuracy: 0.9647 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0938 - accuracy: 0.9640 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0918 - accuracy: 0.9653 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0932 - accuracy: 0.9668 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0921 - accuracy: 0.9650 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0925 - accuracy: 0.9648 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9627 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0927 - accuracy: 0.9640 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9671 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0921 - accuracy: 0.9653 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0917 - accuracy: 0.9657 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0926 - accuracy: 0.9660 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9452054794520548 0.935179358086847 0.9550215650030807 0.8905324810316901 0.9451004615449639 0.9879462431759938\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.9405 - accuracy: 0.5335 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5079 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.4510 - accuracy: 0.7556 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2392 - accuracy: 0.9023 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2078 - accuracy: 0.9135 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1726 - accuracy: 0.9297 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1653 - accuracy: 0.9332 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9376 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1395 - accuracy: 0.9466 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1336 - accuracy: 0.9468 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.9468 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1201 - accuracy: 0.9513 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9542 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1133 - accuracy: 0.9554 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1053 - accuracy: 0.9578 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1068 - accuracy: 0.9598 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9594 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9616 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9606 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0950 - accuracy: 0.9643 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9663 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0893 - accuracy: 0.9669 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0924 - accuracy: 0.9656 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0866 - accuracy: 0.9666 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0846 - accuracy: 0.9675 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9668 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0853 - accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9689 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0812 - accuracy: 0.9686 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9689 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0831 - accuracy: 0.9696 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9698 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0829 - accuracy: 0.9678 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0834 - accuracy: 0.9681 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9707 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.9678 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9698 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0770 - accuracy: 0.9725 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9683 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0805 - accuracy: 0.9682 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9700 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9702 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9683 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0783 - accuracy: 0.9703 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9688 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9486301369863014 0.9343206696716033 0.9620253164556962 0.8973313033972459 0.9481729930636498 0.9901241137435681\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7624 - accuracy: 0.5104 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6749 - accuracy: 0.5326 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6466 - accuracy: 0.5502 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6382 - accuracy: 0.5491 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6331 - accuracy: 0.5542 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6313 - accuracy: 0.5605 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6272 - accuracy: 0.5674 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6297 - accuracy: 0.5582 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6224 - accuracy: 0.5653 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6234 - accuracy: 0.5623 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6206 - accuracy: 0.5634 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6199 - accuracy: 0.5647 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6211 - accuracy: 0.5690 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6208 - accuracy: 0.5676 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6189 - accuracy: 0.5683 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6149 - accuracy: 0.5922 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6064 - accuracy: 0.6358 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5146 - accuracy: 0.7391 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3635 - accuracy: 0.8424 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3072 - accuracy: 0.8681 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.8899 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2661 - accuracy: 0.8885 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2570 - accuracy: 0.8947 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.8992 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2389 - accuracy: 0.8999 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2349 - accuracy: 0.9039 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2309 - accuracy: 0.9040 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2272 - accuracy: 0.9075 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2261 - accuracy: 0.9070 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2206 - accuracy: 0.9118 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2233 - accuracy: 0.9109 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2225 - accuracy: 0.9092 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2141 - accuracy: 0.9118 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2141 - accuracy: 0.9141 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2141 - accuracy: 0.9132 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2147 - accuracy: 0.9118 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2157 - accuracy: 0.9125 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2149 - accuracy: 0.9133 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2166 - accuracy: 0.9130 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2106 - accuracy: 0.9147 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9154 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2153 - accuracy: 0.9126 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9144 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2139 - accuracy: 0.9093 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2096 - accuracy: 0.9135 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9277708592777086 0.9151000606428138 0.9411388355726168 0.8559360795857894 0.9281194481077153 0.9789730839800155\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.8835 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1864 - accuracy: 0.9237 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1498 - accuracy: 0.9373 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1387 - accuracy: 0.9429 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1296 - accuracy: 0.9462 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1110 - accuracy: 0.9551 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1054 - accuracy: 0.9570 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9621 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.9659 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9675 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0768 - accuracy: 0.9686 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0690 - accuracy: 0.9743 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9740 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9753 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9759 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0577 - accuracy: 0.9778 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0588 - accuracy: 0.9764 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9792 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9809 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9816 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0481 - accuracy: 0.9824 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9815 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0488 - accuracy: 0.9825 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.9836 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9834 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9840 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0436 - accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0440 - accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0463 - accuracy: 0.9830 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0452 - accuracy: 0.9844 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0426 - accuracy: 0.9856 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0441 - accuracy: 0.9850 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.9858 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.9861 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0431 - accuracy: 0.9843 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9850 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9837 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0439 - accuracy: 0.9847 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9859 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0424 - accuracy: 0.9854 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0440 - accuracy: 0.9839 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0427 - accuracy: 0.9851 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0421 - accuracy: 0.9864 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9845 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9852 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9486301369863014 0.9473354231974922 0.9499072356215214 0.8972557048962723 0.9486213294095067 0.9872590016342816\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.7755 - accuracy: 0.5369 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2567 - accuracy: 0.8937 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1858 - accuracy: 0.9237 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.9310 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1583 - accuracy: 0.9363 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9448 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9464 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1263 - accuracy: 0.9482 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1144 - accuracy: 0.9528 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1079 - accuracy: 0.9552 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1058 - accuracy: 0.9580 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1011 - accuracy: 0.9605 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9637 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0903 - accuracy: 0.9640 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0853 - accuracy: 0.9668 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0855 - accuracy: 0.9674 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9686 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0792 - accuracy: 0.9698 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0754 - accuracy: 0.9714 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9705 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0748 - accuracy: 0.9725 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9722 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9736 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.9725 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0692 - accuracy: 0.9749 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9738 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0662 - accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9757 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.9754 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.9746 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9752 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0676 - accuracy: 0.9739 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9756 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0662 - accuracy: 0.9754 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.9769 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9752 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0663 - accuracy: 0.9748 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9748 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9753 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.9749 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9763 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9770 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9739 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9759 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.949252801992528 0.9307173513182097 0.9683744465528147 0.8992346134481001 0.9495458989355121 0.9889932991056037\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3924 - accuracy: 0.8723 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1978 - accuracy: 0.9197 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1632 - accuracy: 0.9358 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1548 - accuracy: 0.9390 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1439 - accuracy: 0.9418 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9486 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1218 - accuracy: 0.9526 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9559 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1063 - accuracy: 0.9573 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1004 - accuracy: 0.9600 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9631 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9658 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9670 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0871 - accuracy: 0.9661 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0795 - accuracy: 0.9712 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0794 - accuracy: 0.9708 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0768 - accuracy: 0.9711 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0752 - accuracy: 0.9714 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9729 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9727 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9744 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9744 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0693 - accuracy: 0.9738 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0660 - accuracy: 0.9770 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0675 - accuracy: 0.9752 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0684 - accuracy: 0.9752 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0673 - accuracy: 0.9745 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0654 - accuracy: 0.9762 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9755 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9766 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9757 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0649 - accuracy: 0.9757 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9758 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0649 - accuracy: 0.9764 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9772 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9770 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9783 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9758 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9757 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9771 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9770 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9759 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9777 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.9763 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0645 - accuracy: 0.9763 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9483188044831881 0.9446212603437301 0.9518586227909811 0.8965883979973391 0.9482399415673556 0.9876740246647511\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.8607 - accuracy: 0.5170 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.5426 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6340 - accuracy: 0.5556 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6284 - accuracy: 0.5578 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6276 - accuracy: 0.5606 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6213 - accuracy: 0.5643 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6273 - accuracy: 0.5598 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6193 - accuracy: 0.5618 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6213 - accuracy: 0.5666 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6167 - accuracy: 0.5613 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6172 - accuracy: 0.5654 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6186 - accuracy: 0.5595 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6164 - accuracy: 0.5643 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6130 - accuracy: 0.5612 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6181 - accuracy: 0.5634 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6141 - accuracy: 0.5776 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6148 - accuracy: 0.5660 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.6105 - accuracy: 0.5636 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.6039 - accuracy: 0.6085 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5942 - accuracy: 0.6341 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5202 - accuracy: 0.7482 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4519 - accuracy: 0.8090 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4698 - accuracy: 0.7907 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.4100 - accuracy: 0.8301 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.3361 - accuracy: 0.8647 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.8716 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2923 - accuracy: 0.8814 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2852 - accuracy: 0.8860 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2765 - accuracy: 0.8892 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2674 - accuracy: 0.8914 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2684 - accuracy: 0.8919 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2542 - accuracy: 0.8986 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2462 - accuracy: 0.9021 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2473 - accuracy: 0.9003 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2451 - accuracy: 0.9008 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2398 - accuracy: 0.9039 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2424 - accuracy: 0.9036 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2352 - accuracy: 0.9057 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2365 - accuracy: 0.9064 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2390 - accuracy: 0.9026 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2360 - accuracy: 0.9067 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2367 - accuracy: 0.9078 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2346 - accuracy: 0.9068 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2337 - accuracy: 0.9061 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.2347 - accuracy: 0.9095 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9112702366127023 0.8760896637608966 0.9464508094645081 0.8245841363086672 0.9112702366127023 0.9726386030592005\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.5129 - accuracy: 0.8129 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9211 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1697 - accuracy: 0.9334 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9376 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1550 - accuracy: 0.9394 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1347 - accuracy: 0.9473 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1305 - accuracy: 0.9486 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.1260 - accuracy: 0.9496 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9549 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9567 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9581 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0992 - accuracy: 0.9616 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9645 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9630 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0887 - accuracy: 0.9647 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9670 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9661 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0837 - accuracy: 0.9696 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9689 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9692 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9693 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9703 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0771 - accuracy: 0.9702 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0766 - accuracy: 0.9715 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0787 - accuracy: 0.9702 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0768 - accuracy: 0.9715 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0761 - accuracy: 0.9731 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9714 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0744 - accuracy: 0.9721 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0728 - accuracy: 0.9722 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9728 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0729 - accuracy: 0.9724 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9721 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9731 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9734 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0747 - accuracy: 0.9723 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9714 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9735 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9720 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9718 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9728 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9723 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9745 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9742 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9737 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9464508094645081 0.939047619047619 0.9535736102626756 0.8929052559479974 0.9463106146551473 0.9902118664611029\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 1.0733 - accuracy: 0.8121 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2103 - accuracy: 0.9114 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1568 - accuracy: 0.9372 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1401 - accuracy: 0.9434 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1274 - accuracy: 0.9472 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1068 - accuracy: 0.9590 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0943 - accuracy: 0.9632 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0910 - accuracy: 0.9645 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0772 - accuracy: 0.9708 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0684 - accuracy: 0.9741 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0625 - accuracy: 0.9749 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0556 - accuracy: 0.9788 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0524 - accuracy: 0.9797 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0492 - accuracy: 0.9817 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0454 - accuracy: 0.9831 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0441 - accuracy: 0.9839 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0407 - accuracy: 0.9851 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0394 - accuracy: 0.9868 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0364 - accuracy: 0.9871 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0367 - accuracy: 0.9873 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0336 - accuracy: 0.9889 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0336 - accuracy: 0.9900 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0321 - accuracy: 0.9893 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0338 - accuracy: 0.9881 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9907 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0308 - accuracy: 0.9903 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9917 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9906 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9907 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9905 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9912 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9918 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9904 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9917 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9902 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9915 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0284 - accuracy: 0.9917 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9905 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9902 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0290 - accuracy: 0.9910 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9912 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9905 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0282 - accuracy: 0.9910 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9900 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9517434620174346 0.9368355222013759 0.9665220086794792 0.9038600317166167 0.9516787654404275 0.9896486761138297\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 1.3620 - accuracy: 0.5013 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6967 - accuracy: 0.5040 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6943 - accuracy: 0.5052 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.4997 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6952 - accuracy: 0.4970 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6934 - accuracy: 0.4998 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.5073 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6941 - accuracy: 0.5028 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.5073 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5005 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6934 - accuracy: 0.5058 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6930 - accuracy: 0.5044 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6929 - accuracy: 0.5051 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6924 - accuracy: 0.5033 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6909 - accuracy: 0.5134 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6890 - accuracy: 0.5329 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6851 - accuracy: 0.5461 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6523 - accuracy: 0.6066 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6409 - accuracy: 0.6319 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6215 - accuracy: 0.6397 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.4705 - accuracy: 0.7676 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.3719 - accuracy: 0.8277 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.3309 - accuracy: 0.8566 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2835 - accuracy: 0.8796 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2694 - accuracy: 0.8868 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2635 - accuracy: 0.8927 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2454 - accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2361 - accuracy: 0.9066 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2357 - accuracy: 0.9063 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2245 - accuracy: 0.9116 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2242 - accuracy: 0.9125 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2214 - accuracy: 0.9120 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2153 - accuracy: 0.9155 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2166 - accuracy: 0.9170 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2150 - accuracy: 0.9159 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2118 - accuracy: 0.9170 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2122 - accuracy: 0.9185 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2095 - accuracy: 0.9199 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2081 - accuracy: 0.9208 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2091 - accuracy: 0.9197 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2057 - accuracy: 0.9212 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2052 - accuracy: 0.9201 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2047 - accuracy: 0.9215 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2081 - accuracy: 0.9193 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2061 - accuracy: 0.9200 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.9209215442092155 0.9201014584654407 0.9217125382262997 0.8417957139817317 0.9209069983458702 0.9757170642977511\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 0.8700 - accuracy: 0.8282 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2050 - accuracy: 0.9180 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1630 - accuracy: 0.9359 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1513 - accuracy: 0.9400 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1405 - accuracy: 0.9451 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1145 - accuracy: 0.9559 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1031 - accuracy: 0.9591 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0949 - accuracy: 0.9640 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0830 - accuracy: 0.9691 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0748 - accuracy: 0.9719 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0700 - accuracy: 0.9724 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0641 - accuracy: 0.9771 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0595 - accuracy: 0.9783 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0550 - accuracy: 0.9801 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0495 - accuracy: 0.9832 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0460 - accuracy: 0.9844 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9843 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0421 - accuracy: 0.9869 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0414 - accuracy: 0.9858 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0404 - accuracy: 0.9867 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0392 - accuracy: 0.9869 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0368 - accuracy: 0.9886 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0379 - accuracy: 0.9872 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0356 - accuracy: 0.9882 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9876 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0353 - accuracy: 0.9872 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0341 - accuracy: 0.9887 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0333 - accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9887 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0317 - accuracy: 0.9900 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9891 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0343 - accuracy: 0.9889 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9906 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0317 - accuracy: 0.9893 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0335 - accuracy: 0.9893 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0317 - accuracy: 0.9898 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0329 - accuracy: 0.9896 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0329 - accuracy: 0.9897 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0321 - accuracy: 0.9895 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9897 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0332 - accuracy: 0.9894 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0327 - accuracy: 0.9891 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0320 - accuracy: 0.9890 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0318 - accuracy: 0.9900 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 1ms/step\n",
            "0.951120797011208 0.9421019509125236 0.9599507085643869 0.9023408376970043 0.9510263297384552 0.9894024576697388\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 1.4898 - accuracy: 0.4958 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6949 - accuracy: 0.4994 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6939 - accuracy: 0.4931 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6937 - accuracy: 0.4970 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6937 - accuracy: 0.4973 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6936 - accuracy: 0.4947 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6935 - accuracy: 0.5004 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6936 - accuracy: 0.4991 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.5011 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6934 - accuracy: 0.5019 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6934 - accuracy: 0.4971 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.4969 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6925 - accuracy: 0.5220 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6901 - accuracy: 0.5374 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6885 - accuracy: 0.5391 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6839 - accuracy: 0.5558 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6806 - accuracy: 0.5582 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6108 - accuracy: 0.6728 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.5590 - accuracy: 0.7173 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.4496 - accuracy: 0.8067 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.3763 - accuracy: 0.8554 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.3454 - accuracy: 0.8673 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.3214 - accuracy: 0.8793 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2923 - accuracy: 0.8931 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2786 - accuracy: 0.8937 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2716 - accuracy: 0.8934 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2534 - accuracy: 0.9028 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2559 - accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2498 - accuracy: 0.9050 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2395 - accuracy: 0.9082 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2384 - accuracy: 0.9077 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2320 - accuracy: 0.9105 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2344 - accuracy: 0.9113 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2309 - accuracy: 0.9102 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2314 - accuracy: 0.9085 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2241 - accuracy: 0.9151 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2244 - accuracy: 0.9160 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2214 - accuracy: 0.9151 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2235 - accuracy: 0.9144 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2221 - accuracy: 0.9139 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2188 - accuracy: 0.9148 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2213 - accuracy: 0.9148 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2208 - accuracy: 0.9142 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2190 - accuracy: 0.9150 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.2209 - accuracy: 0.9127 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.926214196762142 0.9072762395363811 0.9439421338155516 0.8525441693318635 0.9256091866759664 0.9791837688395597\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 2.6992 - accuracy: 0.5025 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6977 - accuracy: 0.4989 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6965 - accuracy: 0.5047 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6936 - accuracy: 0.5011 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6934 - accuracy: 0.5004 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6940 - accuracy: 0.4998 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.5009 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6936 - accuracy: 0.4970 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.5051 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6935 - accuracy: 0.4931 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6935 - accuracy: 0.4998 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.4995 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.4963 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6933 - accuracy: 0.4967 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5012 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5008 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.4994 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.4967 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5022 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5033 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5035 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6931 - accuracy: 0.5052 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6931 - accuracy: 0.5071 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6931 - accuracy: 0.5051 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5023 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5033 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6931 - accuracy: 0.5040 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6929 - accuracy: 0.5114 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6928 - accuracy: 0.5135 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6931 - accuracy: 0.5040 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6925 - accuracy: 0.5170 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6927 - accuracy: 0.5203 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6916 - accuracy: 0.5350 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6915 - accuracy: 0.5329 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6906 - accuracy: 0.5455 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6898 - accuracy: 0.5471 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6893 - accuracy: 0.5514 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6887 - accuracy: 0.5518 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6876 - accuracy: 0.5596 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6872 - accuracy: 0.5616 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6863 - accuracy: 0.5598 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6865 - accuracy: 0.5578 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6857 - accuracy: 0.5582 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6853 - accuracy: 0.5570 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.6850 - accuracy: 0.5611 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.5828144458281445 0.8526379624014554 0.2981445937300064 0.18171357630781437 0.5753912780657309 0.704498393140029\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: 0.7228 - accuracy: 0.8621 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1848 - accuracy: 0.9250 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1470 - accuracy: 0.9428 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1355 - accuracy: 0.9466 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1249 - accuracy: 0.9492 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.1042 - accuracy: 0.9594 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0945 - accuracy: 0.9608 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0898 - accuracy: 0.9631 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0766 - accuracy: 0.9703 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0704 - accuracy: 0.9718 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0653 - accuracy: 0.9736 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0574 - accuracy: 0.9789 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9795 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0527 - accuracy: 0.9812 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9844 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0435 - accuracy: 0.9842 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0425 - accuracy: 0.9851 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0400 - accuracy: 0.9871 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0378 - accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0360 - accuracy: 0.9877 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9880 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0337 - accuracy: 0.9896 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9886 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0325 - accuracy: 0.9899 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0309 - accuracy: 0.9906 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0312 - accuracy: 0.9900 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9897 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9906 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9910 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9904 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9910 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9912 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0292 - accuracy: 0.9908 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9909 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9905 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9898 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9906 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9904 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9907 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9910 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9915 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9910 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9911 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9903 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: 0.0290 - accuracy: 0.9914 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n",
            "0.9458281444582815 0.9379310344827586 0.9536178107606679 0.8917397219643708 0.9457744226217133 0.9859802684254095\n",
            "Epoch 1/45\n",
            "402/402 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.5037 - lr: 0.1000\n",
            "Epoch 2/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.1000\n",
            "Epoch 3/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0600\n",
            "Epoch 4/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0600\n",
            "Epoch 5/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0600\n",
            "Epoch 6/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0360\n",
            "Epoch 7/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0360\n",
            "Epoch 8/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0360\n",
            "Epoch 9/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0216\n",
            "Epoch 10/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0216\n",
            "Epoch 11/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0216\n",
            "Epoch 12/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0130\n",
            "Epoch 13/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0130\n",
            "Epoch 14/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0130\n",
            "Epoch 15/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0078\n",
            "Epoch 16/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0078\n",
            "Epoch 17/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0078\n",
            "Epoch 18/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0047\n",
            "Epoch 19/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0047\n",
            "Epoch 20/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0047\n",
            "Epoch 21/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0028\n",
            "Epoch 22/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0028\n",
            "Epoch 23/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0028\n",
            "Epoch 24/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0017\n",
            "Epoch 25/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0017\n",
            "Epoch 26/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0017\n",
            "Epoch 27/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0010\n",
            "Epoch 28/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0010\n",
            "Epoch 29/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 0.0010\n",
            "Epoch 30/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 6.0466e-04\n",
            "Epoch 31/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 6.0466e-04\n",
            "Epoch 32/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 6.0466e-04\n",
            "Epoch 33/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 3.6280e-04\n",
            "Epoch 34/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 3.6280e-04\n",
            "Epoch 35/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 3.6280e-04\n",
            "Epoch 36/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 2.1768e-04\n",
            "Epoch 37/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 2.1768e-04\n",
            "Epoch 38/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 2.1768e-04\n",
            "Epoch 39/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 1.3061e-04\n",
            "Epoch 40/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 1.3061e-04\n",
            "Epoch 41/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 1.3061e-04\n",
            "Epoch 42/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 7.8364e-05\n",
            "Epoch 43/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 7.8364e-05\n",
            "Epoch 44/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 7.8364e-05\n",
            "Epoch 45/45\n",
            "402/402 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.5019 - lr: 4.7018e-05\n",
            "3212/3212 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-b92178710ae7>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_whole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_whole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN_channel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# optimal paraemters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# performance evaluation at the independent test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mACC_collection_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-43b1e503552b>\u001b[0m in \u001b[0;36mcheck_performance\u001b[0;34m(saved_model, X_test, y_test)\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mpredicted_protability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_protability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_protability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_protability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mpredicted_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "# final model\n",
        "final_ACC_collection_test = []\n",
        "final_BACC_collection_test = []\n",
        "final_Sn_collection_test = []\n",
        "final_Sp_collection_test = []\n",
        "final_MCC_collection_test = []\n",
        "final_AUC_collection_test = []\n",
        "for i in range(len(CNN_channel)):\n",
        "  i= i + 2\n",
        "  # split dataset ten times and each times as 8:2 ratio for data division\n",
        "  ACC_collection_test = []\n",
        "  BACC_collection_test = []\n",
        "  Sn_collection_test = []\n",
        "  Sp_collection_test = []\n",
        "  MCC_collection_test = []\n",
        "  AUC_collection_test = []\n",
        "  for a in range(10):\n",
        "      random_num = a\n",
        "      X_train_whole, X_test, y_train_whole, y_test = train_test_split( X, y, test_size=0.2, random_state=random_num,shuffle=True)\n",
        "\n",
        "      # train the model with the optimal parameters in the cross validation\n",
        "      saved_model = train_model(X_train_whole, y_train_whole,CNN_channel[i],kernel_size[i],stride_size[i],dense_node[i]) # optimal paraemters\n",
        "      # performance evaluation at the independent test dataset\n",
        "      ACC, Sn, Sp, MCC, BACC, AUC = check_performance(saved_model, X_test, y_test)\n",
        "      print(ACC, Sn, Sp, MCC, BACC, AUC)\n",
        "      ACC_collection_test.append(ACC)\n",
        "      BACC_collection_test.append(BACC)\n",
        "      Sn_collection_test.append(Sn)\n",
        "      Sp_collection_test.append(Sp)\n",
        "      MCC_collection_test.append(MCC)\n",
        "      AUC_collection_test.append(AUC)\n",
        "\n",
        "  import math\n",
        "  final_ACC_collection_test.append(str(round(statistics.mean(ACC_collection_test),3))+'±'+ str(round(statistics.stdev(ACC_collection_test),3)))\n",
        "  if any(math.isnan(i) for i in MCC_collection_test):\n",
        "      final_BACC_collection_test.append('none')\n",
        "      final_Sn_collection_test.append('none')\n",
        "      final_Sp_collection_test.append('none')\n",
        "      final_MCC_collection_test.append('none')\n",
        "      final_AUC_collection_test.append('none')\n",
        "  else:\n",
        "      final_BACC_collection_test.append(str(round(statistics.mean(BACC_collection_test),3))+'±'+str(round(statistics.stdev(BACC_collection_test),3)))\n",
        "      final_Sn_collection_test.append(str(round(statistics.mean(Sn_collection_test),3))+'±'+str(round(statistics.stdev(Sn_collection_test),3)))\n",
        "      final_Sp_collection_test.append(str(round(statistics.mean(Sp_collection_test),3))+'±'+str(round(statistics.stdev(Sp_collection_test),3)))\n",
        "      final_MCC_collection_test.append(str(round(statistics.mean(MCC_collection_test),3))+'±'+str(round(statistics.stdev(MCC_collection_test),3)))\n",
        "      final_AUC_collection_test.append(str(round(statistics.mean(AUC_collection_test),3))+'±'+str(round(statistics.stdev(AUC_collection_test),3)))\n",
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performance in test\n",
        "print(final_ACC_collection_test, '\\n',final_BACC_collection_test, '\\n',final_Sn_collection_test, '\\n',final_Sp_collection_test, '\\n',final_MCC_collection_test,'\\n', final_AUC_collection_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpDO7FzVQKbl",
        "outputId": "23afd7c5-a32c-4974-fce9-640ae908263b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.95±0.004', '0.938±0.018'] \n",
            " ['0.95±0.004', '0.938±0.018'] \n",
            " ['0.941±0.009', '0.929±0.021'] \n",
            " ['0.958±0.007', '0.948±0.024'] \n",
            " ['0.9±0.008', '0.877±0.036'] \n",
            " ['0.989±0.002', '0.984±0.01']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lncekyd435aF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "95NTckuFZZzm",
        "m91cA0H5w_eY",
        "5RLR10hUsxca",
        "ztgr6bl-YGDI",
        "C3yzGDFEYfCY",
        "mFyOy-19Yvil",
        "dEdAluvxYzfJ",
        "Ex7esuYyY0vU",
        "xSCXCjv8gYIr",
        "jZBMpsS3_Ymu",
        "Vn_ddIHq_Ymv",
        "HXbl2M2w_Ymw",
        "riQQE4SS_Ymy",
        "A8q0KSsR_Ymz",
        "e7Phr-fdR3zm",
        "0apTBCCEpEhR",
        "myos98aO_YO2",
        "QW4FNivjn0Y7",
        "hQ158sS6YJim",
        "AHLPytdEYTcw",
        "RjTN9KSDoVxJ",
        "cM9mOI27cXie",
        "KgOX83DaYVzr",
        "1nkHCRyydkIQ",
        "xkIhO_TpdWpz",
        "bJ69ACU5YYKi",
        "0J2EaTe_fNao",
        "15NhF_b8eB64",
        "bo1csPt1d4__",
        "LNMAzPKaYcpT",
        "475QQQ4td6H2"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}